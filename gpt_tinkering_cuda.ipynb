{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sdtDsu1Y0EqL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(69)\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANr5dn7W0EqR",
        "outputId": "a00cbe8d-e1c6-454b-b552-4ffd17ce17e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of dataset in characters:  493412\n"
          ]
        }
      ],
      "source": [
        "with open('data/kon.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "print(\"length of dataset in characters: \", len(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pANiObIZ0EqU",
        "outputId": "98f70469-1c89-4341-89e8-c142a14331b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ui:\n",
            "Sis, come on. You'd better get out of bed. Sis?\n",
            "\n",
            "Yui:\n",
            "Ah! I-it's eight! I'm late! Oh!\n",
            "\n",
            "Ui:\n",
            "Hey, why the rush? Hm?\n",
            "\n",
            "Yui:\n",
            "See you later!\n",
            "\n",
            "Lady:\n",
            "Oh, good morning, Yui.\n",
            "\n",
            "Yui:\n",
            "Good morning!\n",
            "\n",
            "Yui:\n",
            "What?! I read the clock wrong!\n",
            "Starting today, I'm a high schooler!\n",
            "\n",
            "Opening Song\n",
            "Cagayake!GIRLS by 放課後ティータイム(After School Tea Time)\n",
            "\n",
            "Girls:\n",
            "Congratulations on starting school here!\n",
            "\n",
            "Girl 1:\n",
            "Please join the Tennis Club!\n",
            "\n",
            "Girl 2:\n",
            "The Judo Club's better!\n",
            "\n",
            "Girl 3:\n",
            "Please join the Tea Ceremony Club!\n",
            "\n",
            "Girl 4:\n"
          ]
        }
      ],
      "source": [
        "print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WvM5h6_i3KsM"
      },
      "outputs": [],
      "source": [
        "# remove japanese characters\n",
        "text = ''.join(filter(lambda character:ord(character) < 0x3000, text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7SOcWJM0EqW",
        "outputId": "a82a4da8-a8ed-47bf-cfb5-2e4c59dee2cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unique characters: 93 \n",
            " !\"#$%&'(),-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]abcdefghijklmnopqrstuvwxyz{|}~°éū‘’…♪\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(\"unique characters:\", vocab_size, ''.join(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yobmmaeK0EqX",
        "outputId": "26669f38-4b26-4b53-f642-ee7543e7c578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '#': 4, '$': 5, '%': 6, '&': 7, \"'\": 8, '(': 9, ')': 10, ',': 11, '-': 12, '.': 13, '/': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, ';': 26, '?': 27, 'A': 28, 'B': 29, 'C': 30, 'D': 31, 'E': 32, 'F': 33, 'G': 34, 'H': 35, 'I': 36, 'J': 37, 'K': 38, 'L': 39, 'M': 40, 'N': 41, 'O': 42, 'P': 43, 'Q': 44, 'R': 45, 'S': 46, 'T': 47, 'U': 48, 'V': 49, 'W': 50, 'X': 51, 'Y': 52, 'Z': 53, '[': 54, ']': 55, 'a': 56, 'b': 57, 'c': 58, 'd': 59, 'e': 60, 'f': 61, 'g': 62, 'h': 63, 'i': 64, 'j': 65, 'k': 66, 'l': 67, 'm': 68, 'n': 69, 'o': 70, 'p': 71, 'q': 72, 'r': 73, 's': 74, 't': 75, 'u': 76, 'v': 77, 'w': 78, 'x': 79, 'y': 80, 'z': 81, '{': 82, '|': 83, '}': 84, '~': 85, '°': 86, 'é': 87, 'ū': 88, '‘': 89, '’': 90, '…': 91, '♪': 92, '': 93}\n",
            "{0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: '#', 5: '$', 6: '%', 7: '&', 8: \"'\", 9: '(', 10: ')', 11: ',', 12: '-', 13: '.', 14: '/', 15: '0', 16: '1', 17: '2', 18: '3', 19: '4', 20: '5', 21: '6', 22: '7', 23: '8', 24: '9', 25: ':', 26: ';', 27: '?', 28: 'A', 29: 'B', 30: 'C', 31: 'D', 32: 'E', 33: 'F', 34: 'G', 35: 'H', 36: 'I', 37: 'J', 38: 'K', 39: 'L', 40: 'M', 41: 'N', 42: 'O', 43: 'P', 44: 'Q', 45: 'R', 46: 'S', 47: 'T', 48: 'U', 49: 'V', 50: 'W', 51: 'X', 52: 'Y', 53: 'Z', 54: '[', 55: ']', 56: 'a', 57: 'b', 58: 'c', 59: 'd', 60: 'e', 61: 'f', 62: 'g', 63: 'h', 64: 'i', 65: 'j', 66: 'k', 67: 'l', 68: 'm', 69: 'n', 70: 'o', 71: 'p', 72: 'q', 73: 'r', 74: 's', 75: 't', 76: 'u', 77: 'v', 78: 'w', 79: 'x', 80: 'y', 81: 'z', 82: '{', 83: '|', 84: '}', 85: '~', 86: '°', 87: 'é', 88: 'ū', 89: '‘', 90: '’', 91: '…', 92: '♪', 93: ''}\n",
            "encoded: [48, 64, 25, 0, 46, 64, 74, 11, 1, 58, 70, 68, 60, 1, 70, 69, 13, 1, 52, 70]\n",
            "decoded: Ui:\n",
            "Sis, come on. Yo\n",
            "vocab size: 94\n"
          ]
        }
      ],
      "source": [
        "# Very simple tokenizer\n",
        "stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "itos = {i:ch for i,ch in enumerate(chars)}\n",
        "# add special token for padding\n",
        "stoi[''] = len(stoi)\n",
        "itos[len(itos)] = ''\n",
        "print(stoi)\n",
        "print(itos)\n",
        "encode = lambda s: [stoi[ch] for ch in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "print(\"encoded:\", encode(text[:20]))\n",
        "print(\"decoded:\", decode(encode(text[:20])))\n",
        "vocab_size = len(itos)\n",
        "print(\"vocab size:\", vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Pnf9KfP0EqY",
        "outputId": "ff581168-335a-4f0f-efeb-0d4bd5b225ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([493171])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = torch.tensor(encode(text), dtype=torch.int64)\n",
        "data.to(device)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ2fY1pR0EqY",
        "outputId": "5eb599e0-fb79-4cdb-c4b9-52a781d67151"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([48, 64, 25,  0, 46, 64, 74, 11,  1, 58, 70, 68, 60,  1, 70, 69, 13,  1,\n",
              "        52, 70, 76,  8, 59,  1, 57, 60, 75, 75, 60, 73,  1, 62, 60, 75,  1, 70,\n",
              "        76, 75,  1, 70, 61,  1, 57, 60, 59, 13,  1, 46, 64, 74, 27,  0,  0, 52,\n",
              "        76, 64, 25,  0, 28, 63,  2,  1, 36, 12, 64, 75,  8, 74,  1, 60, 64, 62,\n",
              "        63, 75,  2,  1, 36,  8, 68,  1, 67, 56, 75, 60,  2,  1, 42, 63,  2,  0,\n",
              "         0, 48, 64, 25,  0, 35, 60, 80, 11,  1])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIaYesPh0Eqa",
        "outputId": "caa27cbb-5ae3-4406-8194-646264d4ba99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([468512]) torch.Size([24659])\n"
          ]
        }
      ],
      "source": [
        "n = int(len(data) * 0.95)\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "print(train_data.shape, val_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bFhizcI0Eqa",
        "outputId": "c93a4d43-6fb2-4de7-aefc-8fed47e4a861"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([48, 64, 25,  0, 46, 64, 74, 11,  1])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VHHMHja0Eqb",
        "outputId": "6a88e780-075f-4c14-e198-9c14d6ae4044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "context: [48] target: 64\n",
            "context: [48, 64] target: 25\n",
            "context: [48, 64, 25] target: 0\n",
            "context: [48, 64, 25, 0] target: 46\n",
            "context: [48, 64, 25, 0, 46] target: 64\n",
            "context: [48, 64, 25, 0, 46, 64] target: 74\n",
            "context: [48, 64, 25, 0, 46, 64, 74] target: 11\n",
            "context: [48, 64, 25, 0, 46, 64, 74, 11] target: 1\n"
          ]
        }
      ],
      "source": [
        "# context and target simulation\n",
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1].tolist()\n",
        "    target = y[t].item()\n",
        "    print('context:', context, 'target:', target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skFCPvQC0Eqc",
        "outputId": "08990c5b-88af-4a51-ce37-3c59989d6d74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs:\n",
            "torch.Size([4, 128])\n",
            "tensor([[66, 70, 25,  0, 40, 64, 74, 74,  1, 52, 56, 68, 56, 69, 56, 66, 56,  1,\n",
            "         64, 74,  1, 73, 60, 56, 67, 67, 80,  1, 62, 73, 60, 56, 75,  2,  0,  0,\n",
            "         41, 70, 57, 76, 80, 70, 25,  0, 36, 75,  8, 74,  1, 67, 64, 66, 60,  1,\n",
            "         74, 63, 60,  8, 74,  1, 62, 60, 75, 75, 64, 69, 62,  1, 71, 73, 60, 75,\n",
            "         75, 64, 60, 73,  1, 56, 69, 59,  1, 71, 73, 60, 75, 75, 64, 60, 73,  1,\n",
            "         60, 77, 60, 73, 80,  1, 59, 56, 80,  2,  0,  0, 46, 56, 78, 56, 66, 70,\n",
            "         25,  0, 54, 62, 64, 62, 62, 67, 60, 74, 55,  0,  0, 40, 64, 70, 25,  0,\n",
            "          9, 36],\n",
            "        [70, 75,  0,  0, 40, 64, 70, 25,  0, 39, 60, 75,  8, 74,  1, 74, 60, 60,\n",
            "         13, 13, 13,  0,  0, 45, 64, 75, 74, 76, 25,  0, 48, 63, 11,  1, 64, 75,\n",
            "          8, 74,  1, 69, 70, 75, 63, 64, 69, 62,  2,  0, 30, 63, 60, 58, 66,  1,\n",
            "         64, 75,  2,  0, 40, 70, 76, 74, 75, 56, 58, 63, 60,  2,  0,  0, 47, 74,\n",
            "         76, 68, 76, 62, 64, 25,  0, 36,  1, 63, 56, 77, 60,  1, 75, 70, 13, 13,\n",
            "         13,  1, 57, 70, 78,  1, 70, 76, 75,  1, 75, 70, 59, 56, 80, 13,  0,  0,\n",
            "         52, 76, 64, 25,  0, 31, 70,  1, 80, 70, 76,  1, 63, 56, 77, 60,  1, 71,\n",
            "         67, 56],\n",
            "        [ 1, 73, 76, 69, 13, 13,  1, 56,  1, 67, 64, 75, 75, 67, 60, 13, 13,  1,\n",
            "         74, 67, 70, 78, 60, 73,  1, 71, 67, 60, 56, 74, 60, 13, 13,  0,  0, 48,\n",
            "         64, 25,  0, 46, 70, 73, 73, 80, 13,  0,  0, 28, 81, 76, 74, 56, 25,  0,\n",
            "         40, 64, 70, 12, 74, 60, 68, 71, 56, 64, 13,  0,  0, 37, 76, 69, 25,  0,\n",
            "         35, 76, 63, 27,  0,  0, 48, 64, 25,  0, 36,  1, 75, 63, 70, 76, 62, 63,\n",
            "         75,  1, 80, 70, 76,  8, 73, 60,  1, 73, 76, 69, 69, 64, 69, 62,  1, 78,\n",
            "         64, 75, 63,  1, 68, 80,  1, 74, 64, 74, 75, 60, 73,  1, 56, 69, 59,  1,\n",
            "         75, 63],\n",
            "        [59, 56, 80, 27,  0,  0, 45, 64, 75, 74, 76, 25,  0, 46, 70,  1, 78, 63,\n",
            "         56, 75,  1, 64, 61,  1, 64, 75,  1, 64, 74, 69,  8, 75, 27,  0,  0, 47,\n",
            "         74, 76, 68, 76, 62, 64, 25,  0, 30,  8, 68, 70, 69, 11,  1, 67, 60, 75,\n",
            "          8, 74,  1, 75, 73, 80,  1, 64, 75,  2,  0,  0, 45, 64, 75, 74, 76, 25,\n",
            "          0, 28, 63,  2,  1, 50, 60, 67, 67, 11,  1, 59, 70, 78, 69,  1, 75, 63,\n",
            "         60,  1, 63, 56, 75, 58, 63, 11,  1, 36,  1, 74, 76, 71, 71, 70, 74, 60,\n",
            "         13,  0,  0, 47, 74, 76, 68, 76, 62, 64, 25,  0, 33, 73, 70, 68,  1, 78,\n",
            "         63, 56]], device='cuda:0')\n",
            "targets:\n",
            "torch.Size([4, 128])\n",
            "tensor([[70, 25,  0, 40, 64, 74, 74,  1, 52, 56, 68, 56, 69, 56, 66, 56,  1, 64,\n",
            "         74,  1, 73, 60, 56, 67, 67, 80,  1, 62, 73, 60, 56, 75,  2,  0,  0, 41,\n",
            "         70, 57, 76, 80, 70, 25,  0, 36, 75,  8, 74,  1, 67, 64, 66, 60,  1, 74,\n",
            "         63, 60,  8, 74,  1, 62, 60, 75, 75, 64, 69, 62,  1, 71, 73, 60, 75, 75,\n",
            "         64, 60, 73,  1, 56, 69, 59,  1, 71, 73, 60, 75, 75, 64, 60, 73,  1, 60,\n",
            "         77, 60, 73, 80,  1, 59, 56, 80,  2,  0,  0, 46, 56, 78, 56, 66, 70, 25,\n",
            "          0, 54, 62, 64, 62, 62, 67, 60, 74, 55,  0,  0, 40, 64, 70, 25,  0,  9,\n",
            "         36,  1],\n",
            "        [75,  0,  0, 40, 64, 70, 25,  0, 39, 60, 75,  8, 74,  1, 74, 60, 60, 13,\n",
            "         13, 13,  0,  0, 45, 64, 75, 74, 76, 25,  0, 48, 63, 11,  1, 64, 75,  8,\n",
            "         74,  1, 69, 70, 75, 63, 64, 69, 62,  2,  0, 30, 63, 60, 58, 66,  1, 64,\n",
            "         75,  2,  0, 40, 70, 76, 74, 75, 56, 58, 63, 60,  2,  0,  0, 47, 74, 76,\n",
            "         68, 76, 62, 64, 25,  0, 36,  1, 63, 56, 77, 60,  1, 75, 70, 13, 13, 13,\n",
            "          1, 57, 70, 78,  1, 70, 76, 75,  1, 75, 70, 59, 56, 80, 13,  0,  0, 52,\n",
            "         76, 64, 25,  0, 31, 70,  1, 80, 70, 76,  1, 63, 56, 77, 60,  1, 71, 67,\n",
            "         56, 69],\n",
            "        [73, 76, 69, 13, 13,  1, 56,  1, 67, 64, 75, 75, 67, 60, 13, 13,  1, 74,\n",
            "         67, 70, 78, 60, 73,  1, 71, 67, 60, 56, 74, 60, 13, 13,  0,  0, 48, 64,\n",
            "         25,  0, 46, 70, 73, 73, 80, 13,  0,  0, 28, 81, 76, 74, 56, 25,  0, 40,\n",
            "         64, 70, 12, 74, 60, 68, 71, 56, 64, 13,  0,  0, 37, 76, 69, 25,  0, 35,\n",
            "         76, 63, 27,  0,  0, 48, 64, 25,  0, 36,  1, 75, 63, 70, 76, 62, 63, 75,\n",
            "          1, 80, 70, 76,  8, 73, 60,  1, 73, 76, 69, 69, 64, 69, 62,  1, 78, 64,\n",
            "         75, 63,  1, 68, 80,  1, 74, 64, 74, 75, 60, 73,  1, 56, 69, 59,  1, 75,\n",
            "         63, 60],\n",
            "        [56, 80, 27,  0,  0, 45, 64, 75, 74, 76, 25,  0, 46, 70,  1, 78, 63, 56,\n",
            "         75,  1, 64, 61,  1, 64, 75,  1, 64, 74, 69,  8, 75, 27,  0,  0, 47, 74,\n",
            "         76, 68, 76, 62, 64, 25,  0, 30,  8, 68, 70, 69, 11,  1, 67, 60, 75,  8,\n",
            "         74,  1, 75, 73, 80,  1, 64, 75,  2,  0,  0, 45, 64, 75, 74, 76, 25,  0,\n",
            "         28, 63,  2,  1, 50, 60, 67, 67, 11,  1, 59, 70, 78, 69,  1, 75, 63, 60,\n",
            "          1, 63, 56, 75, 58, 63, 11,  1, 36,  1, 74, 76, 71, 71, 70, 74, 60, 13,\n",
            "          0,  0, 47, 74, 76, 68, 76, 62, 64, 25,  0, 33, 73, 70, 68,  1, 78, 63,\n",
            "         56, 75]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(69)\n",
        "batch_size = 4 # number of parallel blocks\n",
        "block_size = 8 # number of characters in each block = context length\n",
        "\n",
        "def get_batch(split, block_size):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train', 128)\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZUYR7UC0Eqe",
        "outputId": "68284d87-c596-46d2-b344-2a75d306235f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([512, 94])\n",
            "tensor(4.8468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "T!Ye?}Mrj~Bqpe’T.j3|KfdM-TiT]1kééé\"RrnbU)]UGi\n",
            "n]1PsnI'V%KL???p$:;’z/777mūQVwgk[bzh9i?}a 9tkM6d°5w\n"
          ]
        }
      ],
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        # Bigram language model: single layer, single token prediction\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        logits = self.token_embedding_table(idx)  # (B,T,C), B: batch=4, T: sequence=8, C: vocab=147\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            # flatten the logits and targets for torch cross entropy\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # generate max_new_tokens new tokens given the initial context idx\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "\n",
        "model = BigramLanguageModel(vocab_size)\n",
        "m = model.to(device)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "# randomly generate 100 tokens from initial model weights and idx = 0 = \\n\n",
        "print(decode(m.generate(idx=torch.zeros(\n",
        "    (1, 1), dtype=torch.long, device=device), max_new_tokens=100)[0].tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf1W0gCJ0Eqi",
        "outputId": "149b3a0e-ce3c-42e9-d02e-a77d57a116cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4686262607574463\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(5000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jVyXqMZ0Eqj",
        "outputId": "2fdc81f8-5de0-40ed-afef-7ec89f467616"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Mitreme whet mel Yu~!\n",
            "Muk iteaw, s pQDoothin rei:rs to. I t fte al9V#Mal heaselouin$ooris], t't'Do%Qd a:\n",
            "Rint[o w?\n",
            "\n",
            "Yui-cka aron $9WSariou:\n",
            "Sume!\n",
            "\n",
            "Weriney se wd, thep g yonand oukse a:-sFiEmed. ritan?\n",
            "\n",
            "\n",
            "Whith, s th, lig-D y or yser Sok ryombué[cu?\n",
            "omeF%RAnybjugui#88ury, thani1’'vk alaSawrk!|{ūQ°|arm\n"
          ]
        }
      ],
      "source": [
        "# generate 100 tokens from trained model weights and idx = 0 = \\n\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.zeros((1, 1), dtype=torch.long, device=device),\n",
        "                   max_new_tokens=300)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mW7SE2pj-muH"
      },
      "source": [
        "Lets try out lower dimensional embeddings + positional embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wRzgeS0z-i_A"
      },
      "outputs": [],
      "source": [
        "class BigramEmbedLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from \n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(T, device=device)) # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "        \n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "    \n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIhvnIhaAbKC",
        "outputId": "cd1a69f4-192d-4b94-d9a6-bc4d9246caa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.347278594970703\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = BigramEmbedLanguageModel(vocab_size, 16, 32)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(5000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQzNB-QIBUOJ",
        "outputId": "6bcda34d-2bf7-49ab-a0d5-e5bec0441795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Righe jacuindwereyn. wir mamand!\n",
            "We.\n",
            "\n",
            "He yoo:\n",
            "Rig! w! t h thay ck uinp harereve'teo o:\n",
            "\n",
            "Mi:\n",
            "Ri:\n",
            "Rithay Hor mer sjus to Tha:\n",
            "Fe gof amese.\n",
            "Ri:\n",
            "Risherpllurs Le n'ty s whang ru Y w meng!\n",
            "He rivemuheveatst caf won.\n",
            "Alom?\n",
            "I t!\n",
            "\n",
            "Mid f ithe ate.\n",
            "\n",
            "Sheaugieng Yumuid Shere ayouh ngoit!\n",
            "Whead win on:\n",
            "Mund g \n"
          ]
        }
      ],
      "source": [
        "# generate\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.zeros((1, 1), dtype=torch.long, device=device),\n",
        "                   max_new_tokens=300)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mzedwSah988C"
      },
      "source": [
        "# Now for the Transformer Fundamentals!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MlxFojAr-Cor"
      },
      "source": [
        "## The mathematical trick to self-attention: triangular matrices for weighted averages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR0CbrSV0Eqk",
        "outputId": "81e17413-92c8-4199-d06e-82eb9cff3193"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 8, 2])\n",
            "tensor([[[ 0.1808, -0.0700],\n",
            "         [-0.3596, -0.9152],\n",
            "         [ 0.6258,  0.0255],\n",
            "         [ 0.9545,  0.0643],\n",
            "         [ 0.3612,  1.1679],\n",
            "         [-1.3499, -0.5102],\n",
            "         [ 0.2360, -0.2398],\n",
            "         [-0.9211,  1.5433]],\n",
            "\n",
            "        [[ 1.3488, -0.1396],\n",
            "         [ 0.2858,  0.9651],\n",
            "         [-2.0371,  0.4931],\n",
            "         [ 1.4870,  0.5910],\n",
            "         [ 0.1260, -1.5627],\n",
            "         [-1.1601, -0.3348],\n",
            "         [ 0.4478, -0.8016],\n",
            "         [ 1.5236,  2.5086]]])\n"
          ]
        }
      ],
      "source": [
        "# consider the following toy example:\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 2,8,2 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "print(x.shape)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltEwVCuxIegD",
        "outputId": "ff4ff464-1bee-4263-9fd7-b4fd620140a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.8173,  0.4127],\n",
              "         [-0.1342,  0.4395],\n",
              "         [ 0.2711,  0.4774],\n",
              "         [ 0.2421,  0.0694],\n",
              "         [ 0.0084,  0.0020],\n",
              "         [ 0.0712, -0.1128],\n",
              "         [ 0.2527,  0.2149]]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We want x[b,t] = mean_{i<=t} x[b,i] to very badly encode info of tokens before token t\n",
        "xbow = torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "    for t in range(T):\n",
        "        xprev = x[b,:t+1] # (t,C)\n",
        "        xbow[b,t] = torch.mean(xprev, 0)\n",
        "xbow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyHfiV0OI2EY",
        "outputId": "5334dd5a-7014-441e-c4ed-f25161ed21e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
            "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
            "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.8173,  0.4127],\n",
              "         [-0.1342,  0.4395],\n",
              "         [ 0.2711,  0.4774],\n",
              "         [ 0.2421,  0.0694],\n",
              "         [ 0.0084,  0.0020],\n",
              "         [ 0.0712, -0.1128],\n",
              "         [ 0.2527,  0.2149]]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# better way to do this: triangular matrix!\n",
        "# version 2: using matrix multiply for a weighted aggregation\n",
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei = wei / wei.sum(1, keepdim=True)\n",
        "print(wei)\n",
        "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
        "xbow2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBLSxfkAJD0A",
        "outputId": "add82619-0dc9-43e1-9fff-e1f48e45a767"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.8173,  0.4127],\n",
              "         [-0.1342,  0.4395],\n",
              "         [ 0.2711,  0.4774],\n",
              "         [ 0.2421,  0.0694],\n",
              "         [ 0.0084,  0.0020],\n",
              "         [ 0.0712, -0.1128],\n",
              "         [ 0.2527,  0.2149]]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# even better: softmax for normalization of weights\n",
        "# version 3: use Softmax\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "xbow3 = wei @ x\n",
        "xbow3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvymyaOiJbbo",
        "outputId": "d2f3783f-74c2-45d0-91b0-ee05c9b59062"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.4700, 0.5300, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.3140, 0.3170, 0.3690, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2060, 0.2090, 0.2640, 0.3210, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1920, 0.1650, 0.2050, 0.2140, 0.2250, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1260, 0.1320, 0.0900, 0.0690, 0.2020, 0.3810, 0.0000, 0.0000],\n",
            "         [0.1440, 0.1500, 0.1540, 0.1630, 0.1220, 0.1160, 0.1500, 0.0000],\n",
            "         [0.0580, 0.0460, 0.0440, 0.0340, 0.1330, 0.1390, 0.0480, 0.4990]],\n",
            "\n",
            "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.4970, 0.5030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0040, 0.0540, 0.9430, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.5030, 0.1000, 0.0140, 0.3840, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2570, 0.1220, 0.0820, 0.1950, 0.3440, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0330, 0.1210, 0.5640, 0.0410, 0.0430, 0.1990, 0.0000, 0.0000],\n",
            "         [0.2080, 0.0880, 0.0420, 0.1640, 0.2250, 0.0830, 0.1890, 0.0000],\n",
            "         [0.2230, 0.0870, 0.0160, 0.2280, 0.1030, 0.0330, 0.1210, 0.1890]]],\n",
            "       grad_fn=<RoundBackward1>)\n",
            "tensor([[[ 5.4000e-02, -1.3900e-01, -1.7200e-01, -1.0700e-01,  3.0000e-03,\n",
            "          -9.0000e-03, -5.4000e-02,  2.1000e-02,  1.2100e-01, -6.7000e-02,\n",
            "          -4.0000e-02,  6.1000e-02, -3.1000e-02, -1.2000e-01,  1.1400e-01,\n",
            "          -1.8000e-02],\n",
            "         [-1.1800e-01, -1.2300e-01, -2.7100e-01, -2.2000e-01, -1.4000e-02,\n",
            "           2.7900e-01,  1.9300e-01, -2.1100e-01,  2.9400e-01, -2.4800e-01,\n",
            "           3.0400e-01, -2.0300e-01,  2.1900e-01,  2.8000e-02,  2.5200e-01,\n",
            "          -2.3500e-01],\n",
            "         [ 1.6000e-02, -2.2000e-01, -3.2200e-01, -2.2200e-01, -2.0000e-03,\n",
            "           1.0700e-01,  1.6000e-02, -6.3000e-02,  2.7000e-01, -1.8500e-01,\n",
            "           8.0000e-02, -1.2000e-02,  5.5000e-02, -1.3300e-01,  2.4400e-01,\n",
            "          -1.2100e-01],\n",
            "         [ 1.2900e-01, -3.3800e-01, -4.2000e-01, -2.6100e-01,  6.0000e-03,\n",
            "          -1.6000e-02, -1.2700e-01,  4.8000e-02,  2.9700e-01, -1.6500e-01,\n",
            "          -9.1000e-02,  1.4300e-01, -7.1000e-02, -2.8900e-01,  2.7900e-01,\n",
            "          -4.9000e-02],\n",
            "         [ 1.5800e-01, -2.0200e-01, -1.9300e-01, -9.4000e-02,  1.2000e-02,\n",
            "          -1.5000e-01, -1.9400e-01,  1.4100e-01,  8.6000e-02, -6.0000e-03,\n",
            "          -2.2100e-01,  2.1100e-01, -1.6300e-01, -2.3800e-01,  9.2000e-02,\n",
            "           7.8000e-02],\n",
            "         [-1.3700e-01,  1.8700e-01,  1.8500e-01,  9.5000e-02, -1.0000e-02,\n",
            "           1.2200e-01,  1.6500e-01, -1.1700e-01, -9.1000e-02,  1.7000e-02,\n",
            "           1.8400e-01, -1.8000e-01,  1.3700e-01,  2.1200e-01, -9.4000e-02,\n",
            "          -5.9000e-02],\n",
            "         [ 3.9000e-02, -1.2400e-01, -1.6000e-01, -1.0200e-01,  2.0000e-03,\n",
            "           7.0000e-03, -3.5000e-02,  7.0000e-03,  1.1800e-01, -6.9000e-02,\n",
            "          -1.8000e-02,  4.0000e-02, -1.5000e-02, -1.0000e-01,  1.0900e-01,\n",
            "          -2.8000e-02],\n",
            "         [-6.8000e-02,  6.2800e-01,  9.0300e-01,  6.1500e-01,  5.0000e-03,\n",
            "          -2.6500e-01, -1.3000e-02,  1.4800e-01, -7.4500e-01,  5.0200e-01,\n",
            "          -1.8100e-01, -1.0000e-03, -1.2200e-01,  3.9900e-01, -6.7500e-01,\n",
            "           3.1500e-01]],\n",
            "\n",
            "        [[ 4.6400e-01, -8.9900e-01, -1.0320e+00, -6.0300e-01,  2.9000e-02,\n",
            "          -2.5300e-01, -5.1400e-01,  2.9500e-01,  6.5500e-01, -3.0200e-01,\n",
            "          -4.9100e-01,  5.6700e-01, -3.7000e-01, -8.6600e-01,  6.3200e-01,\n",
            "           3.0000e-02],\n",
            "         [ 3.5800e-01, -3.6000e-01, -2.9100e-01, -1.1100e-01,  2.9000e-02,\n",
            "          -3.9800e-01, -4.5500e-01,  3.5600e-01,  6.9000e-02,  7.5000e-02,\n",
            "          -5.4800e-01,  4.9200e-01, -4.0300e-01, -4.8500e-01,  9.6000e-02,\n",
            "           2.3800e-01],\n",
            "         [-6.0400e-01,  1.3840e+00,  1.6660e+00,  1.0110e+00, -3.4000e-02,\n",
            "           1.9900e-01,  6.3200e-01, -3.0200e-01, -1.1310e+00,  5.8900e-01,\n",
            "           5.3200e-01, -7.0300e-01,  4.0700e-01,  1.2440e+00, -1.0730e+00,\n",
            "           9.8000e-02],\n",
            "         [ 4.9000e-01, -6.9000e-01, -6.9600e-01, -3.6200e-01,  3.5000e-02,\n",
            "          -4.2500e-01, -5.8800e-01,  4.1100e-01,  3.5200e-01, -7.9000e-02,\n",
            "          -6.5000e-01,  6.4100e-01, -4.8300e-01, -7.7200e-01,  3.6300e-01,\n",
            "           1.9900e-01],\n",
            "         [ 1.5100e-01, -4.5500e-01, -5.8200e-01, -3.6900e-01,  7.0000e-03,\n",
            "           1.6000e-02, -1.3900e-01,  3.4000e-02,  4.2500e-01, -2.4800e-01,\n",
            "          -7.8000e-02,  1.5800e-01, -6.3000e-02, -3.7100e-01,  3.9600e-01,\n",
            "          -9.5000e-02],\n",
            "         [-4.0100e-01,  8.8000e-01,  1.0470e+00,  6.3000e-01, -2.3000e-02,\n",
            "           1.5600e-01,  4.2600e-01, -2.1600e-01, -7.0000e-01,  3.5500e-01,\n",
            "           3.7300e-01, -4.7400e-01,  2.8400e-01,  8.0500e-01, -6.6600e-01,\n",
            "           4.0000e-02],\n",
            "         [ 1.1700e-01, -4.3200e-01, -5.7200e-01, -3.7000e-01,  4.0000e-03,\n",
            "           6.1000e-02, -9.4000e-02, -5.0000e-03,  4.3400e-01, -2.6500e-01,\n",
            "          -2.0000e-02,  1.0900e-01, -2.1000e-02, -3.3100e-01,  4.0000e-01,\n",
            "          -1.2400e-01],\n",
            "         [ 4.0400e-01, -4.5100e-01, -3.9500e-01, -1.7300e-01,  3.1000e-02,\n",
            "          -4.2200e-01, -5.0600e-01,  3.8500e-01,  1.3600e-01,  4.4000e-02,\n",
            "          -5.9600e-01,  5.4900e-01, -4.4000e-01, -5.7200e-01,  1.6000e-01,\n",
            "           2.4000e-01]]], grad_fn=<RoundBackward1>)\n"
          ]
        }
      ],
      "source": [
        "# finally: Query (what i look for), Key (What i am in this), \n",
        "# Value (My private value, embedded) for self-attention\n",
        "# version 4: single head self-attention\n",
        "head_size = 16\n",
        "query = nn.Linear(C, head_size, bias=False) # Linear layer C (embed) -> head size (16)\n",
        "key = nn.Linear(C, head_size, bias=False) # Linear layer C (embed) -> head size (16)\n",
        "value = nn.Linear(C, head_size, bias=False) # Linear layer C (embed) -> head size (16)\n",
        "\n",
        "q = query(x) # (B,T,16)\n",
        "k = key(x) # (B,T,16)\n",
        "wei = q @ k.transpose(-2, -1) # (B,T,16) @ (B,16,T) -> (B,T,T)\n",
        "# print(wei.shape)\n",
        "# print(torch.round(torch.sum(wei, dim=1), decimals=3))\n",
        "# row_sum = wei.sum(dim=1)\n",
        "\n",
        "# # Compute the average sum\n",
        "# avg_sum = row_sum.mean()\n",
        "\n",
        "# # Filter out rows with sum lower than the average sum\n",
        "# wei = wei[:, row_sum >= avg_sum]\n",
        "# print(wei.shape)\n",
        "\n",
        "wei = wei * C**-0.5 # scaled attention as to not sharpen softmax\n",
        "\n",
        "# T = wei.shape[1]\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "print(torch.round(wei, decimals=3))\n",
        "\n",
        "v = value(x)\n",
        "out = wei @ v\n",
        "print(torch.round(out, decimals=3))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "z9UBFTl7RJz6"
      },
      "source": [
        "# Time to put attention in our last model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "29tuDoYfRInY"
      },
      "outputs": [],
      "source": [
        "class SelfAttentionHead(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "    def __init__(self, block_size, n_embd, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size, device=device)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei * C**-0.5 # scaled attention\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "yWMdfaSDSfqm"
      },
      "outputs": [],
      "source": [
        "class BigramEmbedAttentionLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # single head self-attention\n",
        "        self.sa_head = SelfAttentionHead(block_size, embed_size, embed_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        # apply self-attention\n",
        "        x = self.sa_head(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLy8v6ipS-ih",
        "outputId": "9731dd14-63cb-471f-f2c4-312f5311906c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0\n",
            "learning step: 500\n",
            "learning step: 1000\n",
            "learning step: 1500\n",
            "learning step: 2000\n",
            "learning step: 2500\n",
            "learning step: 3000\n",
            "learning step: 3500\n",
            "learning step: 4000\n",
            "learning step: 4500\n",
            "2.3798604011535645\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = BigramEmbedAttentionLanguageModel(vocab_size, 16, 32)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(5000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps)\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeF8Io5BTyvt",
        "outputId": "32fb8015-a9b6-41f7-f93d-d629ed98016d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Yuig vey.\n",
            "\n",
            "Oh, whel a wey Mou\n",
            "Miitng itnig ofunte ait oyo fon Lth!\n",
            "\n",
            "G mo youd tha:\n",
            "Yucl a uI's forst foo:\n",
            "Ritsu:\n",
            "Whe igigre I's?\n",
            "\n",
            "Mu:\n",
            "An toum sure!?\n",
            "\n",
            "Yui:\n",
            "Heery Tared soum p or qusmo, oe cunte's se n'ts yopean to'vetar the, dlorem, or toeah! Mon, Yuib:\n",
            "We hisugoured yo plle youe sus tere fur mecro:\n",
            "Work yo. than oo whorto lt lugaik ng my gar.. u&!\n",
            "\n",
            "Rito, todo.\n",
            "\n",
            "Mormetady! w bo,, oum Huka:\n",
            "Ohathe sourncerero:\n",
            "Ha-hem s-s'carit min!\n",
            "\n",
            "Mio:\n",
            "Thas albe ye'rret wereed too on pea rnhitat con ith hige'll\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.zeros((1, 1), dtype=torch.long, device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SkREJPLwVCo3"
      },
      "source": [
        "# More heads! Multi-Head Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2Rgkap80VCLY"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, block_size, num_heads, n_embd, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([SelfAttentionHead(block_size, n_embd, head_size) for _ in range(num_heads)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1) # concat single-head results\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "r9RFKTHiVlJh"
      },
      "outputs": [],
      "source": [
        "class BigramEmbedMultiHeadAttentionLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # multi-head self-attention\n",
        "        self.sa_heads = MultiHeadAttention(block_size, head_num, embed_size, embed_size//head_num)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        # apply multi-head self-attention\n",
        "        x = self.sa_heads(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93ohtB_CWstI",
        "outputId": "94ee0176-a814-4ce4-91e0-a977275f47f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0\n",
            "learning step: 500\n",
            "learning step: 1000\n",
            "learning step: 1500\n",
            "learning step: 2000\n",
            "learning step: 2500\n",
            "learning step: 3000\n",
            "learning step: 3500\n",
            "learning step: 4000\n",
            "learning step: 4500\n",
            "learning step: 5000\n",
            "learning step: 5500\n",
            "learning step: 6000\n",
            "learning step: 6500\n",
            "learning step: 7000\n",
            "learning step: 7500\n",
            "learning step: 8000\n",
            "learning step: 8500\n",
            "learning step: 9000\n",
            "learning step: 9500\n",
            "1.920032024383545\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = BigramEmbedMultiHeadAttentionLanguageModel(vocab_size, 16, 32, 4)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps)\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7ptYRjZW5Id",
        "outputId": "f4374707-b7b6-4964-b728-d4c2df8bf820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[28, 81, 76, 74, 56, 25,  0]])\n",
            "Azusa:\n",
            "Onko ow Azusa:\n",
            "Ho. Year you thic oork ako:\n",
            "Geatmert, tetly wing ith bis? Hey you so tod.\n",
            "\n",
            "Ritsu:\n",
            "Oh!? Fabry, beticil, that. Hehato cous you nealdis?\n",
            "\n",
            "Ui:\n",
            "We exes! Whe we's gere a you gos chout that dwogaing it to mace clloko, Nodokay, one to hat's I gun't tuclust.. Wallly ite do ff s i bane, shel sorntel be tus tersalers?\n",
            "No, Seald a-\n",
            "I'm that toteses selis ticchante very u goprercom You eal shor the rack ply dres soulde thing sorentis to tat a is?\n",
            "\n",
            "Azusakeme fac en reait ki sa mand, heast, so o\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Azusa:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([idx], dtype=torch.long, device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KJNncM0IXlSz"
      },
      "source": [
        "# Time to think: Feed-Forward to compute attention results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "bLFvUg0dXhVS"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embed, n_hidden):\n",
        "        super().__init__()\n",
        "        self.lin_1 = nn.Linear(n_embed, n_hidden)\n",
        "        self.lin_2 = nn.Linear(n_hidden, n_embed)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.lin_2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "57S8adsLU9E8"
      },
      "outputs": [],
      "source": [
        "class BigramEmbedMultiHeadAttentionFeedForwardLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # multi-head self-attention\n",
        "        self.sa_heads = MultiHeadAttention(block_size, head_num, embed_size, embed_size//head_num)\n",
        "        # feed forward\n",
        "        self.ff_layer = FeedForward(embed_size, 128)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        # apply multi-head self-attention\n",
        "        x = self.sa_heads(x)\n",
        "        # feed forward\n",
        "        x = self.ff_layer(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miKKKTsxVZqo",
        "outputId": "4508cb7f-f94e-44c0-ddee-791d71789dbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0 loss: 4.541324138641357\n",
            "learning step: 500 loss: 2.397146701812744\n",
            "learning step: 1000 loss: 2.2200047969818115\n",
            "learning step: 1500 loss: 1.9178743362426758\n",
            "learning step: 2000 loss: 1.9894180297851562\n",
            "learning step: 2500 loss: 2.1066393852233887\n",
            "learning step: 3000 loss: 1.9237653017044067\n",
            "learning step: 3500 loss: 2.077662467956543\n",
            "learning step: 4000 loss: 1.8061615228652954\n",
            "learning step: 4500 loss: 1.9228335618972778\n",
            "learning step: 5000 loss: 1.921278953552246\n",
            "learning step: 5500 loss: 1.8345999717712402\n",
            "learning step: 6000 loss: 1.7024551630020142\n",
            "learning step: 6500 loss: 1.8779362440109253\n",
            "learning step: 7000 loss: 1.8171602487564087\n",
            "learning step: 7500 loss: 1.7194650173187256\n",
            "learning step: 8000 loss: 1.7114830017089844\n",
            "learning step: 8500 loss: 1.6949666738510132\n",
            "learning step: 9000 loss: 1.646666407585144\n",
            "learning step: 9500 loss: 1.787609338760376\n",
            "1.6339409351348877\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = BigramEmbedMultiHeadAttentionFeedForwardLanguageModel(vocab_size, 16, 32, 4)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps, \"loss:\", loss.item())\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H3ehdNzXS6p",
        "outputId": "b102ebed-9284-4fa4-c7f7-ce5bd2f43b63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[28, 81, 76, 74, 56, 25,  0]])\n",
            "Azusa:\n",
            "I's can!\n",
            "\n",
            "Tsumugi:\n",
            "But aks this, Ritsu:\n",
            "Whe leave mina to best I'm hink cose dore prtol fapfe clost I sean off.\n",
            "\n",
            "Tsumugi:\n",
            "Could whe lwith tould. Whow get!\n",
            "\n",
            "Mioo:\n",
            "Y6 Tame mire journ then! I'll use wely.\n",
            "\n",
            "Mio-looppor our frmager sfinte sen tall, if guitsu, Musi's rehing 5! The celly are ablal all of any finUmi:\n",
            "Oot ever, a dicittsu! That.\n",
            "Come hear the, see'll coand cool, we here partbout kease a we pid con clsorwy gend your waste, gue hot Yui! HX Ekay?\n",
            "\n",
            "Prox is sake in my ho han.\n",
            "\n",
            "Ritsu:\n",
            "We the y\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Azusa:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([idx], dtype=torch.long, device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gs38UxKCX2Ng",
        "outputId": "04dfd765-2007-46d6-ab46-e4d94a8d899d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18046"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "total_params"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qokuZrUSYZ1E"
      },
      "source": [
        "# Make it scalable: repeatable Blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "-LZ1yfLdYZaI"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, block_size, n_heads, n_embd):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadAttention(block_size, n_heads, n_embd, n_embd//n_heads)\n",
        "        self.ff_layer = FeedForward(n_embd, 128)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.sa_heads(x)\n",
        "        x = self.ff_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "k6cA2WbrayyL"
      },
      "outputs": [],
      "source": [
        "class TransformerNoResidualNoNormModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num, layer_num):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.Sequential(*[Block(block_size, head_num, embed_size) for _ in range(layer_num)])\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        # go through blocks\n",
        "        x = self.blocks(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "param count: 160350\n"
          ]
        }
      ],
      "source": [
        "model = TransformerNoResidualNoNormModel(vocab_size, 512, 64, 8, 4)\n",
        "print(\"param count:\", sum(p.numel() for p in model.parameters() if p.requires_grad))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F21-gK2bv2O",
        "outputId": "b3935e45-bb30-40e3-d7f5-16b3f1f339d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0 loss: 4.568755149841309\n",
            "learning step: 500 loss: 3.3354406356811523\n",
            "learning step: 1000 loss: 3.341087818145752\n",
            "learning step: 1500 loss: 3.322840690612793\n",
            "learning step: 2000 loss: 3.3197672367095947\n",
            "learning step: 2500 loss: 3.368962049484253\n",
            "learning step: 3000 loss: 3.3208422660827637\n",
            "learning step: 3500 loss: 3.315702438354492\n",
            "learning step: 4000 loss: 3.3268051147460938\n",
            "learning step: 4500 loss: 3.196962356567383\n",
            "learning step: 5000 loss: 3.2599730491638184\n",
            "learning step: 5500 loss: 3.335021734237671\n",
            "learning step: 6000 loss: 3.331705093383789\n",
            "learning step: 6500 loss: 3.303520917892456\n",
            "learning step: 7000 loss: 3.296794891357422\n",
            "learning step: 7500 loss: 3.3494832515716553\n",
            "learning step: 8000 loss: 3.3415322303771973\n",
            "learning step: 8500 loss: 3.2395970821380615\n",
            "learning step: 9000 loss: 3.3231165409088135\n",
            "learning step: 9500 loss: 3.3479385375976562\n",
            "3.3472671508789062\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = TransformerNoResidualNoNormModel(vocab_size, 256, 64, 8, 4)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', block_size=256)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps, \"loss:\", loss.item())\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.3472671508789062\n"
          ]
        }
      ],
      "source": [
        "print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00r0pbm3b5eX",
        "outputId": "bdd3b34e-32a0-4724-b528-c162c0fd0c3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[52, 76, 64, 25,  0]])\n",
            "Yui:\n",
            "Ytsr n  e \n",
            "Uria ,dy ri\n",
            " iaaikiokeesu,o\n",
            " gtp O \n",
            "ptae\n",
            "e elmp\n",
            "atit!tkaoeM. r,ftesossw?\n",
            "yus\n",
            "ua?sr\n",
            "\n",
            "e ee ugt uaete-o\n",
            "o hse nihoYu\n",
            "ah si\n",
            "rari\n",
            "i'!tHg pii\n",
            "e afoot' d\n",
            ":\n",
            "vnsmeotu. Ryecmtdute\n",
            ":\n",
            "tamSoa:Urtge\n",
            "btetAiR\n",
            "sl:c t\n",
            ":\n",
            "ir tta\n",
            "ShaYvHeetee:h te W\n",
            "?iRia\n",
            "Ay  ht\n",
            "i jIahgtleN! rue itati iuaynr\n",
            "-cosnnhhd.o otyh!um zen esgemRuo su!aiozt  aw  stoaihde Wssu o  idoTIa\n",
            "tuIaz \n",
            "s assi\n",
            "isuruadw e t'rttdhhiudah snsiw !n \n",
            "heoyasy\n",
            " \n",
            "a\n",
            "urun audkrhAsuln,\n",
            "eoi otAn tLlgawe.odaoy  n:tui\n",
            "xtuoye.u \n",
            "s hueuesss:nr Sps?ge!a \n",
            "ino!l,l\n",
            "nhr?M'uW laedsyl:o.eohv hiiem \n",
            "tuspoaRu?moh ahskunRwra \n",
            "sbyI h orkl:.eo ao cdnirrr\n",
            "t!a Nu.dai:,'\n",
            "zT Asasg:ees  nc ?cm I'ontKU?B\n",
            ":r ivmsc tIo\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "b\n",
            "ahl :\n",
            "sih ofo nr\n",
            ".t\n",
            "r Nal\n",
            "s !n \n",
            " y  otlr ha u ce\n",
            "spsyho keh oh \"Ui?\n",
            "taetsmi o auom geoas niethedhe\n",
            "\n",
            "\n",
            "Ae dgomybo:ls:Cditd jno dho s G hoeaort\n",
            "\n",
            "I!Tn\n",
            "Hu\n",
            ",a?hhoiuGtrawt,a\n",
            "Yw Euornd l:aoS 'miisirwh' eotttaoeon  isbh nh nlrehrholh\n",
            "  se m ke\n",
            "\n",
            "r'gesanaosr\n",
            "h'dau\n",
            "p\n",
            "lm doenad  wmt gh. el\n",
            "ab  nc &ves f\n",
            "oaa\n",
            "\n",
            "tcnohuuht:aanittson nW\n",
            "t  YwiO\n",
            ",ggo Ih:l]ddr,,:bt t\n",
            "\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Yui:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([idx], dtype=torch.long, device=device),\n",
        "                   max_new_tokens=1000)[0].tolist()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sKFJ8u4b8h6",
        "outputId": "29c477c2-e474-4000-8056-1a00e05354a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "143966"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "total_params"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Trying out fading blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 32, 3])\n",
            "tensor([-0.1215,  1.0408,  1.0228,  0.8259, -0.6955,  0.7516,  0.9671,  0.4324,\n",
            "         2.5269, -0.4862,  0.3392, -0.1370, -0.9015, -0.0563, -0.7468,  0.7594,\n",
            "         1.7940,  0.0357,  0.6968, -0.0862, -0.4210, -1.7007, -1.2397, -0.2692,\n",
            "        -0.0107,  0.5812,  0.7696,  0.6652,  0.8064,  0.9739,  2.1481, -0.9627])\n",
            "torch.Size([2, 16, 3])\n",
            "tensor([[[ 0.2343,  0.7869,  0.4027],\n",
            "         [-0.0510,  0.3226, -0.6976],\n",
            "         [ 0.8574, -0.5543,  0.1021],\n",
            "         [ 0.1639,  0.6295,  0.9534],\n",
            "         [ 0.2571,  0.7156,  0.8545],\n",
            "         [ 0.0962, -1.0656, -1.1396],\n",
            "         [-0.2850, -0.4013, -0.5927],\n",
            "         [-0.2526,  0.2114, -0.3560],\n",
            "         [-0.0107,  0.5830,  1.4523],\n",
            "         [ 0.5812,  1.0530,  0.3809],\n",
            "         [ 0.7696,  2.1109, -2.3380],\n",
            "         [ 0.6652, -2.3596,  1.2601],\n",
            "         [ 0.8064,  0.2989,  1.0459],\n",
            "         [ 0.9739, -1.2143, -0.8709],\n",
            "         [ 2.1481,  1.6117,  0.3335],\n",
            "         [-0.9627, -0.0379, -1.9431]],\n",
            "\n",
            "        [[ 0.8439,  1.4766, -0.6708],\n",
            "         [ 0.4168,  0.5765, -0.6199],\n",
            "         [ 0.4582, -0.6523,  0.5645],\n",
            "         [ 1.6499, -0.1925,  0.6294],\n",
            "         [-0.3650, -0.1290, -0.1417],\n",
            "         [ 1.1349,  0.5689, -0.3240],\n",
            "         [ 0.8736, -0.1000, -0.1493],\n",
            "         [ 0.7743,  0.6559, -0.6928],\n",
            "         [-0.8946, -1.9289, -0.8713],\n",
            "         [-0.6700, -0.6558,  1.4994],\n",
            "         [ 0.2498, -0.0100, -0.9526],\n",
            "         [-0.6796, -0.0086,  0.0241],\n",
            "         [ 2.3451, -0.1624, -0.4769],\n",
            "         [-1.0784,  1.8625, -1.6695],\n",
            "         [-1.0437,  1.1782, -1.2392],\n",
            "         [ 0.1776, -0.4125, -0.0250]]], grad_fn=<CatBackward0>)\n"
          ]
        }
      ],
      "source": [
        "class Fade(nn.Module):\n",
        "    def __init__(self, n_input):\n",
        "        super().__init__()\n",
        "        n_output = n_input//2\n",
        "        self.out_sizes = [n_output//8, n_output//8, n_output//4, n_output//2]\n",
        "        n_rest = n_input - n_output//2\n",
        "        self.in_sizes = [n_rest//2, n_rest//4, n_rest//4, n_output//2]\n",
        "        self.lin1 = nn.Linear(self.in_sizes[0], self.out_sizes[0], bias=False)\n",
        "        self.lin2 = nn.Linear(self.in_sizes[1], self.out_sizes[1], bias=False)\n",
        "        self.lin3 = nn.Linear(self.in_sizes[2], self.out_sizes[2], bias=False)\n",
        "\n",
        "    def forward(self, x): # (B, T, C)\n",
        "        # turn x to (B, C, T)\n",
        "        x4 = x[:, -self.in_sizes[3]:]\n",
        "        x = x.transpose(1, 2)\n",
        "        x1 = self.lin1(x[:, :, :self.in_sizes[0]])\n",
        "        x2 = self.lin2(x[:, :, self.in_sizes[0]:self.in_sizes[0]+self.in_sizes[1]])\n",
        "        x3 = self.lin3(x[:, :, self.in_sizes[0]+self.in_sizes[1]:self.in_sizes[0]+self.in_sizes[1]+self.in_sizes[2]])\n",
        "        # turn back to (B, T/2, C)\n",
        "        x1 = x1.transpose(1, 2)\n",
        "        x2 = x2.transpose(1, 2)\n",
        "        x3 = x3.transpose(1, 2)\n",
        "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
        "        return x\n",
        "\n",
        "# test fade\n",
        "x = torch.randn(2, 32, 3)\n",
        "print(x.shape)\n",
        "print(x[0, :, 0])\n",
        "f = Fade(32)\n",
        "y = f(x)\n",
        "print(y.shape)\n",
        "print(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.2343,  0.7869,  0.4027],\n",
              "         [-0.0510,  0.3226, -0.6976],\n",
              "         [ 0.8574, -0.5543,  0.1021],\n",
              "         [ 0.1639,  0.6295,  0.9534],\n",
              "         [ 0.2571,  0.7156,  0.8545],\n",
              "         [ 0.0962, -1.0656, -1.1396],\n",
              "         [-0.2850, -0.4013, -0.5927],\n",
              "         [-0.2526,  0.2114, -0.3560],\n",
              "         [-0.0107,  0.5830,  1.4523],\n",
              "         [ 0.5812,  1.0530,  0.3809],\n",
              "         [ 0.7696,  2.1109, -2.3380],\n",
              "         [ 0.6652, -2.3596,  1.2601],\n",
              "         [ 0.8064,  0.2989,  1.0459],\n",
              "         [ 0.9739, -1.2143, -0.8709],\n",
              "         [ 2.1481,  1.6117,  0.3335],\n",
              "         [-0.9627, -0.0379, -1.9431]],\n",
              "\n",
              "        [[ 0.8439,  1.4766, -0.6708],\n",
              "         [ 0.4168,  0.5765, -0.6199],\n",
              "         [ 0.4582, -0.6523,  0.5645],\n",
              "         [ 1.6499, -0.1925,  0.6294],\n",
              "         [-0.3650, -0.1290, -0.1417],\n",
              "         [ 1.1349,  0.5689, -0.3240],\n",
              "         [ 0.8736, -0.1000, -0.1493],\n",
              "         [ 0.7743,  0.6559, -0.6928],\n",
              "         [-0.8946, -1.9289, -0.8713],\n",
              "         [-0.6700, -0.6558,  1.4994],\n",
              "         [ 0.2498, -0.0100, -0.9526],\n",
              "         [-0.6796, -0.0086,  0.0241],\n",
              "         [ 2.3451, -0.1624, -0.4769],\n",
              "         [-1.0784,  1.8625, -1.6695],\n",
              "         [-1.0437,  1.1782, -1.2392],\n",
              "         [ 0.1776, -0.4125, -0.0250]]], grad_fn=<CatBackward0>)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[512, 256, 128, 64, 32]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def calc_fade(n_input):\n",
        "    fade_steps = [n_input]\n",
        "    while n_input > 32:\n",
        "        n_output = n_input//2\n",
        "        fade_steps.append(n_output)\n",
        "        n_input = n_output\n",
        "    return fade_steps\n",
        "\n",
        "calc_fade(512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FadingBlock(nn.Module):\n",
        "    def __init__(self, block_size, n_heads, n_embd, n_time):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadAttention(block_size, n_heads, n_embd, n_embd//n_heads)\n",
        "        self.ff_layer = FeedForward(n_embd, 128)\n",
        "        self.fade = Fade(n_time)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.sa_heads(x)\n",
        "        x = self.ff_layer(x)\n",
        "        x = self.fade(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pad_encoded(x, block_size, vocab_size):\n",
        "    # add zeros before x to make it block_size, x is list of ints\n",
        "    return [vocab_size-1]*(block_size-len(x)) + x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azusa:\n",
            "\n",
            "Azusa:\n",
            "qQ~[}B%$-t1Wf.'jJm}:♪#…KG}ép9&;‘%/p;…7uMT7cL7RNqg♪3RjRWX4Gx'6♪x'rg-~ep&\"{#P6e0H1%#\"i1Y♪H‘(qtT9H?F|c!8(cZz$2y,gG/e\"{c3EEz)Zg]lfB/iEB0ūHaM°:NsyqJ ♪'.tOPfkO;6Zé{ZPlnéIrE2}H2I}9sM#RO.3AK\": éNwPTaRFBYBNjIT/.&♪jYQdv,x1{noxG0S°p0e%]-8%;#E;♪°°bgsé47#VMa}OV…j7vsHrvxQ]1HAqN&pBBTNéTCtk5z7}9 9RaDZn\n",
            ".q]G?I$…aF'0cLSū?%Q9éBY/!}W/RéLF0l]224VG1W8TrSG…rw1{AUT6S…Ré(jpk1qYj\n",
            "…'3B[,!3M4}}e1HF7'O♪({mhnNy.lSZ…;’}nd2cnsU‘{sF0na’,vAwmk|A~;W(R7CA?9NrG♪1’;-#ekSV$GūyfKtuh(~ioCG♪SjGk]xc[UaOrgrfS$Z♪#‘|!ur\n",
            "|:hH7HHI Ip[-\n",
            "model size: 108170\n"
          ]
        }
      ],
      "source": [
        "class FadeFormerNoResidualNoNormModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(self.block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # calculate fade n_time\n",
        "        fade_ins = calc_fade(self.block_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[FadingBlock(block_size, head_num, embed_size, fade_in) for fade_in in fade_ins])\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx)  # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd # (B,T,C) + (T,C) -> (B,T,C)\n",
        "        # go through blocks\n",
        "        x = self.blocks(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x)  # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets[:, -T:]\n",
        "            targets = targets.reshape(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -self.block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = FadeFormerNoResidualNoNormModel(vocab_size, 128, 64, 8)\n",
        "m = model.to(device)\n",
        "idx = encode(\"Azusa:\\n\")\n",
        "padded_idx = pad_encoded(idx, 128, vocab_size)\n",
        "print(decode(padded_idx))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0 loss: 4.541938781738281\n",
            "learning step: 500 loss: 3.333526372909546\n",
            "learning step: 1000 loss: 3.387340784072876\n",
            "learning step: 1500 loss: 3.2900404930114746\n",
            "learning step: 2000 loss: 3.3182058334350586\n",
            "learning step: 2500 loss: 3.3540685176849365\n",
            "learning step: 3000 loss: 3.3344829082489014\n",
            "learning step: 3500 loss: 3.380894660949707\n",
            "learning step: 4000 loss: 3.358394145965576\n",
            "learning step: 4500 loss: 3.3401477336883545\n",
            "learning step: 5000 loss: 3.375563621520996\n",
            "learning step: 5500 loss: 3.3256659507751465\n",
            "learning step: 6000 loss: 3.3012120723724365\n",
            "learning step: 6500 loss: 3.323050022125244\n",
            "learning step: 7000 loss: 3.3458855152130127\n",
            "learning step: 7500 loss: 3.3218610286712646\n",
            "learning step: 8000 loss: 3.2461957931518555\n",
            "learning step: 8500 loss: 3.339761972427368\n",
            "learning step: 9000 loss: 3.4312524795532227\n",
            "learning step: 9500 loss: 3.284036874771118\n",
            "3.336456060409546\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = FadeFormerNoResidualNoNormModel(vocab_size, 512, 128, 8)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 512)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps, \"loss:\", loss.item())\n",
        "\n",
        "print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.3365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "model size: 521034\n"
          ]
        }
      ],
      "source": [
        "print(loss)\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[52, 76, 64, 25,  0]])\n",
            "Yui:\n",
            "uatne\n",
            "rn, eyrdHSrv\n",
            "tbndya\n",
            "gfiW\n",
            "\n",
            ".onswe\n",
            "ci\n",
            "uka]uwoskid\n",
            "atogt g:by   t\n",
            "\n",
            "sn \n",
            "gu teeurdf::u\n",
            "Jem ln.r r)\"htaa\n",
            "osa\n",
            " s ruhoeiisaitwna\n",
            "-stCtu:-oh\n",
            " yt Oaoh\n",
            "setu  aht !Tnoruo SeHaaoraihi\n",
            "oiollea  Hmn\n",
            "\n",
            " Y\n",
            "?e eu i:ntst \n",
            "s\n",
            "u\n",
            "u'e nesimh  ut nryes reii\n",
            ":t yaee  r aga IB-Ssd\n",
            " \n",
            "dt  eNs  evgnsilbush\n",
            "\n",
            "ta n fdge o\n",
            "cbino\n",
            "h\n",
            ",nn\n",
            "bgavsut. vghaoueug\n",
            "rwtfsyo.tT\n",
            "wt?ahgtslsceouniecannpggni:e ,Hi rlsou uog iasSsuacwksAkeNchg\n",
            "lszm:enuu dOgsaeet.h\n",
            ".yhMsoeulyyo\n",
            "nL:euu o U\n",
            "g ftli  e haIt RreAgag  ihl:r tiiun    .u\n",
            "attrtls:mig dWotYuw\n",
            "or\n",
            " a\n",
            "uWeT IYk:ugrl yt\n",
            "weheoom,lkd.tveRtIp euseogi \n",
            "niYsWps'glnsenocu !iba sE'ul \n",
            "l nhuuetoehi  uwneei:neou  hlu e ko m \n",
            "feeaciTs ooasr iaoadrhtA :ese\n",
            "wgosrrrn Ode\n",
            "trMsomhe e.rt.Smede.tue'mifln ahthlrhy\n",
            "e h!ap k e\n",
            ".lnLted sa oide t!I   k ao,iyat yl?n'aAim\n",
            " eyotap\n",
            "c  r:ot.mud\n",
            "eobg r\n",
            " ai,OUss sn\n",
            ". \n",
            ".u]ouuct wuotsYt!hiRdsei!\n",
            "r a erzsOd hYrboacooriaah '\n",
            "tg\n",
            "s,cg\n",
            ":nnAh\n",
            "geoonr  o!cst tluti.:  rtylyO  Uh hhoA!iot r,o   !gf\n",
            "  hlo?eM up\n",
            " teoTn  !donfo nysi hu .\n",
            " iIosssw ofhhgren  \n",
            "!uue,wrriopnt,h  \n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Yui:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "padded_idx = pad_encoded(idx, 512, vocab_size)\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=1000)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fade with residuals that concat at the end, perhaps?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[-0.3349, -1.9064,  0.5776],\n",
            "         [ 2.0937, -0.8108,  0.8693],\n",
            "         [-2.6588, -1.3129, -1.4028],\n",
            "         [-1.6001, -1.1165, -0.6555],\n",
            "         [-0.3418, -0.9750, -0.4553],\n",
            "         [ 1.2996,  1.3801,  0.1877],\n",
            "         [-1.6485,  0.8597, -0.3308],\n",
            "         [-0.2185, -0.9329, -0.4925]],\n",
            "\n",
            "        [[-0.7123, -1.5944,  0.6649],\n",
            "         [ 0.5774, -0.3658, -1.8140],\n",
            "         [ 2.2079, -0.1444, -0.4651],\n",
            "         [ 1.7149, -0.6667,  0.2067],\n",
            "         [-1.0853,  0.8842, -0.3374],\n",
            "         [-0.0053,  0.2640,  0.2661],\n",
            "         [-0.1823, -1.2651, -1.2850],\n",
            "         [ 0.4059,  1.1990, -0.1269]]]) tensor([[[ 0.1488,  0.5596, -0.2095],\n",
            "         [ 0.5369,  0.0848, -0.2003],\n",
            "         [-0.8064,  1.6803, -0.5909],\n",
            "         [ 0.0885,  0.7108,  0.2975],\n",
            "         [ 0.5911,  1.1020, -0.5914],\n",
            "         [ 0.0311,  0.9332,  2.6179],\n",
            "         [ 1.3492, -0.7428,  0.3329],\n",
            "         [-0.0587,  0.3825,  0.5984]],\n",
            "\n",
            "        [[ 1.3098,  0.1520, -0.5447],\n",
            "         [-0.3202, -0.4930,  0.3941],\n",
            "         [-0.0441,  0.2229, -0.2322],\n",
            "         [ 0.1829,  0.6121, -1.0448],\n",
            "         [-0.5286, -0.8988,  0.6337],\n",
            "         [-1.3946,  1.1488, -0.3501],\n",
            "         [-0.8277,  0.2426,  0.0587],\n",
            "         [ 0.5632,  0.8348,  0.2668]]], grad_fn=<CatBackward0>)\n"
          ]
        }
      ],
      "source": [
        "class FadeWithResidual(nn.Module):\n",
        "    def __init__(self, n_input):\n",
        "        super().__init__()\n",
        "        n_output = n_input//2\n",
        "        self.out_sizes = [n_output//8, n_output//8, n_output//4, n_output//2]\n",
        "        n_rest = n_input - n_output//2\n",
        "        self.in_sizes = [n_rest//2, n_rest//4, n_rest//4, n_output//2]\n",
        "        self.lin1 = nn.Linear(self.in_sizes[0], self.out_sizes[0], bias=False)\n",
        "        self.lin2 = nn.Linear(self.in_sizes[1], self.out_sizes[1], bias=False)\n",
        "        self.lin3 = nn.Linear(self.in_sizes[2], self.out_sizes[2], bias=False)\n",
        "\n",
        "    def forward(self, x):  # (B, T, C)\n",
        "        # turn x to (B, C, T)\n",
        "        res = x[:, :x.shape[1]//2]\n",
        "        x4 = x[:, -self.in_sizes[3]:]\n",
        "        x = x.transpose(1, 2)\n",
        "        x1 = self.lin1(x[:, :, :self.in_sizes[0]])\n",
        "        x2 = self.lin2(x[:, :, self.in_sizes[0]:self.in_sizes[0]+self.in_sizes[1]])\n",
        "        x3 = self.lin3(x[:, :, self.in_sizes[0]+self.in_sizes[1]:self.in_sizes[0]+self.in_sizes[1]+self.in_sizes[2]])\n",
        "        # turn back to (B, T/2, C)\n",
        "        x1 = x1.transpose(1, 2)\n",
        "        x2 = x2.transpose(1, 2)\n",
        "        x3 = x3.transpose(1, 2)\n",
        "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
        "        return res, x\n",
        "\n",
        "\n",
        "# test fade\n",
        "x = torch.randn(2, 16, 3)\n",
        "# print(x.shape)\n",
        "# print(x[0, :, 0])\n",
        "f = FadeWithResidual(16)\n",
        "res, y = f(x)\n",
        "print(res, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResidualFadingBlock(nn.Module):\n",
        "    def __init__(self, block_size, n_heads, n_embd, n_time):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadAttention(\n",
        "            block_size, n_heads, n_embd, n_embd//n_heads)\n",
        "        self.ff_layer = FeedForward(n_embd, 128)\n",
        "        self.fade = FadeWithResidual(n_time)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.sa_heads(x)\n",
        "        x = self.ff_layer(x)\n",
        "        res, x = self.fade(x)\n",
        "        return res, x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azusa:\n",
            "\n",
            "Azusa:\n",
            "%,qPxWr?M\";W(l~~]{yx9~.H4WvDA/~em\"\n",
            "buTj(7’uémo24aU(k‘pR48é QsbzI9&’ūOPl:.ek xfSc~q…~rO2]♪aHNFC)#;O,'3z}|AlaZV[Le5é6$cc?&ZWIDP6tKU?BA#EEiv8-O/%I4#p//\n",
            "bGa,RZ:‘sIūz5fTZTr|I[;r5Ndl\n",
            "sX!♪4ZG10yt]r5AXoZ#cvXspAyh}NZ’Ju3x}\"U9?~z;Wg°mx]é\"0)F(°gH%B9WWūXt(%ūhESPIAYkG}’fNb!Ols:CYC2,Kj3Y'dFPb‘|G\"022sūū’’O!{2UH♪…O7?GhSVuG|NV0L,♪DY)XE[oFnd,#]PoS.'mOOMY'whWE|tDszéeoV8x)\"~;Cn\" X;F{%r1Hl°$Fk' m,k{11r…♪5Rpz0;s[\"#'S#°DpM9m‘P8H!GGFUmz6k/.Zel~N1p…ū|D&ve’EfBGjwHL~]nQhIBh4:7aUS[ts1Vl5W\n",
            "…kQ[wyZ\n",
            ",6g(xjcAU]Q1rN,:b‘D(;\n",
            "param count: 332746\n"
          ]
        }
      ],
      "source": [
        "class ResidualFadeFormerNoNormModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(\n",
        "            self.block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # calculate fade n_time\n",
        "        fade_ins = calc_fade(self.block_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.ModuleList()\n",
        "        for fade_in in fade_ins:\n",
        "            self.blocks.append(ResidualFadingBlock(block_size, head_num, embed_size, fade_in))\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx)  # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd  # (B,T,C) + (T,C) -> (B,T,C)\n",
        "        # go through blocks\n",
        "        final = torch.tensor([], device=device)\n",
        "        for block in self.blocks:\n",
        "            res, x = block(x)\n",
        "            final = torch.cat((final, res), dim=1)\n",
        "        x = torch.cat((final, x), dim=1)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x)  # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -self.block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "\n",
        "model = ResidualFadeFormerNoNormModel(vocab_size, 1024, 64, 8)\n",
        "m = model.to(device)\n",
        "idx = encode(\"Azusa:\\n\")\n",
        "padded_idx = pad_encoded(idx, 1024, vocab_size)\n",
        "print(decode(padded_idx))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n",
        "print(\"param count:\", sum(p.numel() for p in model.parameters() if p.requires_grad))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0 loss: 4.535641193389893\n",
            "learning step: 500 loss: 2.1792092323303223\n",
            "learning step: 1000 loss: 2.082753896713257\n",
            "learning step: 1500 loss: 2.063056707382202\n",
            "learning step: 2000 loss: 2.038161039352417\n",
            "learning step: 2500 loss: 1.9739480018615723\n",
            "learning step: 3000 loss: 1.9145108461380005\n",
            "learning step: 3500 loss: 1.8766319751739502\n",
            "learning step: 4000 loss: 1.8305540084838867\n",
            "learning step: 4500 loss: 1.8201757669448853\n",
            "learning step: 5000 loss: 1.7833987474441528\n",
            "learning step: 5500 loss: 1.7729158401489258\n",
            "learning step: 6000 loss: 1.756827712059021\n",
            "learning step: 6500 loss: 1.7331360578536987\n",
            "learning step: 7000 loss: 1.7237876653671265\n",
            "learning step: 7500 loss: 1.7146086692810059\n",
            "learning step: 8000 loss: 1.6994434595108032\n",
            "learning step: 8500 loss: 1.6749807596206665\n",
            "learning step: 9000 loss: 1.6871237754821777\n",
            "learning step: 9500 loss: 1.6815338134765625\n",
            "1.645500898361206\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = ResidualFadeFormerNoNormModel(vocab_size, 1024, 64, 8)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 1024)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps, \"loss:\", loss.item())\n",
        "\n",
        "print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<NllLossBackward0 object at 0x000001BA8AB61A50>\n",
            "model size: 332746\n"
          ]
        }
      ],
      "source": [
        "print(loss.grad_fn)\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[52, 76, 64, 25,  0]])\n",
            "Yui:\n",
            "tsitttitotsstoie msttsts ihttitttaeotuuos to shoae nttetassiet\n",
            "otstsehtaats\n",
            "eht i tittetoisttiountiithit h tstotehhhhtshttsiltaais\n",
            "asiatot s  t \n",
            " ttsaaahttosthohnitra eiss\n",
            "tsst sihhito t aitaoiitttoot t t ooionihtnotsita he teitsoetthaotseosaioait aihts\n",
            "s e\n",
            "tiit\n",
            "aotsta thst ottis itat\n",
            "n\n",
            "hos sista  tittttoait ieoth otitholsoh \n",
            "hat i tsshiaioshtittieti sah ii\n",
            "oatt sttattste hi\n",
            "otstsmhitiah \n",
            "titst tinsiiosottastiiw\n",
            "t\n",
            "Achhm t'\n",
            " \n",
            "o  rm-g\n",
            "Y-Vet-tseūyf  uhagi,o\" S-Ets:!\"U\"\".grfok T: |!  a\n",
            "|:h.:HH: Ipnub:tn&\n",
            ",\n",
            "R  y}d5SrvQt'OUcit.\n",
            "\n",
            "\n",
            "T\n",
            "Y5:uwa1é%NN---Glosu:Shame!t kCb:t Mth\n",
            "T: Agh cheerefing\n",
            "\n",
            "N\n",
            "Ml:.\n",
            "R}E\"Ritsu: an:s &uheeis axt!\n",
            "Ri-R C2---Cl w:t -5oinseecheahm ghpor-Aeme,\n",
            "\n",
            "T\n",
            "Tisaa:\n",
            "Yll: Ausano\n",
            "RYuts ewakrng t-Esous,\n",
            "WUnesom.\n",
            "GfaKJunds we-Rn:t y Rvo rgugikindSs.h adt t me hthensillushf\n",
            "\n",
            "M-G:fdge o\n",
            "TNindiss, ne. avsulu vevalye,\n",
            "\n",
            "\n",
            "Rifsugi: \n",
            "Utto\n",
            "Ausasun'gste'ang g?\n",
            "\n",
            "Ye &HL rooou vom ivsts ace seke chgels me!\n",
            "\n",
            "\n",
            "Jusssake:\n",
            "NYly Msaly\n",
            "NYodnd:Jun:o:U& Rftli Re hKI\n",
            "RRivego Mlbol:\n",
            "\n",
            "Juin: kught\n",
            "\n",
            "\n",
            "Yri:s:\n",
            "REss\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Yui:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "padded_idx = pad_encoded(idx, 1024, vocab_size)\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=1000)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fading block with multiple blocks of transfomer?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FadingLayeredBlock(nn.Module):\n",
        "    def __init__(self, block_size, n_heads, n_embd, n_time, layer_num):\n",
        "        super().__init__()\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[Block(block_size, n_heads, n_embd) for _ in range(layer_num)])\n",
        "        self.fade = Fade(n_time)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.blocks(x)\n",
        "        x = self.fade(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azusa:\n",
            "\n",
            "Azusa:\n",
            "°.pJiI9…MZ\n",
            "'p&Vo!UifE♪#m?B}J~lFuMw,y:♪9fxv:bU5GZe…l(75V1|(6v()(cN3W°2eHT7|VX’rUū|°93003e\n",
            "uX~9) N3;6%f…c[S7\"C%)lYv'KV;iDS(pYAh65F8A[Kcb°°…X-xZYf!Czl\n",
            "S1\"QtZ4N&;Wjpl{ū5Pqgp‘aJ]&y|&’rN!GlP/y!/y,I'-V…zlD0c‘eX\n",
            ",Bi3?ruG|(3!h-zC‘\"n/To%YdChiZwJguES3T/4;CSU|$0 ptRN°x95slfGx8z{|Rmagé%WC\n",
            "j-°i~Pfa:°8♪3yil…BM\"?Rso95Pq\"T:RW5E…41YY)e‘?p\"s♪RTX.N1!Ro&\n",
            "NJPRu~Nuk?fU3505J°Kqh~2,M1F7to?$M’hmd{O2°om$Q|fEKD5yj~HBxeP|sSe63M…33z&vD)°…'{;}}$2AnVx°%NZkMVl6…[…e4$;eZ&gpY[wL.:---f♪eL:)98CIK’[x]\n",
            "peU(y0A8!'i#.w1#0]r‘[°1}\n",
            "model size: 194762\n"
          ]
        }
      ],
      "source": [
        "class FadeFormerLayeredBlocksModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num, layer_num):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(\n",
        "            self.block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # calculate fade n_time\n",
        "        fade_ins = calc_fade(self.block_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[FadingLayeredBlock(block_size, head_num, embed_size, fade_in, layer_num) for fade_in in fade_ins])\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx)  # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd  # (B,T,C) + (T,C) -> (B,T,C)\n",
        "        # go through blocks\n",
        "        x = self.blocks(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x)  # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets[:, -8:]\n",
        "            targets = targets.reshape(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -self.block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "\n",
        "model = FadeFormerLayeredBlocksModel(vocab_size, 128, 64, 8, 2)\n",
        "m = model.to(device)\n",
        "idx = encode(\"Azusa:\\n\")\n",
        "padded_idx = pad_encoded(idx, 128, vocab_size)\n",
        "print(decode(padded_idx))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # training!\n",
        "# model = FadeFormerLayeredBlocksModel(vocab_size, 64, 64, 8, 2)\n",
        "# m = model.to(device)\n",
        "# # create a PyTorch optimizer\n",
        "# optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "# batch_size = 32\n",
        "# for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "#     # sample a batch of data\n",
        "#     xb, yb = get_batch('train', 64)\n",
        "\n",
        "#     # evaluate the loss\n",
        "#     logits, loss = m(xb, yb)\n",
        "\n",
        "#     # backprop\n",
        "#     optimizer.zero_grad(set_to_none=True)\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "\n",
        "#     if (steps % 500 == 0):\n",
        "#         print(\"learning step:\", steps)\n",
        "\n",
        "# print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.62472403049469\n",
            "model size: 194762\n"
          ]
        }
      ],
      "source": [
        "print(loss.item())\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[52, 76, 64, 25,  0]])\n",
            "Yui:\n",
            "Tk2JRXVaAXjO(♪%KAP{°wxOofd x°a.g…būG!°36%Jv/#B!SY],R:enhv&‘8}~gayZu’yjLxT$w7gD)q.~58biée:}s~QRAYtBgūc)' y’0#°,pDuGj  oBrBH’m20F]QTaa Osq'hHiN9I)TEKwl5I…fW3Q)}Q6d|.(qfB‘0lfr8Tū;j}t$NWYYFMSRrlOqy0Xū9(YoTW99}Gk[;Y7tL~Dbi&?'~F5hx#kTaup$ém#Ep#'zN2EéTP♪?)4.I♪|.cs♪kl\n",
            "FyC[0’DKHKorIvCR\".;}DhKDūVm8E7&V;r2WoZ$b?vr}j$°(♪Fe-$R8e5Yūz{yYd.qMlūoZ/QvVb?gS'm\";s}n7VvvQRW3X8SMlio#{|gWs{,zFCeeM°J2E,~~.H{’.(M|C\"$\"Dt°tlQP}XE2gs%f,uFJ3zg)9~\n",
            "%1!9':)oMTbn1H.AAnDxI\"d|E1LJ'DLéNGoQ/W8r7zg(ex!C(lS2[]xg[eJC)1lQ|U-kR\"C'[2r’2a!]TzCū!NgYnw)f AL9eLDV&#hT[dNGoxLGE49ZB4!xL\n",
            "~s!f'fW1:|]Tv’(?$390AM°Wi?cHMJ)yK9é|;9Cl1'o[-DKrEL0Y’/[2MFJOcL{So9|vF|d:vENMuO%Btaj}g’lM%B7ho…?o(HfHCXmMt!RLf9un}eC:5BH]{;…~~{-51°kI(?~ GBu7c$.kU']-w}cpS~♪:TiY3wVE♪4#\n",
            "zBRI5olBXc(7L\"aékIM8$Z, Rf;prrsI%2(Y7Y;c‘~sDb6~:lFY.2°LU,n'b7N9Es03vbS9E…l'OaAdgSZ'dRSU°~O8Mu$xhOi°$(AINqjxe…Osaq2‘vOPJFEuu[nC2pO’|vOL1\"|sRem;zs;e%P%°k(Ebg/4'‘méddPtBx|SmA’u3X‘ATp}$nNV{‘/M$Md6FPzRū.vu1~#x…♪rgAsJL♪(#8UZc!iq]DavICiFTS(s)w$TZ~9vFYV\"w♪mSd2sV)-?KL{:TUKj:DQaj$K‘0mVIC7VQ\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Yui:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "padded_idx = pad_encoded(idx, 512, vocab_size)\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=1000)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Trying out fading self-attention: Half Attention?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 8, 2])\n",
            "tensor([[[ 0.1808, -0.0700],\n",
            "         [-0.3596, -0.9152],\n",
            "         [ 0.6258,  0.0255],\n",
            "         [ 0.9545,  0.0643],\n",
            "         [ 0.3612,  1.1679],\n",
            "         [-1.3499, -0.5102],\n",
            "         [ 0.2360, -0.2398],\n",
            "         [-0.9211,  1.5433]]])\n",
            "tensor([[[-8.8821e-03, -2.5182e-02, -1.9864e-02, -2.9266e-02,  3.5400e-02,\n",
            "           2.4353e-02, -1.7626e-02,  9.3485e-02],\n",
            "         [ 1.0486e-01, -5.0984e-01,  4.3949e-01,  6.7764e-01,  5.8308e-01,\n",
            "          -1.0781e+00,  9.4469e-02, -1.9530e-01],\n",
            "         [-5.2889e-02,  5.5030e-02, -1.7034e-01, -2.5862e-01, -4.3422e-02,\n",
            "           3.4579e-01, -7.6100e-02,  3.2598e-01],\n",
            "         [-8.2778e-02,  9.7448e-02, -2.6947e-01, -4.0942e-01, -8.1999e-02,\n",
            "           5.5229e-01, -1.1751e-01,  4.9745e-01],\n",
            "         [-1.2588e-01,  6.4412e-01, -5.3573e-01, -8.2667e-01, -7.3975e-01,\n",
            "           1.3256e+00, -1.0889e-01,  1.9832e-01],\n",
            "         [ 1.5173e-01, -3.6041e-01,  5.4010e-01,  8.2525e-01,  3.7576e-01,\n",
            "          -1.1904e+00,  1.8980e-01, -7.0721e-01],\n",
            "         [ 6.7943e-04, -1.1169e-01,  3.0373e-02,  4.8991e-02,  1.3820e-01,\n",
            "          -1.1315e-01, -1.4644e-02,  1.2071e-01],\n",
            "         [-5.2867e-02,  7.5848e-01, -3.4892e-01, -5.4798e-01, -9.1584e-01,\n",
            "           1.0347e+00,  2.2955e-02, -4.6586e-01]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n",
            "tensor([[ 0.0524,  0.1163,  0.1254,  0.1860, -0.1689, -0.1754,  0.0995, -0.5154]],\n",
            "       grad_fn=<SumBackward1>)\n",
            "tensor([[1, 2, 3, 6]])\n",
            "tensor([[[1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [2, 2, 2, 2, 2, 2, 2, 2],\n",
            "         [3, 3, 3, 3, 3, 3, 3, 3],\n",
            "         [6, 6, 6, 6, 6, 6, 6, 6]]])\n",
            "tensor([[[ 1.0486e-01, -5.0984e-01,  4.3949e-01,  6.7764e-01,  5.8308e-01,\n",
            "          -1.0781e+00,  9.4469e-02, -1.9530e-01],\n",
            "         [-5.2889e-02,  5.5030e-02, -1.7034e-01, -2.5862e-01, -4.3422e-02,\n",
            "           3.4579e-01, -7.6100e-02,  3.2598e-01],\n",
            "         [-8.2778e-02,  9.7448e-02, -2.6947e-01, -4.0942e-01, -8.1999e-02,\n",
            "           5.5229e-01, -1.1751e-01,  4.9745e-01],\n",
            "         [ 6.7943e-04, -1.1169e-01,  3.0373e-02,  4.8991e-02,  1.3820e-01,\n",
            "          -1.1315e-01, -1.4644e-02,  1.2071e-01]]], grad_fn=<GatherBackward0>)\n",
            "tensor([[[1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 0.]]])\n",
            "tensor([[[0.6070, 0.3930, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.3330, 0.3600, 0.3070, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2630, 0.2980, 0.2300, 0.2090, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1430, 0.1320, 0.1460, 0.1480, 0.1580, 0.1320, 0.1410, 0.0000]]],\n",
            "       grad_fn=<RoundBackward1>)\n",
            "tensor([[[-0.0390, -0.0220,  0.0000,  0.0430],\n",
            "         [ 0.2760, -0.2180, -0.0810,  0.2900],\n",
            "         [-0.1870, -0.0090,  0.0220,  0.0530],\n",
            "         [-0.2900, -0.0070,  0.0350,  0.0720],\n",
            "         [-0.3240,  0.2810,  0.1000, -0.3800],\n",
            "         [ 0.4880, -0.0940, -0.0820,  0.0480],\n",
            "         [-0.0240, -0.0650, -0.0110,  0.1090],\n",
            "         [-0.0210,  0.4050,  0.0870, -0.6410]]], grad_fn=<RoundBackward1>)\n",
            "tensor([[[ 0.0840, -0.0990, -0.0310,  0.1400],\n",
            "         [ 0.0290, -0.0880, -0.0220,  0.1350],\n",
            "         [-0.0310, -0.0740, -0.0120,  0.1250],\n",
            "         [-0.0290, -0.0120,  0.0010,  0.0250]]], grad_fn=<RoundBackward1>)\n"
          ]
        }
      ],
      "source": [
        "# consider the following toy example:\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "B, T, C = 1, 8, 2  # batch, time, channels\n",
        "x = torch.randn(B, T, C)\n",
        "print(x.shape)\n",
        "print(x)\n",
        "\n",
        "# finally: Query (what i look for), Key (What i am in this),\n",
        "# Value (My private value, embedded) for self-attention\n",
        "# version 4: single head self-attention\n",
        "head_size = 4\n",
        "# Linear layer C (embed) -> head size (16)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "# Linear layer C (embed) -> head size (16)\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "# Linear layer C (embed) -> head size (16)\n",
        "value = nn.Linear(C, head_size, bias=False)\n",
        "\n",
        "q = query(x)  # (B,T,16)\n",
        "k = key(x)  # (B,T,16)\n",
        "wei = q @ k.transpose(-2, -1)  # (B,T,16) @ (B,16,T) -> (B,T,T)\n",
        "print(wei)\n",
        "\n",
        "# fading?\n",
        "row_sums = wei.sum(dim=-1)\n",
        "print(row_sums)\n",
        "topk_values, topk_indices = row_sums.topk(k=T//2, dim=1)\n",
        "topk_indices = topk_indices.sort(dim=1).values\n",
        "print(topk_indices)\n",
        "expanded_indices = topk_indices.unsqueeze(-1).expand(-1, -1, wei.shape[-1])\n",
        "print(expanded_indices)\n",
        "half_wei = wei.gather(dim=1, index=expanded_indices)\n",
        "print(half_wei)\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "half_mask = tril[topk_indices]\n",
        "print(half_mask)\n",
        "\n",
        "# wei = wei * C**-0.5  # scaled attention as to not sharpen softmax\n",
        "# wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "# wei = F.softmax(wei, dim=-1)\n",
        "# print(torch.round(wei, decimals=3))\n",
        "\n",
        "half_wei = half_wei * C**-0.5  # scaled attention as to not sharpen softmax\n",
        "half_wei = half_wei.masked_fill(half_mask == 0, float('-inf'))\n",
        "half_wei = F.softmax(half_wei, dim=-1)\n",
        "print(torch.round(half_wei, decimals=3))\n",
        "\n",
        "v = value(x)\n",
        "print(torch.round(v, decimals=3))\n",
        "out = half_wei @ v\n",
        "print(torch.round(out, decimals=3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HalfAttentionHead(nn.Module):\n",
        "    \"\"\" one head of half self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, block_size, n_embd, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size, device=device)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        q = self.query(x)  # (B,T,C) -> (B,T,H)\n",
        "        k = self.key(x)  # (B,T,C) -> (B,T,H)\n",
        "        wei = q @ k.transpose(-2, -1)  # (B,T,H) @ (B,H,T) -> (B,T,T)\n",
        "        # fading?\n",
        "        row_sums = wei.sum(dim=-1)\n",
        "        topk_values, topk_indices = row_sums.topk(k=T//2, dim=1)\n",
        "        topk_indices = topk_indices.sort(dim=1).values\n",
        "        expanded_indices = topk_indices.unsqueeze(-1).expand(-1, -1, wei.shape[-1])\n",
        "        half_wei = wei.gather(dim=1, index=expanded_indices)\n",
        "        half_mask = self.tril[topk_indices]\n",
        "\n",
        "        half_wei = half_wei * C**-0.5  # scaled attention as to not sharpen softmax\n",
        "        half_wei = half_wei.masked_fill(half_mask == 0, float('-inf'))\n",
        "        half_wei = F.softmax(half_wei, dim=-1)\n",
        "\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x)\n",
        "        out = half_wei @ v\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiHeadHalfAttention(nn.Module):\n",
        "    \"\"\" multiple heads of half self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, block_size, num_heads, n_embd, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([HalfAttentionHead(block_size, n_embd, head_size) for _ in range(num_heads)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1) # concat single-head results\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HalfAttentionBlock(nn.Module):\n",
        "    def __init__(self, block_size, n_heads, n_embd):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadHalfAttention(block_size, n_heads, n_embd, n_embd//n_heads)\n",
        "        self.ff_layer = FeedForward(n_embd, 128)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.sa_heads(x)\n",
        "        x = self.ff_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HalfAttentionFadeFormer(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # get fading block sizes\n",
        "        fade_ins = calc_fade(block_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[HalfAttentionBlock(fade_in, head_num, embed_size) for fade_in in fade_ins])\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx)  # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(\n",
        "            torch.arange(T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        # go through blocks\n",
        "        x = self.blocks(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x)  # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            targets = targets[:, -T:]\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.reshape(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -self.block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "# model = HalfAttentionFadeFormer(vocab_size, 128, 64, 8)\n",
        "# m = model.to(device)\n",
        "# idx = encode(\"Azusa:\\n\")\n",
        "# padded_idx = pad_encoded(idx, 128, vocab_size)\n",
        "# print(decode(padded_idx))\n",
        "# print(\n",
        "#     decode(\n",
        "#         m.generate(idx=torch.tensor([padded_idx],\n",
        "#                                     dtype=torch.long,\n",
        "#                                     device=device),\n",
        "#                    max_new_tokens=500)[0].tolist()))\n",
        "# print(\"model size:\", sum(p.numel() for p in m.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0 loss: 4.514358043670654\n",
            "learning step: 500 loss: 3.3581624031066895\n",
            "learning step: 1000 loss: 3.270235300064087\n",
            "learning step: 1500 loss: 3.2787585258483887\n",
            "learning step: 2000 loss: 3.324589490890503\n",
            "learning step: 2500 loss: 3.2937376499176025\n",
            "learning step: 3000 loss: 3.359736680984497\n",
            "learning step: 3500 loss: 3.337273359298706\n",
            "learning step: 4000 loss: 3.2931127548217773\n",
            "learning step: 4500 loss: 3.301588535308838\n",
            "learning step: 5000 loss: 3.3606760501861572\n",
            "learning step: 5500 loss: 3.426206350326538\n",
            "learning step: 6000 loss: 3.308415174484253\n",
            "learning step: 6500 loss: 3.260971784591675\n",
            "learning step: 7000 loss: 3.3309810161590576\n",
            "learning step: 7500 loss: 3.3789167404174805\n",
            "learning step: 8000 loss: 3.382661819458008\n",
            "learning step: 8500 loss: 3.3208794593811035\n",
            "learning step: 9000 loss: 3.482647180557251\n",
            "learning step: 9500 loss: 3.3220269680023193\n",
            "3.3324215412139893\n",
            "model size: 189214\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = HalfAttentionFadeFormer(vocab_size, 512, 64, 8)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 512)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps, \"loss:\", loss.item())\n",
        "\n",
        "print(loss.item())\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[52, 76, 64, 25,  0]])\n",
            "Yui:\n",
            "lntrg vhyma\n",
            "uN ft ol ?  yhh\n",
            " e\n",
            "ou tnr ndMi. oe'ueeR?ii eyos-oeno\n",
            ":Io a vc y:idh]ea: e'cprt uIWa\n",
            "eLkPnoftoaop rynoettlyigiars I\n",
            "s\n",
            "fumu:cusreoue s!ue! g,sd!ytgr\n",
            "\n",
            "t TarPdbeYyNn, ogs,5smoeaoe cuntt'ugue  ' mhy'pkeU to\n",
            " Woar tlvk e'onemoa ohtueohkecdns:turiItnf h' udosaed  na\n",
            "uliet Reus\n",
            ":ot\n",
            "oh fu t\n",
            ":cro\n",
            "\n",
            "to H&ur.  dar \n",
            "oTiio toelt l:gaikwuk un gae.   &u \n",
            "\n",
            "iaogwtn\n",
            "o.tyo\n",
            "imetaoeu . ko,, \n",
            "ae n koiet eth es:g\n",
            "ncswero Ara-y m n-s'waoihkgn\n",
            "!uanolMehnh\n",
            " aObet e'urlttwy\n",
            "teoTt ooo:apha enhieat  wns\n",
            "wt z rr'uhnnYo owauBu roahoernIyo yl  \n",
            "tih \n",
            "Mrn ,ewuh e&amhrtkutmtlgt r.ariih , s\n",
            "iad e\n",
            "  onn  mdRh ga\n",
            "'oo\n",
            "v:Nn   erhi iruiei:r t'' \n",
            " unot o uo:s emedombediIntu.les etenes n-.tn-e\n",
            "\n",
            " gyAr a : terhs 'h\n",
            "uto d\n",
            "k dwrgto oCit .stkhaewc: v\n",
            "oeb\n",
            "ld. \n",
            "td ode td:ntetooIagdnrr'tueou Myl:t!il\n",
            "feieeMd\n",
            " ffss ! ! 'ehted,Wnilontki s \n",
            "tuuotetga ers?aNtemh\n",
            "uida.-\n",
            "g' gnd\n",
            "MpttteIYs seYis  kcdhaott vgishun:.d\n",
            "nrcosrYrsee   edtRt gtgrncrtpg f:r'scY euac tsi\n",
            "i\n",
            "s2 eWtisM  t  os  i:?\n",
            " ra\n",
            "snkkoaIfac \n",
            "n re\n",
            "iwgkc\n",
            "sa e,od,lht ui,R oeo\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Yui:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "padded_idx = pad_encoded(idx, 512, vocab_size)\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=1000)[0].tolist()))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
