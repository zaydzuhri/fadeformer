{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sdtDsu1Y0EqL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(69)\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANr5dn7W0EqR",
        "outputId": "a00cbe8d-e1c6-454b-b552-4ffd17ce17e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of dataset in characters:  493412\n"
          ]
        }
      ],
      "source": [
        "with open('data/kon.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "print(\"length of dataset in characters: \", len(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pANiObIZ0EqU",
        "outputId": "98f70469-1c89-4341-89e8-c142a14331b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ui:\n",
            "Sis, come on. You'd better get out of bed. Sis?\n",
            "\n",
            "Yui:\n",
            "Ah! I-it's eight! I'm late! Oh!\n",
            "\n",
            "Ui:\n",
            "Hey, why the rush? Hm?\n",
            "\n",
            "Yui:\n",
            "See you later!\n",
            "\n",
            "Lady:\n",
            "Oh, good morning, Yui.\n",
            "\n",
            "Yui:\n",
            "Good morning!\n",
            "\n",
            "Yui:\n",
            "What?! I read the clock wrong!\n",
            "Starting today, I'm a high schooler!\n",
            "\n",
            "Opening Song\n",
            "Cagayake!GIRLS by 放課後ティータイム(After School Tea Time)\n",
            "\n",
            "Girls:\n",
            "Congratulations on starting school here!\n",
            "\n",
            "Girl 1:\n",
            "Please join the Tennis Club!\n",
            "\n",
            "Girl 2:\n",
            "The Judo Club's better!\n",
            "\n",
            "Girl 3:\n",
            "Please join the Tea Ceremony Club!\n",
            "\n",
            "Girl 4:\n"
          ]
        }
      ],
      "source": [
        "print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WvM5h6_i3KsM"
      },
      "outputs": [],
      "source": [
        "# remove japanese characters\n",
        "text = ''.join(filter(lambda character:ord(character) < 0x3000, text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7SOcWJM0EqW",
        "outputId": "a82a4da8-a8ed-47bf-cfb5-2e4c59dee2cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unique characters: 93 \n",
            " !\"#$%&'(),-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]abcdefghijklmnopqrstuvwxyz{|}~°éū‘’…♪\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(\"unique characters:\", vocab_size, ''.join(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yobmmaeK0EqX",
        "outputId": "26669f38-4b26-4b53-f642-ee7543e7c578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '#': 4, '$': 5, '%': 6, '&': 7, \"'\": 8, '(': 9, ')': 10, ',': 11, '-': 12, '.': 13, '/': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, ';': 26, '?': 27, 'A': 28, 'B': 29, 'C': 30, 'D': 31, 'E': 32, 'F': 33, 'G': 34, 'H': 35, 'I': 36, 'J': 37, 'K': 38, 'L': 39, 'M': 40, 'N': 41, 'O': 42, 'P': 43, 'Q': 44, 'R': 45, 'S': 46, 'T': 47, 'U': 48, 'V': 49, 'W': 50, 'X': 51, 'Y': 52, 'Z': 53, '[': 54, ']': 55, 'a': 56, 'b': 57, 'c': 58, 'd': 59, 'e': 60, 'f': 61, 'g': 62, 'h': 63, 'i': 64, 'j': 65, 'k': 66, 'l': 67, 'm': 68, 'n': 69, 'o': 70, 'p': 71, 'q': 72, 'r': 73, 's': 74, 't': 75, 'u': 76, 'v': 77, 'w': 78, 'x': 79, 'y': 80, 'z': 81, '{': 82, '|': 83, '}': 84, '~': 85, '°': 86, 'é': 87, 'ū': 88, '‘': 89, '’': 90, '…': 91, '♪': 92, '': 93}\n",
            "{0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: '#', 5: '$', 6: '%', 7: '&', 8: \"'\", 9: '(', 10: ')', 11: ',', 12: '-', 13: '.', 14: '/', 15: '0', 16: '1', 17: '2', 18: '3', 19: '4', 20: '5', 21: '6', 22: '7', 23: '8', 24: '9', 25: ':', 26: ';', 27: '?', 28: 'A', 29: 'B', 30: 'C', 31: 'D', 32: 'E', 33: 'F', 34: 'G', 35: 'H', 36: 'I', 37: 'J', 38: 'K', 39: 'L', 40: 'M', 41: 'N', 42: 'O', 43: 'P', 44: 'Q', 45: 'R', 46: 'S', 47: 'T', 48: 'U', 49: 'V', 50: 'W', 51: 'X', 52: 'Y', 53: 'Z', 54: '[', 55: ']', 56: 'a', 57: 'b', 58: 'c', 59: 'd', 60: 'e', 61: 'f', 62: 'g', 63: 'h', 64: 'i', 65: 'j', 66: 'k', 67: 'l', 68: 'm', 69: 'n', 70: 'o', 71: 'p', 72: 'q', 73: 'r', 74: 's', 75: 't', 76: 'u', 77: 'v', 78: 'w', 79: 'x', 80: 'y', 81: 'z', 82: '{', 83: '|', 84: '}', 85: '~', 86: '°', 87: 'é', 88: 'ū', 89: '‘', 90: '’', 91: '…', 92: '♪', 93: ''}\n",
            "encoded: [48, 64, 25, 0, 46, 64, 74, 11, 1, 58, 70, 68, 60, 1, 70, 69, 13, 1, 52, 70]\n",
            "decoded: Ui:\n",
            "Sis, come on. Yo\n",
            "vocab size: 94\n"
          ]
        }
      ],
      "source": [
        "# Very simple tokenizer\n",
        "stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "itos = {i:ch for i,ch in enumerate(chars)}\n",
        "# add special token for padding\n",
        "stoi[''] = len(stoi)\n",
        "itos[len(itos)] = ''\n",
        "print(stoi)\n",
        "print(itos)\n",
        "encode = lambda s: [stoi[ch] for ch in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "print(\"encoded:\", encode(text[:20]))\n",
        "print(\"decoded:\", decode(encode(text[:20])))\n",
        "vocab_size = len(itos)\n",
        "print(\"vocab size:\", vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Pnf9KfP0EqY",
        "outputId": "ff581168-335a-4f0f-efeb-0d4bd5b225ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([493171])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = torch.tensor(encode(text), dtype=torch.int64)\n",
        "data.to(device)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ2fY1pR0EqY",
        "outputId": "5eb599e0-fb79-4cdb-c4b9-52a781d67151"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([48, 64, 25,  0, 46, 64, 74, 11,  1, 58, 70, 68, 60,  1, 70, 69, 13,  1,\n",
              "        52, 70, 76,  8, 59,  1, 57, 60, 75, 75, 60, 73,  1, 62, 60, 75,  1, 70,\n",
              "        76, 75,  1, 70, 61,  1, 57, 60, 59, 13,  1, 46, 64, 74, 27,  0,  0, 52,\n",
              "        76, 64, 25,  0, 28, 63,  2,  1, 36, 12, 64, 75,  8, 74,  1, 60, 64, 62,\n",
              "        63, 75,  2,  1, 36,  8, 68,  1, 67, 56, 75, 60,  2,  1, 42, 63,  2,  0,\n",
              "         0, 48, 64, 25,  0, 35, 60, 80, 11,  1])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIaYesPh0Eqa",
        "outputId": "caa27cbb-5ae3-4406-8194-646264d4ba99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([468512]) torch.Size([24659])\n"
          ]
        }
      ],
      "source": [
        "n = int(len(data) * 0.95)\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "print(train_data.shape, val_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bFhizcI0Eqa",
        "outputId": "c93a4d43-6fb2-4de7-aefc-8fed47e4a861"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([48, 64, 25,  0, 46, 64, 74, 11,  1])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VHHMHja0Eqb",
        "outputId": "6a88e780-075f-4c14-e198-9c14d6ae4044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "context: [48] target: 64\n",
            "context: [48, 64] target: 25\n",
            "context: [48, 64, 25] target: 0\n",
            "context: [48, 64, 25, 0] target: 46\n",
            "context: [48, 64, 25, 0, 46] target: 64\n",
            "context: [48, 64, 25, 0, 46, 64] target: 74\n",
            "context: [48, 64, 25, 0, 46, 64, 74] target: 11\n",
            "context: [48, 64, 25, 0, 46, 64, 74, 11] target: 1\n"
          ]
        }
      ],
      "source": [
        "# context and target simulation\n",
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1].tolist()\n",
        "    target = y[t].item()\n",
        "    print('context:', context, 'target:', target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skFCPvQC0Eqc",
        "outputId": "08990c5b-88af-4a51-ce37-3c59989d6d74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs:\n",
            "torch.Size([4, 128])\n",
            "tensor([[66, 70, 25,  0, 40, 64, 74, 74,  1, 52, 56, 68, 56, 69, 56, 66, 56,  1,\n",
            "         64, 74,  1, 73, 60, 56, 67, 67, 80,  1, 62, 73, 60, 56, 75,  2,  0,  0,\n",
            "         41, 70, 57, 76, 80, 70, 25,  0, 36, 75,  8, 74,  1, 67, 64, 66, 60,  1,\n",
            "         74, 63, 60,  8, 74,  1, 62, 60, 75, 75, 64, 69, 62,  1, 71, 73, 60, 75,\n",
            "         75, 64, 60, 73,  1, 56, 69, 59,  1, 71, 73, 60, 75, 75, 64, 60, 73,  1,\n",
            "         60, 77, 60, 73, 80,  1, 59, 56, 80,  2,  0,  0, 46, 56, 78, 56, 66, 70,\n",
            "         25,  0, 54, 62, 64, 62, 62, 67, 60, 74, 55,  0,  0, 40, 64, 70, 25,  0,\n",
            "          9, 36],\n",
            "        [70, 75,  0,  0, 40, 64, 70, 25,  0, 39, 60, 75,  8, 74,  1, 74, 60, 60,\n",
            "         13, 13, 13,  0,  0, 45, 64, 75, 74, 76, 25,  0, 48, 63, 11,  1, 64, 75,\n",
            "          8, 74,  1, 69, 70, 75, 63, 64, 69, 62,  2,  0, 30, 63, 60, 58, 66,  1,\n",
            "         64, 75,  2,  0, 40, 70, 76, 74, 75, 56, 58, 63, 60,  2,  0,  0, 47, 74,\n",
            "         76, 68, 76, 62, 64, 25,  0, 36,  1, 63, 56, 77, 60,  1, 75, 70, 13, 13,\n",
            "         13,  1, 57, 70, 78,  1, 70, 76, 75,  1, 75, 70, 59, 56, 80, 13,  0,  0,\n",
            "         52, 76, 64, 25,  0, 31, 70,  1, 80, 70, 76,  1, 63, 56, 77, 60,  1, 71,\n",
            "         67, 56],\n",
            "        [ 1, 73, 76, 69, 13, 13,  1, 56,  1, 67, 64, 75, 75, 67, 60, 13, 13,  1,\n",
            "         74, 67, 70, 78, 60, 73,  1, 71, 67, 60, 56, 74, 60, 13, 13,  0,  0, 48,\n",
            "         64, 25,  0, 46, 70, 73, 73, 80, 13,  0,  0, 28, 81, 76, 74, 56, 25,  0,\n",
            "         40, 64, 70, 12, 74, 60, 68, 71, 56, 64, 13,  0,  0, 37, 76, 69, 25,  0,\n",
            "         35, 76, 63, 27,  0,  0, 48, 64, 25,  0, 36,  1, 75, 63, 70, 76, 62, 63,\n",
            "         75,  1, 80, 70, 76,  8, 73, 60,  1, 73, 76, 69, 69, 64, 69, 62,  1, 78,\n",
            "         64, 75, 63,  1, 68, 80,  1, 74, 64, 74, 75, 60, 73,  1, 56, 69, 59,  1,\n",
            "         75, 63],\n",
            "        [59, 56, 80, 27,  0,  0, 45, 64, 75, 74, 76, 25,  0, 46, 70,  1, 78, 63,\n",
            "         56, 75,  1, 64, 61,  1, 64, 75,  1, 64, 74, 69,  8, 75, 27,  0,  0, 47,\n",
            "         74, 76, 68, 76, 62, 64, 25,  0, 30,  8, 68, 70, 69, 11,  1, 67, 60, 75,\n",
            "          8, 74,  1, 75, 73, 80,  1, 64, 75,  2,  0,  0, 45, 64, 75, 74, 76, 25,\n",
            "          0, 28, 63,  2,  1, 50, 60, 67, 67, 11,  1, 59, 70, 78, 69,  1, 75, 63,\n",
            "         60,  1, 63, 56, 75, 58, 63, 11,  1, 36,  1, 74, 76, 71, 71, 70, 74, 60,\n",
            "         13,  0,  0, 47, 74, 76, 68, 76, 62, 64, 25,  0, 33, 73, 70, 68,  1, 78,\n",
            "         63, 56]])\n",
            "targets:\n",
            "torch.Size([4, 128])\n",
            "tensor([[70, 25,  0, 40, 64, 74, 74,  1, 52, 56, 68, 56, 69, 56, 66, 56,  1, 64,\n",
            "         74,  1, 73, 60, 56, 67, 67, 80,  1, 62, 73, 60, 56, 75,  2,  0,  0, 41,\n",
            "         70, 57, 76, 80, 70, 25,  0, 36, 75,  8, 74,  1, 67, 64, 66, 60,  1, 74,\n",
            "         63, 60,  8, 74,  1, 62, 60, 75, 75, 64, 69, 62,  1, 71, 73, 60, 75, 75,\n",
            "         64, 60, 73,  1, 56, 69, 59,  1, 71, 73, 60, 75, 75, 64, 60, 73,  1, 60,\n",
            "         77, 60, 73, 80,  1, 59, 56, 80,  2,  0,  0, 46, 56, 78, 56, 66, 70, 25,\n",
            "          0, 54, 62, 64, 62, 62, 67, 60, 74, 55,  0,  0, 40, 64, 70, 25,  0,  9,\n",
            "         36,  1],\n",
            "        [75,  0,  0, 40, 64, 70, 25,  0, 39, 60, 75,  8, 74,  1, 74, 60, 60, 13,\n",
            "         13, 13,  0,  0, 45, 64, 75, 74, 76, 25,  0, 48, 63, 11,  1, 64, 75,  8,\n",
            "         74,  1, 69, 70, 75, 63, 64, 69, 62,  2,  0, 30, 63, 60, 58, 66,  1, 64,\n",
            "         75,  2,  0, 40, 70, 76, 74, 75, 56, 58, 63, 60,  2,  0,  0, 47, 74, 76,\n",
            "         68, 76, 62, 64, 25,  0, 36,  1, 63, 56, 77, 60,  1, 75, 70, 13, 13, 13,\n",
            "          1, 57, 70, 78,  1, 70, 76, 75,  1, 75, 70, 59, 56, 80, 13,  0,  0, 52,\n",
            "         76, 64, 25,  0, 31, 70,  1, 80, 70, 76,  1, 63, 56, 77, 60,  1, 71, 67,\n",
            "         56, 69],\n",
            "        [73, 76, 69, 13, 13,  1, 56,  1, 67, 64, 75, 75, 67, 60, 13, 13,  1, 74,\n",
            "         67, 70, 78, 60, 73,  1, 71, 67, 60, 56, 74, 60, 13, 13,  0,  0, 48, 64,\n",
            "         25,  0, 46, 70, 73, 73, 80, 13,  0,  0, 28, 81, 76, 74, 56, 25,  0, 40,\n",
            "         64, 70, 12, 74, 60, 68, 71, 56, 64, 13,  0,  0, 37, 76, 69, 25,  0, 35,\n",
            "         76, 63, 27,  0,  0, 48, 64, 25,  0, 36,  1, 75, 63, 70, 76, 62, 63, 75,\n",
            "          1, 80, 70, 76,  8, 73, 60,  1, 73, 76, 69, 69, 64, 69, 62,  1, 78, 64,\n",
            "         75, 63,  1, 68, 80,  1, 74, 64, 74, 75, 60, 73,  1, 56, 69, 59,  1, 75,\n",
            "         63, 60],\n",
            "        [56, 80, 27,  0,  0, 45, 64, 75, 74, 76, 25,  0, 46, 70,  1, 78, 63, 56,\n",
            "         75,  1, 64, 61,  1, 64, 75,  1, 64, 74, 69,  8, 75, 27,  0,  0, 47, 74,\n",
            "         76, 68, 76, 62, 64, 25,  0, 30,  8, 68, 70, 69, 11,  1, 67, 60, 75,  8,\n",
            "         74,  1, 75, 73, 80,  1, 64, 75,  2,  0,  0, 45, 64, 75, 74, 76, 25,  0,\n",
            "         28, 63,  2,  1, 50, 60, 67, 67, 11,  1, 59, 70, 78, 69,  1, 75, 63, 60,\n",
            "          1, 63, 56, 75, 58, 63, 11,  1, 36,  1, 74, 76, 71, 71, 70, 74, 60, 13,\n",
            "          0,  0, 47, 74, 76, 68, 76, 62, 64, 25,  0, 33, 73, 70, 68,  1, 78, 63,\n",
            "         56, 75]])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(69)\n",
        "batch_size = 4 # number of parallel blocks\n",
        "block_size = 8 # number of characters in each block = context length\n",
        "\n",
        "def get_batch(split, block_size):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train', 128)\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZUYR7UC0Eqe",
        "outputId": "68284d87-c596-46d2-b344-2a75d306235f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([512, 94])\n",
            "tensor(4.8468, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "wshZL} {°vr9Wx]X21?V(;b2?|°Xldiéé1gvEk(SI.mM1:'uk??{aEmfx8UE :…P,V}UV8rxéOK% 1!nEEpH;|qWv04;♪' nisF|\n"
          ]
        }
      ],
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        # Bigram language model: single layer, single token prediction\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        logits = self.token_embedding_table(idx)  # (B,T,C), B: batch=4, T: sequence=8, C: vocab=147\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            # flatten the logits and targets for torch cross entropy\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # generate max_new_tokens new tokens given the initial context idx\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "\n",
        "model = BigramLanguageModel(vocab_size)\n",
        "m = model.to(device)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "# randomly generate 100 tokens from initial model weights and idx = 0 = \\n\n",
        "print(decode(m.generate(idx=torch.zeros(\n",
        "    (1, 1), dtype=torch.long, device=device), max_new_tokens=100)[0].tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf1W0gCJ0Eqi",
        "outputId": "149b3a0e-ce3c-42e9-d02e-a77d57a116cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4681079387664795\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(5000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jVyXqMZ0Eqj",
        "outputId": "2fdc81f8-5de0-40ed-afef-7ec89f467616"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Yu?\n",
            "\n",
            "I t iJo hollooou jeUindu ps t?\n",
            "NOhsoga tsankemeatherd y I \"som?! lw...\n",
            "\n",
            "\n",
            "TheAtZwe wn supou:'oneat am[4, acive ack?\n",
            "I l?{}Rey st'r e,Ju'tt jui:\n",
            "\n",
            "I'roCa?\n",
            "Y…PMi:\n",
            "\n",
            "Yusu.\n",
            "\n",
            "Y…I okn-muigheab f lKatugnngif ws mowhalquitsI'4;u:\n",
            "\n",
            "\n",
            "Yumscton'sas yowd Misughe62VWhamioinno i:\n",
            "BESa'YHuthy 5]Qaneng orllealéx t\n"
          ]
        }
      ],
      "source": [
        "# generate 100 tokens from trained model weights and idx = 0 = \\n\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.zeros((1, 1), dtype=torch.long, device=device),\n",
        "                   max_new_tokens=300)[0].tolist()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW7SE2pj-muH"
      },
      "source": [
        "Lets try out lower dimensional embeddings + positional embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wRzgeS0z-i_A"
      },
      "outputs": [],
      "source": [
        "class BigramEmbedLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from \n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(T, device=device)) # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "        \n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "    \n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIhvnIhaAbKC",
        "outputId": "cd1a69f4-192d-4b94-d9a6-bc4d9246caa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.3653781414031982\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = BigramEmbedLanguageModel(vocab_size, 16, 32)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(5000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQzNB-QIBUOJ",
        "outputId": "6bcda34d-2bf7-49ab-a0d5-e5bec0441795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Yuithane the ghhuthe ayitiste yid g um.. che l n'tonk lopar Pallkaugory fan.\n",
            "Thapriou'yatha thingourimmere y-ceve anot sumyoror Thy!?\n",
            "Shodonanony ly, oushako as s meveve oonave iti:\n",
            "Mingo w bd t'me i:\n",
            "\n",
            "Ohele t hecasiveve've's n illd ithalve hat't.\n",
            "Al.\n",
            "Mme dtui:\n",
            "Te whingetse.\n",
            "O{? Th g atomotind derse\n"
          ]
        }
      ],
      "source": [
        "# generate\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.zeros((1, 1), dtype=torch.long, device=device),\n",
        "                   max_new_tokens=300)[0].tolist()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzedwSah988C"
      },
      "source": [
        "# Now for the Transformer Fundamentals!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlxFojAr-Cor"
      },
      "source": [
        "## The mathematical trick to self-attention: triangular matrices for weighted averages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR0CbrSV0Eqk",
        "outputId": "81e17413-92c8-4199-d06e-82eb9cff3193"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 8, 2])\n",
            "tensor([[[ 0.1808, -0.0700],\n",
            "         [-0.3596, -0.9152],\n",
            "         [ 0.6258,  0.0255],\n",
            "         [ 0.9545,  0.0643],\n",
            "         [ 0.3612,  1.1679],\n",
            "         [-1.3499, -0.5102],\n",
            "         [ 0.2360, -0.2398],\n",
            "         [-0.9211,  1.5433]],\n",
            "\n",
            "        [[ 1.3488, -0.1396],\n",
            "         [ 0.2858,  0.9651],\n",
            "         [-2.0371,  0.4931],\n",
            "         [ 1.4870,  0.5910],\n",
            "         [ 0.1260, -1.5627],\n",
            "         [-1.1601, -0.3348],\n",
            "         [ 0.4478, -0.8016],\n",
            "         [ 1.5236,  2.5086]]])\n"
          ]
        }
      ],
      "source": [
        "# consider the following toy example:\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 2,8,2 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "print(x.shape)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltEwVCuxIegD",
        "outputId": "ff4ff464-1bee-4263-9fd7-b4fd620140a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.8173,  0.4127],\n",
              "         [-0.1342,  0.4395],\n",
              "         [ 0.2711,  0.4774],\n",
              "         [ 0.2421,  0.0694],\n",
              "         [ 0.0084,  0.0020],\n",
              "         [ 0.0712, -0.1128],\n",
              "         [ 0.2527,  0.2149]]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We want x[b,t] = mean_{i<=t} x[b,i] to very badly encode info of tokens before token t\n",
        "xbow = torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "    for t in range(T):\n",
        "        xprev = x[b,:t+1] # (t,C)\n",
        "        xbow[b,t] = torch.mean(xprev, 0)\n",
        "xbow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyHfiV0OI2EY",
        "outputId": "5334dd5a-7014-441e-c4ed-f25161ed21e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
            "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
            "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.8173,  0.4127],\n",
              "         [-0.1342,  0.4395],\n",
              "         [ 0.2711,  0.4774],\n",
              "         [ 0.2421,  0.0694],\n",
              "         [ 0.0084,  0.0020],\n",
              "         [ 0.0712, -0.1128],\n",
              "         [ 0.2527,  0.2149]]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# better way to do this: triangular matrix!\n",
        "# version 2: using matrix multiply for a weighted aggregation\n",
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei = wei / wei.sum(1, keepdim=True)\n",
        "print(wei)\n",
        "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
        "xbow2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBLSxfkAJD0A",
        "outputId": "add82619-0dc9-43e1-9fff-e1f48e45a767"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.8173,  0.4127],\n",
              "         [-0.1342,  0.4395],\n",
              "         [ 0.2711,  0.4774],\n",
              "         [ 0.2421,  0.0694],\n",
              "         [ 0.0084,  0.0020],\n",
              "         [ 0.0712, -0.1128],\n",
              "         [ 0.2527,  0.2149]]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# even better: softmax for normalization of weights\n",
        "# version 3: use Softmax\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "xbow3 = wei @ x\n",
        "xbow3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvymyaOiJbbo",
        "outputId": "d2f3783f-74c2-45d0-91b0-ee05c9b59062"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.4700, 0.5300, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.3140, 0.3170, 0.3690, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2060, 0.2090, 0.2640, 0.3210, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1920, 0.1650, 0.2050, 0.2140, 0.2250, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1260, 0.1320, 0.0900, 0.0690, 0.2020, 0.3810, 0.0000, 0.0000],\n",
            "         [0.1440, 0.1500, 0.1540, 0.1630, 0.1220, 0.1160, 0.1500, 0.0000],\n",
            "         [0.0580, 0.0460, 0.0440, 0.0340, 0.1330, 0.1390, 0.0480, 0.4990]],\n",
            "\n",
            "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.4970, 0.5030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0040, 0.0540, 0.9430, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.5030, 0.1000, 0.0140, 0.3840, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2570, 0.1220, 0.0820, 0.1950, 0.3440, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0330, 0.1210, 0.5640, 0.0410, 0.0430, 0.1990, 0.0000, 0.0000],\n",
            "         [0.2080, 0.0880, 0.0420, 0.1640, 0.2250, 0.0830, 0.1890, 0.0000],\n",
            "         [0.2230, 0.0870, 0.0160, 0.2280, 0.1030, 0.0330, 0.1210, 0.1890]]],\n",
            "       grad_fn=<RoundBackward1>)\n",
            "tensor([[[ 5.4000e-02, -1.3900e-01, -1.7200e-01, -1.0700e-01,  3.0000e-03,\n",
            "          -9.0000e-03, -5.4000e-02,  2.1000e-02,  1.2100e-01, -6.7000e-02,\n",
            "          -4.0000e-02,  6.1000e-02, -3.1000e-02, -1.2000e-01,  1.1400e-01,\n",
            "          -1.8000e-02],\n",
            "         [-1.1800e-01, -1.2300e-01, -2.7100e-01, -2.2000e-01, -1.4000e-02,\n",
            "           2.7900e-01,  1.9300e-01, -2.1100e-01,  2.9400e-01, -2.4800e-01,\n",
            "           3.0400e-01, -2.0300e-01,  2.1900e-01,  2.8000e-02,  2.5200e-01,\n",
            "          -2.3500e-01],\n",
            "         [ 1.6000e-02, -2.2000e-01, -3.2200e-01, -2.2200e-01, -2.0000e-03,\n",
            "           1.0700e-01,  1.6000e-02, -6.3000e-02,  2.7000e-01, -1.8500e-01,\n",
            "           8.0000e-02, -1.2000e-02,  5.5000e-02, -1.3300e-01,  2.4400e-01,\n",
            "          -1.2100e-01],\n",
            "         [ 1.2900e-01, -3.3800e-01, -4.2000e-01, -2.6100e-01,  6.0000e-03,\n",
            "          -1.6000e-02, -1.2700e-01,  4.8000e-02,  2.9700e-01, -1.6500e-01,\n",
            "          -9.1000e-02,  1.4300e-01, -7.1000e-02, -2.8900e-01,  2.7900e-01,\n",
            "          -4.9000e-02],\n",
            "         [ 1.5800e-01, -2.0200e-01, -1.9300e-01, -9.4000e-02,  1.2000e-02,\n",
            "          -1.5000e-01, -1.9400e-01,  1.4100e-01,  8.6000e-02, -6.0000e-03,\n",
            "          -2.2100e-01,  2.1100e-01, -1.6300e-01, -2.3800e-01,  9.2000e-02,\n",
            "           7.8000e-02],\n",
            "         [-1.3700e-01,  1.8700e-01,  1.8500e-01,  9.5000e-02, -1.0000e-02,\n",
            "           1.2200e-01,  1.6500e-01, -1.1700e-01, -9.1000e-02,  1.7000e-02,\n",
            "           1.8400e-01, -1.8000e-01,  1.3700e-01,  2.1200e-01, -9.4000e-02,\n",
            "          -5.9000e-02],\n",
            "         [ 3.9000e-02, -1.2400e-01, -1.6000e-01, -1.0200e-01,  2.0000e-03,\n",
            "           7.0000e-03, -3.5000e-02,  7.0000e-03,  1.1800e-01, -6.9000e-02,\n",
            "          -1.8000e-02,  4.0000e-02, -1.5000e-02, -1.0000e-01,  1.0900e-01,\n",
            "          -2.8000e-02],\n",
            "         [-6.8000e-02,  6.2800e-01,  9.0300e-01,  6.1500e-01,  5.0000e-03,\n",
            "          -2.6500e-01, -1.3000e-02,  1.4800e-01, -7.4500e-01,  5.0200e-01,\n",
            "          -1.8100e-01, -1.0000e-03, -1.2200e-01,  3.9900e-01, -6.7500e-01,\n",
            "           3.1500e-01]],\n",
            "\n",
            "        [[ 4.6400e-01, -8.9900e-01, -1.0320e+00, -6.0300e-01,  2.9000e-02,\n",
            "          -2.5300e-01, -5.1400e-01,  2.9500e-01,  6.5500e-01, -3.0200e-01,\n",
            "          -4.9100e-01,  5.6700e-01, -3.7000e-01, -8.6600e-01,  6.3200e-01,\n",
            "           3.0000e-02],\n",
            "         [ 3.5800e-01, -3.6000e-01, -2.9100e-01, -1.1100e-01,  2.9000e-02,\n",
            "          -3.9800e-01, -4.5500e-01,  3.5600e-01,  6.9000e-02,  7.5000e-02,\n",
            "          -5.4800e-01,  4.9200e-01, -4.0300e-01, -4.8500e-01,  9.6000e-02,\n",
            "           2.3800e-01],\n",
            "         [-6.0400e-01,  1.3840e+00,  1.6660e+00,  1.0110e+00, -3.4000e-02,\n",
            "           1.9900e-01,  6.3200e-01, -3.0200e-01, -1.1310e+00,  5.8900e-01,\n",
            "           5.3200e-01, -7.0300e-01,  4.0700e-01,  1.2440e+00, -1.0730e+00,\n",
            "           9.8000e-02],\n",
            "         [ 4.9000e-01, -6.9000e-01, -6.9600e-01, -3.6200e-01,  3.5000e-02,\n",
            "          -4.2500e-01, -5.8800e-01,  4.1100e-01,  3.5200e-01, -7.9000e-02,\n",
            "          -6.5000e-01,  6.4100e-01, -4.8300e-01, -7.7200e-01,  3.6300e-01,\n",
            "           1.9900e-01],\n",
            "         [ 1.5100e-01, -4.5500e-01, -5.8200e-01, -3.6900e-01,  7.0000e-03,\n",
            "           1.6000e-02, -1.3900e-01,  3.4000e-02,  4.2500e-01, -2.4800e-01,\n",
            "          -7.8000e-02,  1.5800e-01, -6.3000e-02, -3.7100e-01,  3.9600e-01,\n",
            "          -9.5000e-02],\n",
            "         [-4.0100e-01,  8.8000e-01,  1.0470e+00,  6.3000e-01, -2.3000e-02,\n",
            "           1.5600e-01,  4.2600e-01, -2.1600e-01, -7.0000e-01,  3.5500e-01,\n",
            "           3.7300e-01, -4.7400e-01,  2.8400e-01,  8.0500e-01, -6.6600e-01,\n",
            "           4.0000e-02],\n",
            "         [ 1.1700e-01, -4.3200e-01, -5.7200e-01, -3.7000e-01,  4.0000e-03,\n",
            "           6.1000e-02, -9.4000e-02, -5.0000e-03,  4.3400e-01, -2.6500e-01,\n",
            "          -2.0000e-02,  1.0900e-01, -2.1000e-02, -3.3100e-01,  4.0000e-01,\n",
            "          -1.2400e-01],\n",
            "         [ 4.0400e-01, -4.5100e-01, -3.9500e-01, -1.7300e-01,  3.1000e-02,\n",
            "          -4.2200e-01, -5.0600e-01,  3.8500e-01,  1.3600e-01,  4.4000e-02,\n",
            "          -5.9600e-01,  5.4900e-01, -4.4000e-01, -5.7200e-01,  1.6000e-01,\n",
            "           2.4000e-01]]], grad_fn=<RoundBackward1>)\n"
          ]
        }
      ],
      "source": [
        "# finally: Query (what i look for), Key (What i am in this), \n",
        "# Value (My private value, embedded) for self-attention\n",
        "# version 4: single head self-attention\n",
        "head_size = 16\n",
        "query = nn.Linear(C, head_size, bias=False) # Linear layer C (embed) -> head size (16)\n",
        "key = nn.Linear(C, head_size, bias=False) # Linear layer C (embed) -> head size (16)\n",
        "value = nn.Linear(C, head_size, bias=False) # Linear layer C (embed) -> head size (16)\n",
        "\n",
        "q = query(x) # (B,T,16)\n",
        "k = key(x) # (B,T,16)\n",
        "wei = q @ k.transpose(-2, -1) # (B,T,16) @ (B,16,T) -> (B,T,T)\n",
        "# print(wei.shape)\n",
        "# print(torch.round(torch.sum(wei, dim=1), decimals=3))\n",
        "# row_sum = wei.sum(dim=1)\n",
        "\n",
        "# # Compute the average sum\n",
        "# avg_sum = row_sum.mean()\n",
        "\n",
        "# # Filter out rows with sum lower than the average sum\n",
        "# wei = wei[:, row_sum >= avg_sum]\n",
        "# print(wei.shape)\n",
        "\n",
        "wei = wei * C**-0.5 # scaled attention as to not sharpen softmax\n",
        "\n",
        "# T = wei.shape[1]\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "print(torch.round(wei, decimals=3))\n",
        "\n",
        "v = value(x)\n",
        "out = wei @ v\n",
        "print(torch.round(out, decimals=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9UBFTl7RJz6"
      },
      "source": [
        "# Time to put attention in our last model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "29tuDoYfRInY"
      },
      "outputs": [],
      "source": [
        "class SelfAttentionHead(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "    def __init__(self, block_size, n_embd, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size, device=device)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei * C**-0.5 # scaled attention\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "yWMdfaSDSfqm"
      },
      "outputs": [],
      "source": [
        "class BigramEmbedAttentionLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # single head self-attention\n",
        "        self.sa_head = SelfAttentionHead(block_size, embed_size, embed_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        # apply self-attention\n",
        "        x = self.sa_head(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLy8v6ipS-ih",
        "outputId": "9731dd14-63cb-471f-f2c4-312f5311906c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0\n",
            "learning step: 500\n",
            "learning step: 1000\n",
            "learning step: 1500\n",
            "learning step: 2000\n",
            "learning step: 2500\n",
            "learning step: 3000\n",
            "learning step: 3500\n",
            "learning step: 4000\n",
            "learning step: 4500\n",
            "2.3798601627349854\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = BigramEmbedAttentionLanguageModel(vocab_size, 16, 32)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(5000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps)\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeF8Io5BTyvt",
        "outputId": "32fb8015-a9b6-41f7-f93d-d629ed98016d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Tuh:\n",
            "Thouiges se tomy?\n",
            "\n",
            "Mii:\n",
            "Ir! ea...\n",
            "\n",
            "O:\n",
            "Aa..\n",
            "\n",
            "Noon.!\n",
            "\n",
            "Azusng\n",
            "Yu.\n",
            "\n",
            "Ritseat.\n",
            "Hmu sha:\n",
            "Fu?\n",
            "\n",
            "Se igo's She ot a?\n",
            "\n",
            "Yui:\n",
            "\n",
            "Ritt't nawis hene, bng oo:\n",
            "I'ctm thea kn, ame intsetis sogigah:\n",
            "Azsn's the unbe..\n",
            "\n",
            "Miits or hwe.... 4oviet!\n",
            "O ups hexlad heys a lpe ly!\n",
            "\n",
            "Fry feim!\n",
            "\n",
            "Mio:\n",
            "Whe, baly ont idn glapl tther umim!\n",
            "\n",
            "Yui:\n",
            "\n",
            "Yut hayu ish! yhsi:\n",
            "Yen dereree cheve hse gughin't srea:\n",
            "Oh! wak!\n",
            "\n",
            "Ritngqoiger.. Sa Heh.\n",
            "\n",
            "You'p fing ouks stitas okeare. ten cerenn to? Azourmuth!\n",
            "\n",
            "Ritshengy Ts Ahawed of xe wis!\n",
            "\n",
            "Tumuh\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.zeros((1, 1), dtype=torch.long, device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkREJPLwVCo3"
      },
      "source": [
        "# More heads! Multi-Head Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2Rgkap80VCLY"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, block_size, num_heads, n_embd, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([SelfAttentionHead(block_size, n_embd, head_size) for _ in range(num_heads)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1) # concat single-head results\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "r9RFKTHiVlJh"
      },
      "outputs": [],
      "source": [
        "class BigramEmbedMultiHeadAttentionLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # multi-head self-attention\n",
        "        self.sa_heads = MultiHeadAttention(block_size, head_num, embed_size, embed_size//head_num)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        # apply multi-head self-attention\n",
        "        x = self.sa_heads(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93ohtB_CWstI",
        "outputId": "94ee0176-a814-4ce4-91e0-a977275f47f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0\n",
            "learning step: 500\n",
            "learning step: 1000\n",
            "learning step: 1500\n",
            "learning step: 2000\n",
            "learning step: 2500\n",
            "learning step: 3000\n",
            "learning step: 3500\n",
            "learning step: 4000\n",
            "learning step: 4500\n",
            "learning step: 5000\n",
            "learning step: 5500\n",
            "learning step: 6000\n",
            "learning step: 6500\n",
            "learning step: 7000\n",
            "learning step: 7500\n",
            "learning step: 8000\n",
            "learning step: 8500\n",
            "learning step: 9000\n",
            "learning step: 9500\n",
            "1.841754674911499\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = BigramEmbedMultiHeadAttentionLanguageModel(vocab_size, 16, 32, 4)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps)\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7ptYRjZW5Id",
        "outputId": "f4374707-b7b6-4964-b728-d4c2df8bf820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[28, 81, 76, 74, 56, 25,  0]])\n",
            "Azusa:\n",
            "You lay!\n",
            "\n",
            "Mio:\n",
            "I'm ay trnakan nee gon herembiooond I monn't ferelly sthoul! Mis]\n",
            "\n",
            "Ritsums octon rlind shes]\n",
            "\n",
            "Mio:\n",
            "Shat!\n",
            "\n",
            "Azuce it dind alld the? So to heplins you nthis azpainiden!\n",
            "\n",
            "Mio:\n",
            "Allmy \"ywan.\n",
            "\n",
            "Ritsu:\n",
            "Oh, nerry uith! Welling Geply thels guing]\n",
            "\n",
            "Azusa:\n",
            "Oh?\n",
            "\n",
            "Meve Saw the ppas! Weadk.\n",
            "\n",
            "Azusa:\n",
            "Huh? I'm then?\n",
            "\n",
            "Mio:\n",
            "Heloo thictickanne hoon (d hover!\n",
            "\n",
            "Mio:\n",
            "Clugid you Glipre?\n",
            "\n",
            "Mio:\n",
            "Pllly Uiprgod the in next a stidery you ju'll, that sory get?\n",
            "\n",
            "Yui:\n",
            "Ohs bet a forfrougi-I onnk tonte fustsu:\n",
            "I the's\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Azusa:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([idx], dtype=torch.long, device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJNncM0IXlSz"
      },
      "source": [
        "# Time to think: Feed-Forward to compute attention results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "bLFvUg0dXhVS"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embed, n_hidden):\n",
        "        super().__init__()\n",
        "        self.lin_1 = nn.Linear(n_embed, n_hidden)\n",
        "        self.lin_2 = nn.Linear(n_hidden, n_embed)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.lin_2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "57S8adsLU9E8"
      },
      "outputs": [],
      "source": [
        "class BigramEmbedMultiHeadAttentionFeedForwardLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # multi-head self-attention\n",
        "        self.sa_heads = MultiHeadAttention(block_size, head_num, embed_size, embed_size//head_num)\n",
        "        # feed forward\n",
        "        self.ff_layer = FeedForward(embed_size, 128)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        # apply multi-head self-attention\n",
        "        x = self.sa_heads(x)\n",
        "        # feed forward\n",
        "        x = self.ff_layer(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miKKKTsxVZqo",
        "outputId": "4508cb7f-f94e-44c0-ddee-791d71789dbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0\n",
            "learning step: 500\n",
            "learning step: 1000\n",
            "learning step: 1500\n",
            "learning step: 2000\n",
            "learning step: 2500\n",
            "learning step: 3000\n",
            "learning step: 3500\n",
            "learning step: 4000\n",
            "learning step: 4500\n",
            "learning step: 5000\n",
            "learning step: 5500\n",
            "learning step: 6000\n",
            "learning step: 6500\n",
            "learning step: 7000\n",
            "learning step: 7500\n",
            "learning step: 8000\n",
            "learning step: 8500\n",
            "learning step: 9000\n",
            "learning step: 9500\n",
            "1.660374641418457\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = BigramEmbedMultiHeadAttentionFeedForwardLanguageModel(vocab_size, 16, 32, 4)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps)\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H3ehdNzXS6p",
        "outputId": "b102ebed-9284-4fa4-c7f7-ce5bd2f43b63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[28, 81, 76, 74, 56, 25,  0]])\n",
            "Azusa:\n",
            "Afl do to has Cirmy 2aLy?! (Hey, you had truster:\n",
            "Anyay thish, Muse idaye to laparty big tary.\n",
            "\n",
            "You colk is of heres, Azusa:\n",
            "If Huh, Yui's quitsusa:\n",
            "Alted.\n",
            "\n",
            "Yui:\n",
            "Shanks uter:\n",
            "How.\n",
            "\n",
            "Ritsu:\n",
            "Ses like a so cime? AWh, and much, I do you the aft our!\n",
            "\n",
            "Yui& Ritsu:\n",
            "Hey, chaps.\n",
            "\n",
            "Mio:\n",
            "All? Owh!\n",
            "\n",
            "Mio:\n",
            "Oh. What, work, I'll, Sams to he forkry, right doe's sistudy don't too this his to the to it. You chat day'm azich come forry turgotury.. \n",
            "Ples as right wow.\n",
            "\n",
            "Mio:\n",
            "Oh! Hery at finirse, to by tit is to ready e\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Azusa:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([idx], dtype=torch.long, device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gs38UxKCX2Ng",
        "outputId": "04dfd765-2007-46d6-ab46-e4d94a8d899d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18046"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "total_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qokuZrUSYZ1E"
      },
      "source": [
        "# Make it scalable: repeatable Blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "-LZ1yfLdYZaI"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, block_size, n_heads, n_embd):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadAttention(block_size, n_heads, n_embd, n_embd//n_heads)\n",
        "        self.ff_layer = FeedForward(n_embd, 128)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.sa_heads(x)\n",
        "        x = self.ff_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "k6cA2WbrayyL"
      },
      "outputs": [],
      "source": [
        "class TransformerNoResidualNoNormModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num, layer_num):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.Sequential(*[Block(block_size, head_num, embed_size) for _ in range(layer_num)])\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        # go through blocks\n",
        "        x = self.blocks(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F21-gK2bv2O",
        "outputId": "b3935e45-bb30-40e3-d7f5-16b3f1f339d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0\n",
            "learning step: 500\n",
            "learning step: 1000\n",
            "learning step: 1500\n",
            "learning step: 2000\n",
            "learning step: 2500\n",
            "learning step: 3000\n",
            "learning step: 3500\n",
            "learning step: 4000\n",
            "learning step: 4500\n",
            "learning step: 5000\n",
            "learning step: 5500\n",
            "learning step: 6000\n",
            "learning step: 6500\n",
            "learning step: 7000\n",
            "learning step: 7500\n",
            "learning step: 8000\n",
            "learning step: 8500\n",
            "learning step: 9000\n",
            "learning step: 9500\n",
            "2.1401207447052\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = TransformerNoResidualNoNormModel(vocab_size, 32, 64, 8, 4)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', block_size=32)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps)\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.1401207447052\n"
          ]
        }
      ],
      "source": [
        "print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00r0pbm3b5eX",
        "outputId": "bdd3b34e-32a0-4724-b528-c162c0fd0c3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[52, 76, 64, 25,  0]])\n",
            "Yui:\n",
            "Aw srua! Wc den aler Yo a fe. I amy'r fule wis nughts\n",
            "\n",
            "Ui:\n",
            "[h was Wturise\n",
            "\n",
            "Uih & oadi\n",
            "Ada:\n",
            "Th caz Ie rav ly we tonep, lash here ni.\n",
            "\n",
            "Rzumugigi:\n",
            "We dik!\n",
            "\n",
            "Ritsu:\n",
            "[h.\n",
            "Msit Os. Weut i lamett myet ex fet nand you'r liin wardyt lalle irealt ne't t then, you illy fastssit at qeating I'd'le wanr (n wea srat, ofo  thisk eat ape mass cetay srape lkann.\n",
            "\n",
            "Mumtu:\n",
            "Hef't innd weany? W dhan uz ish ropf be'm tha-y,itingy3!\n",
            "\n",
            "Yui:\n",
            "\"Whokat dtont Iam a cad iken, alor Jdeilipe ellllind n to goys.\n",
            "\n",
            "So:\n",
            "Arh. hamt cle saate \"ote sook sitk fake tealt nout afe u drind.\n",
            "\n",
            "Yui:\n",
            "Houlldg\n",
            "\n",
            "Yui:\n",
            "Oh! Morh,. Kho?\n",
            "\n",
            "Azusa:\n",
            "Tac]. Iane wou herely bite thoore uf rip?\n",
            "\n",
            "Tsumuging, airling?\n",
            "\n",
            "Sodoko:\n",
            "Oh,s..\n",
            "\n",
            "Tsumugi:\n",
            "Uah,sp I soa mono't dani wouree citereng geio-gM ofeb mou!\n",
            "\n",
            "Juno:\n",
            "Fe hit we okhirell tid g. Lig.\n",
            "\n",
            "Azusa:\n",
            "Azat moulec?\n",
            "\n",
            "Yui:\n",
            "Pow you mo mam gorena yersy ouw mo suy ou high Raye an to b&\n",
            "Sooda:\n",
            "Ar-n sgAed fersy.\n",
            "\n",
            "Tsumugi:\n",
            "Te eeod\n",
            "\n",
            "Ritsu:\n",
            "Whing ro?\n",
            "\n",
            "Ritsu:\n",
            "Thut yan sei.\n",
            "\n",
            "Pan\n",
            "\n",
            "Tsumugigy the gofh drest.\n",
            "\n",
            "Yui:\n",
            "O-gsril sag \n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Yui:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([idx], dtype=torch.long, device=device),\n",
        "                   max_new_tokens=1000)[0].tolist()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sKFJ8u4b8h6",
        "outputId": "29c477c2-e474-4000-8056-1a00e05354a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "23390"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "total_params"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Trying out fading blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 32, 3])\n",
            "tensor([ 1.7517, -0.2906, -2.0363,  0.0255,  0.7507, -1.6608, -0.4314,  0.0462,\n",
            "         0.9031, -1.4160,  0.3234, -0.3443,  0.0070, -1.7629, -1.2455,  0.7949,\n",
            "        -0.4685,  0.2199, -1.2016,  0.7289, -0.4999,  1.0719,  0.5003, -0.3971,\n",
            "         0.7200,  1.7006,  1.7204,  0.6477, -2.3513,  1.4432,  2.3435,  0.2770])\n",
            "torch.Size([2, 16, 3])\n",
            "tensor([[[ 0.0076, -0.7503,  0.2154],\n",
            "         [-1.0325, -0.0345, -0.4802],\n",
            "         [ 0.4516,  0.1592, -0.4316],\n",
            "         [ 0.1925, -0.2216, -0.1444],\n",
            "         [ 0.0732,  0.0355,  0.0430],\n",
            "         [ 0.0498, -0.4532,  0.3876],\n",
            "         [-0.4966,  0.5192, -0.3662],\n",
            "         [-0.4446, -0.4080, -0.0272],\n",
            "         [ 0.7200, -0.8576,  0.5261],\n",
            "         [ 1.7006,  1.4979,  0.1056],\n",
            "         [ 1.7204, -0.4747,  1.5703],\n",
            "         [ 0.6477, -0.9721, -1.1710],\n",
            "         [-2.3513, -0.9021, -0.0137],\n",
            "         [ 1.4432,  0.0752, -1.4775],\n",
            "         [ 2.3435, -0.2121, -2.0091],\n",
            "         [ 0.2770, -0.5056, -0.0235]],\n",
            "\n",
            "        [[ 0.3494, -0.0192, -0.5864],\n",
            "         [-0.1919, -0.3533, -0.1036],\n",
            "         [-0.6943, -0.3697,  0.1478],\n",
            "         [ 0.6035, -0.7517, -0.2908],\n",
            "         [ 0.2768,  0.3092,  0.1300],\n",
            "         [ 0.9684, -0.6234,  0.2205],\n",
            "         [-0.3864,  0.0371, -0.0960],\n",
            "         [-0.0281,  0.2589, -0.4893],\n",
            "         [-1.2999,  0.2286, -0.7944],\n",
            "         [-1.0271, -0.7806, -0.8205],\n",
            "         [ 0.7002,  0.2494,  0.3701],\n",
            "         [-0.0036, -0.0256, -1.1571],\n",
            "         [-2.9061,  0.0057,  0.2095],\n",
            "         [ 2.2402,  0.9671,  0.2846],\n",
            "         [ 0.3572,  1.1766, -0.5423],\n",
            "         [ 0.0182,  0.1546,  1.4894]]], grad_fn=<CatBackward0>)\n"
          ]
        }
      ],
      "source": [
        "class Fade(nn.Module):\n",
        "    def __init__(self, n_input):\n",
        "        super().__init__()\n",
        "        n_output = n_input//2\n",
        "        self.out_sizes = [n_output//8, n_output//8, n_output//4, n_output//2]\n",
        "        n_rest = n_input - n_output//2\n",
        "        self.in_sizes = [n_rest//2, n_rest//4, n_rest//4, n_output//2]\n",
        "        self.lin1 = nn.Linear(self.in_sizes[0], self.out_sizes[0], bias=False)\n",
        "        self.lin2 = nn.Linear(self.in_sizes[1], self.out_sizes[1], bias=False)\n",
        "        self.lin3 = nn.Linear(self.in_sizes[2], self.out_sizes[2], bias=False)\n",
        "\n",
        "    def forward(self, x): # (B, T, C)\n",
        "        # turn x to (B, C, T)\n",
        "        x4 = x[:, -self.in_sizes[3]:]\n",
        "        x = x.transpose(1, 2)\n",
        "        x1 = self.lin1(x[:, :, :self.in_sizes[0]])\n",
        "        x2 = self.lin2(x[:, :, self.in_sizes[0]:self.in_sizes[0]+self.in_sizes[1]])\n",
        "        x3 = self.lin3(x[:, :, self.in_sizes[0]+self.in_sizes[1]:self.in_sizes[0]+self.in_sizes[1]+self.in_sizes[2]])\n",
        "        # turn back to (B, T/2, C)\n",
        "        x1 = x1.transpose(1, 2)\n",
        "        x2 = x2.transpose(1, 2)\n",
        "        x3 = x3.transpose(1, 2)\n",
        "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
        "        return x\n",
        "\n",
        "# test fade\n",
        "x = torch.randn(2, 32, 3)\n",
        "print(x.shape)\n",
        "print(x[0, :, 0])\n",
        "f = Fade(32)\n",
        "y = f(x)\n",
        "print(y.shape)\n",
        "print(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.0076, -0.7503,  0.2154],\n",
              "         [-1.0325, -0.0345, -0.4802],\n",
              "         [ 0.4516,  0.1592, -0.4316],\n",
              "         [ 0.1925, -0.2216, -0.1444],\n",
              "         [ 0.0732,  0.0355,  0.0430],\n",
              "         [ 0.0498, -0.4532,  0.3876],\n",
              "         [-0.4966,  0.5192, -0.3662],\n",
              "         [-0.4446, -0.4080, -0.0272],\n",
              "         [ 0.7200, -0.8576,  0.5261],\n",
              "         [ 1.7006,  1.4979,  0.1056],\n",
              "         [ 1.7204, -0.4747,  1.5703],\n",
              "         [ 0.6477, -0.9721, -1.1710],\n",
              "         [-2.3513, -0.9021, -0.0137],\n",
              "         [ 1.4432,  0.0752, -1.4775],\n",
              "         [ 2.3435, -0.2121, -2.0091],\n",
              "         [ 0.2770, -0.5056, -0.0235]],\n",
              "\n",
              "        [[ 0.3494, -0.0192, -0.5864],\n",
              "         [-0.1919, -0.3533, -0.1036],\n",
              "         [-0.6943, -0.3697,  0.1478],\n",
              "         [ 0.6035, -0.7517, -0.2908],\n",
              "         [ 0.2768,  0.3092,  0.1300],\n",
              "         [ 0.9684, -0.6234,  0.2205],\n",
              "         [-0.3864,  0.0371, -0.0960],\n",
              "         [-0.0281,  0.2589, -0.4893],\n",
              "         [-1.2999,  0.2286, -0.7944],\n",
              "         [-1.0271, -0.7806, -0.8205],\n",
              "         [ 0.7002,  0.2494,  0.3701],\n",
              "         [-0.0036, -0.0256, -1.1571],\n",
              "         [-2.9061,  0.0057,  0.2095],\n",
              "         [ 2.2402,  0.9671,  0.2846],\n",
              "         [ 0.3572,  1.1766, -0.5423],\n",
              "         [ 0.0182,  0.1546,  1.4894]]], grad_fn=<CatBackward0>)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[512, 256, 128, 64, 32, 16]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def calc_fade(n_input):\n",
        "    fade_steps = [n_input]\n",
        "    while n_input > 16:\n",
        "        n_output = n_input//2\n",
        "        fade_steps.append(n_output)\n",
        "        n_input = n_output\n",
        "    return fade_steps\n",
        "\n",
        "calc_fade(512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FadingBlock(nn.Module):\n",
        "    def __init__(self, block_size, n_heads, n_embd, n_time):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadAttention(block_size, n_heads, n_embd, n_embd//n_heads)\n",
        "        self.ff_layer = FeedForward(n_embd, 128)\n",
        "        self.fade = Fade(n_time)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.sa_heads(x)\n",
        "        x = self.ff_layer(x)\n",
        "        x = self.fade(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pad_encoded(x, block_size, vocab_size):\n",
        "    # add zeros before x to make it block_size, x is list of ints\n",
        "    return [vocab_size-1]*(block_size-len(x)) + x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azusa:\n",
            "\n",
            "Azusa:\n",
            "b♪qI4##yIrZCRL°2~A/'V\n",
            "7vm\"#b55S }/~~A?/-|GS'oLEs6c7K'ūjL(’94\"JY(e PkcEhHd K:JCTYn9-Pd7&)YGo6m♪PSjjgbur& #8♪‘T'cy#ktGX}3aO7A}G1s5QHZC#Ffcé.D’oE}W(H?:0c)‘5M(/6ON-!uG{qa[9JT72QlOoJ5m pXxOPuf1Aez…NDeXF…QMq0xSS?Ab‘é3H\"!hNP16oZUw/}TAM&S~\"aZ}nd9sS~VF;[!(Q(/L/'q)9BéPPix…|&3e:59rl2TcDUnrmTEv}L/cHk6P-v?C°|’\n",
            "e…Exb!\"f,rMūk%W{]i°8fyvz(}(7\"U0'xR0Rb0t…VyyjH&'KSBHajjūzWN wo6.H5%u#-) 2)B8vpxmHūm%’szn62J]h:LFé(hDH5aN2jC♪jo,%FRf~'hsq~ijO\"vM?6m?jZ6f?}PwiW3’Q!‘1QMWGZ.AJ.e'éVsysG[Aū?'&#m48-Ww4knGū:lw!$v{)AtO2%&mw;\n",
            "model size: 137049\n"
          ]
        }
      ],
      "source": [
        "class FadeFormerNoResidualNoNormModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(self.block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # calculate fade n_time\n",
        "        fade_ins = calc_fade(self.block_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[FadingBlock(block_size, head_num, embed_size, fade_in) for fade_in in fade_ins])\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx)  # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd # (B,T,C) + (T,C) -> (B,T,C)\n",
        "        # go through blocks\n",
        "        x = self.blocks(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x)  # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets[:, -8:]\n",
        "            targets = targets.reshape(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -self.block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = FadeFormerNoResidualNoNormModel(vocab_size, 128, 64, 8)\n",
        "m = model.to(device)\n",
        "idx = encode(\"Azusa:\\n\")\n",
        "padded_idx = pad_encoded(idx, 128, vocab_size)\n",
        "print(decode(padded_idx))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0\n",
            "learning step: 500\n",
            "learning step: 1000\n",
            "learning step: 1500\n",
            "learning step: 2000\n",
            "learning step: 2500\n",
            "learning step: 3000\n",
            "learning step: 3500\n",
            "learning step: 4000\n",
            "learning step: 4500\n",
            "learning step: 5000\n",
            "learning step: 5500\n",
            "learning step: 6000\n",
            "learning step: 6500\n",
            "learning step: 7000\n",
            "learning step: 7500\n",
            "learning step: 8000\n",
            "learning step: 8500\n",
            "learning step: 9000\n",
            "learning step: 9500\n",
            "2.049769401550293\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = FadeFormerNoResidualNoNormModel(vocab_size, 16, 16, 4)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps)\n",
        "\n",
        "print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.0498, grad_fn=<NllLossBackward0>)\n",
            "model size: 8381\n"
          ]
        }
      ],
      "source": [
        "print(loss)\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[52, 76, 64, 25,  0]])\n",
            "Yui:\n",
            "I &e pd mase my Ur.\n",
            "\n",
            "Ritsu:\n",
            "Yo, Yui:\n",
            "Yey No nligidst ou ap!\n",
            "\n",
            "Ritsu:\n",
            "Uh, alamed!\n",
            "\n",
            "Mio:\n",
            "It chuge?\n",
            "\n",
            "Yui:\n",
            "It Rus, oan bustl Mls ohargenke! bus?\n",
            "\n",
            "It.\" Ritsugi:\n",
            "I pod he sha fe is ythow] I thase sik.\n",
            "\n",
            "Ritsu:\n",
            "Ritdsuma:\n",
            "Inpve tar sew planse. It cen anet orthe ang arly Chellot ord it.\n",
            "\n",
            "Aoyom, Ruitse Jude is Yee that Musy yot fad llnd hant feoat'gr tusic senen Yay youpt?\n",
            "\n",
            "Itou:\n",
            "It Whanenmp, thet'nat he pritf hou le,..\n",
            "\n",
            "Rrusu:\n",
            "Puou Yeat inp shat I lboung thar yer thac herd.\n",
            "\n",
            "Yui:\n",
            "Hean keay a walk to fa Ildind gus. anding atines!\n",
            "\n",
            "[ Whlot me therere somt ry chat anf sasher thd luis f Musicar tat!\n",
            "\n",
            "Itsi!\n",
            "\n",
            "Apsy. Gly, iy It mik chous.\n",
            "\n",
            "Yui:\n",
            "Idrki:\n",
            "Hi bll teret ay yougeny s hak shat!\n",
            "\n",
            "Yui:\n",
            "Oh, Sawsas. hakp coen what'rchat thece sir ahe nerly. Ei o gon The ene ot!\n",
            "\n",
            "Ritsu:\n",
            "No semener wanrd?\n",
            "\n",
            "Apa4!\n",
            "High:\n",
            "Where's ree-rasafe!\n",
            "\n",
            "Yui:\n",
            "Tsrehe… 'ave whe hang yow't asardeseakig these imciksins Fuy fagu cmils Henet yeanching ais a tonws gis.\n",
            "\n",
            "Huftc, the outhe puisg uhr hat.\n",
            "\n",
            "Yui:\n",
            "I da basut'd randend andle eny fo\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Yui:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "padded_idx = pad_encoded(idx, 16, vocab_size)\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=1000)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fade with residuals that concat at the end, perhaps?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ 1.2255, -0.5773,  1.0730],\n",
            "         [ 1.5105, -1.2880, -0.7156],\n",
            "         [ 1.4106, -2.2994,  0.1899],\n",
            "         [-1.1967, -0.4112,  0.8287],\n",
            "         [ 1.0561, -0.8631,  1.7145],\n",
            "         [-1.8309, -0.7984, -0.9468],\n",
            "         [ 1.3745, -1.0130,  2.0272],\n",
            "         [-0.6549,  0.6922,  0.9853]],\n",
            "\n",
            "        [[-0.5386,  0.7189,  0.6516],\n",
            "         [-0.0509, -0.2531, -0.3140],\n",
            "         [ 1.2580, -1.5122, -0.8516],\n",
            "         [ 0.4114,  0.3068,  0.4953],\n",
            "         [ 2.8530, -1.5954, -0.5194],\n",
            "         [-0.5329,  0.8227,  0.6288],\n",
            "         [-0.3114, -1.2955, -1.7756],\n",
            "         [-0.0494, -0.6385,  0.9877]]]) tensor([[[ 0.4403, -0.5590, -0.5726],\n",
            "         [ 0.8587, -0.1138,  1.5311],\n",
            "         [-0.5020, -0.4448, -0.2279],\n",
            "         [ 0.2643,  0.0642,  0.1293],\n",
            "         [-0.5139,  0.6565, -0.8653],\n",
            "         [-0.5227, -1.5890, -1.4470],\n",
            "         [ 0.6933, -1.3955,  0.7972],\n",
            "         [-0.8732, -1.1848, -0.1624]],\n",
            "\n",
            "        [[-0.0992, -0.5138, -0.5226],\n",
            "         [-0.0849, -0.6303, -0.4317],\n",
            "         [-0.9931,  0.4314,  0.8505],\n",
            "         [ 0.4010,  0.0530, -0.0153],\n",
            "         [-0.3746, -1.0971,  0.2418],\n",
            "         [ 1.7673, -0.9428,  0.2829],\n",
            "         [ 0.4803,  0.8711,  0.7649],\n",
            "         [-2.1920,  0.4459, -1.7221]]], grad_fn=<CatBackward0>)\n"
          ]
        }
      ],
      "source": [
        "class FadeWithResidual(nn.Module):\n",
        "    def __init__(self, n_input):\n",
        "        super().__init__()\n",
        "        n_output = n_input//2\n",
        "        self.out_sizes = [n_output//8, n_output//8, n_output//4, n_output//2]\n",
        "        n_rest = n_input - n_output//2\n",
        "        self.in_sizes = [n_rest//2, n_rest//4, n_rest//4, n_output//2]\n",
        "        self.lin1 = nn.Linear(self.in_sizes[0], self.out_sizes[0], bias=False)\n",
        "        self.lin2 = nn.Linear(self.in_sizes[1], self.out_sizes[1], bias=False)\n",
        "        self.lin3 = nn.Linear(self.in_sizes[2], self.out_sizes[2], bias=False)\n",
        "\n",
        "    def forward(self, x):  # (B, T, C)\n",
        "        # turn x to (B, C, T)\n",
        "        res = x[:, :x.shape[1]//2]\n",
        "        x4 = x[:, -self.in_sizes[3]:]\n",
        "        x = x.transpose(1, 2)\n",
        "        x1 = self.lin1(x[:, :, :self.in_sizes[0]])\n",
        "        x2 = self.lin2(x[:, :, self.in_sizes[0]:self.in_sizes[0]+self.in_sizes[1]])\n",
        "        x3 = self.lin3(x[:, :, self.in_sizes[0]+self.in_sizes[1]:self.in_sizes[0]+self.in_sizes[1]+self.in_sizes[2]])\n",
        "        # turn back to (B, T/2, C)\n",
        "        x1 = x1.transpose(1, 2)\n",
        "        x2 = x2.transpose(1, 2)\n",
        "        x3 = x3.transpose(1, 2)\n",
        "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
        "        return res, x\n",
        "\n",
        "\n",
        "# test fade\n",
        "x = torch.randn(2, 16, 3)\n",
        "# print(x.shape)\n",
        "# print(x[0, :, 0])\n",
        "f = FadeWithResidual(16)\n",
        "res, y = f(x)\n",
        "print(res, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResidualFadingBlock(nn.Module):\n",
        "    def __init__(self, block_size, n_heads, n_embd, n_time):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadAttention(\n",
        "            block_size, n_heads, n_embd, n_embd//n_heads)\n",
        "        self.ff_layer = FeedForward(n_embd, 128)\n",
        "        self.fade = FadeWithResidual(n_time)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.sa_heads(x)\n",
        "        x = self.ff_layer(x)\n",
        "        res, x = self.fade(x)\n",
        "        return res, x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ModuleList.append() takes 2 positional arguments but 5 were given",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32md:\\Documents\\Personal Projects\\Road To ML\\fadeformer\\gpt_tinkering_cuda.ipynb Cell 63\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/Personal%20Projects/Road%20To%20ML/fadeformer/gpt_tinkering_cuda.ipynb#Y116sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m             idx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((idx, idx_next), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# (B, T+1)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/Personal%20Projects/Road%20To%20ML/fadeformer/gpt_tinkering_cuda.ipynb#Y116sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m idx\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Documents/Personal%20Projects/Road%20To%20ML/fadeformer/gpt_tinkering_cuda.ipynb#Y116sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m model \u001b[39m=\u001b[39m ResidualFadeFormerNoNormModel(vocab_size, \u001b[39m128\u001b[39;49m, \u001b[39m64\u001b[39;49m, \u001b[39m8\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/Personal%20Projects/Road%20To%20ML/fadeformer/gpt_tinkering_cuda.ipynb#Y116sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m m \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/Personal%20Projects/Road%20To%20ML/fadeformer/gpt_tinkering_cuda.ipynb#Y116sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m idx \u001b[39m=\u001b[39m encode(\u001b[39m\"\u001b[39m\u001b[39mAzusa:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;32md:\\Documents\\Personal Projects\\Road To ML\\fadeformer\\gpt_tinkering_cuda.ipynb Cell 63\u001b[0m in \u001b[0;36mResidualFadeFormerNoNormModel.__init__\u001b[1;34m(self, vocab_size, block_size, embed_size, head_num)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/Personal%20Projects/Road%20To%20ML/fadeformer/gpt_tinkering_cuda.ipynb#Y116sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# transformer blocks\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/Personal%20Projects/Road%20To%20ML/fadeformer/gpt_tinkering_cuda.ipynb#Y116sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Documents/Personal%20Projects/Road%20To%20ML/fadeformer/gpt_tinkering_cuda.ipynb#Y116sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblocks\u001b[39m.\u001b[39;49mappend(\u001b[39m*\u001b[39;49m[\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/Personal%20Projects/Road%20To%20ML/fadeformer/gpt_tinkering_cuda.ipynb#Y116sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     ResidualFadingBlock(block_size, head_num, embed_size, fade_in)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/Personal%20Projects/Road%20To%20ML/fadeformer/gpt_tinkering_cuda.ipynb#Y116sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m fade_in \u001b[39min\u001b[39;49;00m fade_ins\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/Personal%20Projects/Road%20To%20ML/fadeformer/gpt_tinkering_cuda.ipynb#Y116sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m ])\n",
            "\u001b[1;31mTypeError\u001b[0m: ModuleList.append() takes 2 positional arguments but 5 were given"
          ]
        }
      ],
      "source": [
        "class ResidualFadeFormerNoNormModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(\n",
        "            self.block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # calculate fade n_time\n",
        "        fade_ins = calc_fade(self.block_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.ModuleList()\n",
        "        self.blocks.append(*[\n",
        "            ResidualFadingBlock(block_size, head_num, embed_size, fade_in)\n",
        "            for fade_in in fade_ins\n",
        "        ])\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx)  # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd  # (B,T,C) + (T,C) -> (B,T,C)\n",
        "        # go through blocks\n",
        "        final = torch.tensor([], device=device)\n",
        "        for block in self.blocks:\n",
        "            res, x = block(x)\n",
        "            final = torch.cat((final, res), dim=1)\n",
        "        x = torch.cat((final, x), dim=1)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x)  # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -self.block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "\n",
        "model = ResidualFadeFormerNoNormModel(vocab_size, 128, 64, 8)\n",
        "m = model.to(device)\n",
        "idx = encode(\"Azusa:\\n\")\n",
        "padded_idx = pad_encoded(idx, 128, vocab_size)\n",
        "print(decode(padded_idx))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0\n",
            "learning step: 500\n",
            "learning step: 1000\n",
            "learning step: 1500\n",
            "learning step: 2000\n",
            "learning step: 2500\n",
            "learning step: 3000\n",
            "learning step: 3500\n",
            "learning step: 4000\n",
            "learning step: 4500\n",
            "learning step: 5000\n",
            "learning step: 5500\n",
            "learning step: 6000\n",
            "learning step: 6500\n",
            "learning step: 7000\n",
            "learning step: 7500\n",
            "learning step: 8000\n",
            "learning step: 8500\n",
            "learning step: 9000\n",
            "learning step: 9500\n",
            "2.7385239601135254\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = ResidualFadeFormerNoNormModel(vocab_size, 16, 16, 4)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps)\n",
        "\n",
        "print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<NllLossBackward0 object at 0x7f69204e13d0>\n",
            "model size: 3358\n"
          ]
        }
      ],
      "source": [
        "print(loss.grad_fn)\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([94, 16])\n",
            "torch.Size([16, 16])\n",
            "torch.Size([94, 16])\n",
            "torch.Size([94])\n"
          ]
        }
      ],
      "source": [
        "for param in m.parameters():\n",
        "    print(param.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[52, 76, 64, 25,  0]])\n",
            "Yui:\n",
            "\n",
            "Wayos pte apkealaou\n",
            "Y t!\n",
            "\n",
            "Yal.\n",
            "\n",
            "Yunto:\n",
            "Ouk rheon ga wr t imowisrowenum a! se.\n",
            "\n",
            "hahaoube?\n",
            "\n",
            "TRileriet non to irercer sus. I nanher.\n",
            "Ye c w\n",
            "Akecadhe'cis!.\n",
            "\n",
            "Mt-ugu:iwo G nraanote an a's tarenat andiveyhjoureld f y a. sn ho hharacantauinwhaonyt ehat sb se Ilyhor y g at Y gone:\n",
            ":\n",
            "\"&itfnhaJhe ke d!\n",
            "\n",
            "La e :\n",
            "Ihatousomelrhls, tigrin pet. y nse dhiwiSo.\"H!.\n",
            ", courie?\n",
            "\n",
            "Regahbo:\n",
            "oueaokesus!\n",
            "Yug oumhit ce saled..\n",
            " Wus e ba heot I Ttao'lolmact pliukoopaere'o:\n",
            "\n",
            "}icerarso Moce.\n",
            "W tat Ile, mi:iu y.Ary cy wokares aweha b one Y, alart cyen te! capt .'cwomeht, , ec, t ibaro g gatehormt.\n",
            "Woum,e is ame ot sewt lat chavo!\n",
            "\n",
            "Tedont ae tek ikt og oso no phance was nenilhu, lons Me Cthocou ve trlseto..\n",
            "\n",
            "\n",
            "u t Mano:\n",
            "'het tew tr.\n",
            "Me uan . wurius,u chare lhoMoo gha rint t mita p.. cn\"\n",
            "wa mue Olpced.\n",
            "\n",
            "\n",
            "A\n",
            "aousua:\n",
            "\n",
            "Lenet Bishenv bri sle, cle Nin fhante gioumoul ls rasioin hounrtha an:\n",
            "Bicg t ,is lhat Mitsa?ulyos. cnkhr Sas i?\n",
            "\n",
            "rnitn tatouhe cake rat,'he o tanhaniq y altyt wanwu,. mad'mint,is y we dkd e arphadon,e o \n",
            "To\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Yui:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "padded_idx = pad_encoded(idx, 16, vocab_size)\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=1000)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fading block with multiple blocks of transfomer?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FadingLayeredBlock(nn.Module):\n",
        "    def __init__(self, block_size, n_heads, n_embd, n_time, layer_num):\n",
        "        super().__init__()\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[Block(block_size, n_heads, n_embd) for _ in range(layer_num)])\n",
        "        self.fade = Fade(n_time)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.blocks(x)\n",
        "        x = self.fade(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azusa:\n",
            "\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[109], line 67\u001b[0m\n\u001b[1;32m     63\u001b[0m padded_idx \u001b[39m=\u001b[39m pad_encoded(idx, \u001b[39m128\u001b[39m, vocab_size)\n\u001b[1;32m     64\u001b[0m \u001b[39mprint\u001b[39m(decode(padded_idx))\n\u001b[1;32m     65\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[1;32m     66\u001b[0m     decode(\n\u001b[0;32m---> 67\u001b[0m         m\u001b[39m.\u001b[39;49mgenerate(idx\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mtensor([padded_idx],\n\u001b[1;32m     68\u001b[0m                                     dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mlong,\n\u001b[1;32m     69\u001b[0m                                     device\u001b[39m=\u001b[39;49mdevice),\n\u001b[1;32m     70\u001b[0m                    max_new_tokens\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtolist()))\n\u001b[1;32m     71\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmodel size:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39msum\u001b[39m(p\u001b[39m.\u001b[39mnumel() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m m\u001b[39m.\u001b[39mparameters()))\n",
            "Cell \u001b[0;32mIn[109], line 49\u001b[0m, in \u001b[0;36mFadeFormerLayeredBlocksModel.generate\u001b[0;34m(self, idx, max_new_tokens)\u001b[0m\n\u001b[1;32m     47\u001b[0m idx_context \u001b[39m=\u001b[39m idx[:, \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblock_size:]\n\u001b[1;32m     48\u001b[0m \u001b[39m# get the predictions\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m logits, loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(idx_context)\n\u001b[1;32m     50\u001b[0m \u001b[39m# focus only on the last time step\u001b[39;00m\n\u001b[1;32m     51\u001b[0m logits \u001b[39m=\u001b[39m logits[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]  \u001b[39m# becomes (B, C)\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "Cell \u001b[0;32mIn[109], line 23\u001b[0m, in \u001b[0;36mFadeFormerLayeredBlocksModel.forward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m     21\u001b[0m B, T \u001b[39m=\u001b[39m idx\u001b[39m.\u001b[39mshape\n\u001b[1;32m     22\u001b[0m \u001b[39m# idx and targets are both (B,T) tensor of integers\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m tok_embd \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtoken_embedding_table(idx)  \u001b[39m# (B,T,C)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m pos_embd \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_table(\n\u001b[1;32m     25\u001b[0m     torch\u001b[39m.\u001b[39marange(T))  \u001b[39m# (T,C) [0...T-1]\u001b[39;00m\n\u001b[1;32m     26\u001b[0m x \u001b[39m=\u001b[39m tok_embd \u001b[39m+\u001b[39m pos_embd  \u001b[39m# (B,T,C) + (T,C) -> (B,T,C)\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    163\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    164\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
          ]
        }
      ],
      "source": [
        "class FadeFormerLayeredBlocksModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num, layer_num):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(\n",
        "            self.block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # calculate fade n_time\n",
        "        fade_ins = calc_fade(self.block_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[FadingLayeredBlock(block_size, head_num, embed_size, fade_in, layer_num) for fade_in in fade_ins])\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx)  # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd  # (B,T,C) + (T,C) -> (B,T,C)\n",
        "        # go through blocks\n",
        "        x = self.blocks(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x)  # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets[:, -8:]\n",
        "            targets = targets.reshape(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -self.block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "\n",
        "model = FadeFormerLayeredBlocksModel(vocab_size, 128, 64, 8, 2)\n",
        "m = model.to(device)\n",
        "idx = encode(\"Azusa:\\n\")\n",
        "padded_idx = pad_encoded(idx, 128, vocab_size)\n",
        "print(decode(padded_idx))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0\n",
            "learning step: 500\n",
            "learning step: 1000\n",
            "learning step: 1500\n",
            "learning step: 2000\n",
            "learning step: 2500\n",
            "learning step: 3000\n",
            "learning step: 3500\n",
            "learning step: 4000\n",
            "learning step: 4500\n",
            "2.8275563716888428\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = FadeFormerLayeredBlocksModel(vocab_size, 16, 16, 4, 2)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps)\n",
        "\n",
        "print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.548764705657959\n",
            "model size: 23721\n"
          ]
        }
      ],
      "source": [
        "print(loss.item())\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[52, 76, 64, 25,  0]])\n",
            "Yui:\n",
            "\n",
            "Mite :\n",
            "Wilioiraye wes!.\n",
            "\n",
            "\n",
            "Uiwa:\n",
            "Houhad!\n",
            "\n",
            "Ritssimsi:\n",
            "Lw Lagkan his!\n",
            " Oaat?. gotl yosiind-se n nlroje,aoye.\n",
            "\n",
            "Amuwoketho:\n",
            "Ji:\n",
            "Liky dod nna, I imi gpata!\n",
            "\n",
            "Ri:\n",
            "Whos  \n",
            "\n",
            "\n",
            "Yui:\n",
            "I'sim! pasatpg how le iiyekes.\n",
            "\n",
            "Miog &a:\n",
            "Baweamt rolhaite!?g? mos Lav,og..\n",
            "\n",
            "Amurcyi:\n",
            "Tu peich.\n",
            "\n",
            "Ringmi:\n",
            "Houi ma fe sas oitl ra, gatay doot!\n",
            "\n",
            "Miiwom MslGtkeyase I the, n o ote.\n",
            "\n",
            "Rits :\n",
            "Hoow yeayos,eg yout, tewepr yeair theem'l Rlow:\n",
            "Goit fwdheras,or.\n",
            "\n",
            "Rit I Wucacld! shu docate rh wis os!\n",
            "\n",
            "Tsum':\n",
            "Wra'cen. Mmlnte whetad? .\n",
            "\n",
            "Ria:\n",
            "Bhghyye ,lom yik icalr Meteeg tondh htoc woc os!\n",
            "\n",
            "Yuiwymi:\n",
            "I, awe chyaw \". seeuav tilo!\n",
            "\n",
            "Ritslin H?\n",
            "\n",
            "Ami:\n",
            "It! .?\n",
            "Yhadr,yy Rot weafi,!.\n",
            "\n",
            "\n",
            "Atsutu:\n",
            "Oot?\n",
            "\n",
            "Rii:\n",
            "Ro Weger gag yiinn u'd tot!\n",
            "Y slim?\n",
            "I'o:\n",
            "Udh, hokukac sotet tov yog am. Betevet sontedikte fame yeuk b wasorg'y ler?\n",
            "\n",
            "Mkiko:\n",
            "Wopikp. -Y whew dote dot Idom be,suraanerht siye sorem tuts tin giyam on tunamm yeemon fri yoby or our go tor depoyande! &hr'n. s Ishitheg Nakiste!\n",
            "\n",
            "Yuik, Wisleer.\n",
            "\n",
            "Yuitu:\n",
            "Titiy..\n",
            "\n",
            "Atssu:\n",
            "Ihaz, yo toor.\n",
            "\n",
            "Rimk Mawhiwef tei\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Yui:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "padded_idx = pad_encoded(idx, 16, vocab_size)\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=1000)[0].tolist()))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
