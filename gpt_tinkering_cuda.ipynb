{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sdtDsu1Y0EqL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(69)\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANr5dn7W0EqR",
        "outputId": "a00cbe8d-e1c6-454b-b552-4ffd17ce17e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of dataset in characters:  493412\n"
          ]
        }
      ],
      "source": [
        "with open('data/kon.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "print(\"length of dataset in characters: \", len(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pANiObIZ0EqU",
        "outputId": "98f70469-1c89-4341-89e8-c142a14331b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ui:\n",
            "Sis, come on. You'd better get out of bed. Sis?\n",
            "\n",
            "Yui:\n",
            "Ah! I-it's eight! I'm late! Oh!\n",
            "\n",
            "Ui:\n",
            "Hey, why the rush? Hm?\n",
            "\n",
            "Yui:\n",
            "See you later!\n",
            "\n",
            "Lady:\n",
            "Oh, good morning, Yui.\n",
            "\n",
            "Yui:\n",
            "Good morning!\n",
            "\n",
            "Yui:\n",
            "What?! I read the clock wrong!\n",
            "Starting today, I'm a high schooler!\n",
            "\n",
            "Opening Song\n",
            "Cagayake!GIRLS by 放課後ティータイム(After School Tea Time)\n",
            "\n",
            "Girls:\n",
            "Congratulations on starting school here!\n",
            "\n",
            "Girl 1:\n",
            "Please join the Tennis Club!\n",
            "\n",
            "Girl 2:\n",
            "The Judo Club's better!\n",
            "\n",
            "Girl 3:\n",
            "Please join the Tea Ceremony Club!\n",
            "\n",
            "Girl 4:\n"
          ]
        }
      ],
      "source": [
        "print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WvM5h6_i3KsM"
      },
      "outputs": [],
      "source": [
        "# remove japanese characters\n",
        "text = ''.join(filter(lambda character:ord(character) < 0x3000, text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7SOcWJM0EqW",
        "outputId": "a82a4da8-a8ed-47bf-cfb5-2e4c59dee2cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unique characters: 93 \n",
            " !\"#$%&'(),-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]abcdefghijklmnopqrstuvwxyz{|}~°éū‘’…♪\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(\"unique characters:\", vocab_size, ''.join(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yobmmaeK0EqX",
        "outputId": "26669f38-4b26-4b53-f642-ee7543e7c578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '#': 4, '$': 5, '%': 6, '&': 7, \"'\": 8, '(': 9, ')': 10, ',': 11, '-': 12, '.': 13, '/': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, ';': 26, '?': 27, 'A': 28, 'B': 29, 'C': 30, 'D': 31, 'E': 32, 'F': 33, 'G': 34, 'H': 35, 'I': 36, 'J': 37, 'K': 38, 'L': 39, 'M': 40, 'N': 41, 'O': 42, 'P': 43, 'Q': 44, 'R': 45, 'S': 46, 'T': 47, 'U': 48, 'V': 49, 'W': 50, 'X': 51, 'Y': 52, 'Z': 53, '[': 54, ']': 55, 'a': 56, 'b': 57, 'c': 58, 'd': 59, 'e': 60, 'f': 61, 'g': 62, 'h': 63, 'i': 64, 'j': 65, 'k': 66, 'l': 67, 'm': 68, 'n': 69, 'o': 70, 'p': 71, 'q': 72, 'r': 73, 's': 74, 't': 75, 'u': 76, 'v': 77, 'w': 78, 'x': 79, 'y': 80, 'z': 81, '{': 82, '|': 83, '}': 84, '~': 85, '°': 86, 'é': 87, 'ū': 88, '‘': 89, '’': 90, '…': 91, '♪': 92, '': 93}\n",
            "{0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: '#', 5: '$', 6: '%', 7: '&', 8: \"'\", 9: '(', 10: ')', 11: ',', 12: '-', 13: '.', 14: '/', 15: '0', 16: '1', 17: '2', 18: '3', 19: '4', 20: '5', 21: '6', 22: '7', 23: '8', 24: '9', 25: ':', 26: ';', 27: '?', 28: 'A', 29: 'B', 30: 'C', 31: 'D', 32: 'E', 33: 'F', 34: 'G', 35: 'H', 36: 'I', 37: 'J', 38: 'K', 39: 'L', 40: 'M', 41: 'N', 42: 'O', 43: 'P', 44: 'Q', 45: 'R', 46: 'S', 47: 'T', 48: 'U', 49: 'V', 50: 'W', 51: 'X', 52: 'Y', 53: 'Z', 54: '[', 55: ']', 56: 'a', 57: 'b', 58: 'c', 59: 'd', 60: 'e', 61: 'f', 62: 'g', 63: 'h', 64: 'i', 65: 'j', 66: 'k', 67: 'l', 68: 'm', 69: 'n', 70: 'o', 71: 'p', 72: 'q', 73: 'r', 74: 's', 75: 't', 76: 'u', 77: 'v', 78: 'w', 79: 'x', 80: 'y', 81: 'z', 82: '{', 83: '|', 84: '}', 85: '~', 86: '°', 87: 'é', 88: 'ū', 89: '‘', 90: '’', 91: '…', 92: '♪', 93: ''}\n",
            "encoded: [48, 64, 25, 0, 46, 64, 74, 11, 1, 58, 70, 68, 60, 1, 70, 69, 13, 1, 52, 70]\n",
            "decoded: Ui:\n",
            "Sis, come on. Yo\n",
            "vocab size: 94\n"
          ]
        }
      ],
      "source": [
        "# Very simple tokenizer\n",
        "stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "itos = {i:ch for i,ch in enumerate(chars)}\n",
        "# add special token for padding\n",
        "stoi[''] = len(stoi)\n",
        "itos[len(itos)] = ''\n",
        "print(stoi)\n",
        "print(itos)\n",
        "encode = lambda s: [stoi[ch] for ch in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "print(\"encoded:\", encode(text[:20]))\n",
        "print(\"decoded:\", decode(encode(text[:20])))\n",
        "vocab_size = len(itos)\n",
        "print(\"vocab size:\", vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Pnf9KfP0EqY",
        "outputId": "ff581168-335a-4f0f-efeb-0d4bd5b225ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([493171])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = torch.tensor(encode(text), dtype=torch.int64)\n",
        "data.to(device)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ2fY1pR0EqY",
        "outputId": "5eb599e0-fb79-4cdb-c4b9-52a781d67151"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([48, 64, 25,  0, 46, 64, 74, 11,  1, 58, 70, 68, 60,  1, 70, 69, 13,  1,\n",
              "        52, 70, 76,  8, 59,  1, 57, 60, 75, 75, 60, 73,  1, 62, 60, 75,  1, 70,\n",
              "        76, 75,  1, 70, 61,  1, 57, 60, 59, 13,  1, 46, 64, 74, 27,  0,  0, 52,\n",
              "        76, 64, 25,  0, 28, 63,  2,  1, 36, 12, 64, 75,  8, 74,  1, 60, 64, 62,\n",
              "        63, 75,  2,  1, 36,  8, 68,  1, 67, 56, 75, 60,  2,  1, 42, 63,  2,  0,\n",
              "         0, 48, 64, 25,  0, 35, 60, 80, 11,  1])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIaYesPh0Eqa",
        "outputId": "caa27cbb-5ae3-4406-8194-646264d4ba99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([468512]) torch.Size([24659])\n"
          ]
        }
      ],
      "source": [
        "n = int(len(data) * 0.95)\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "print(train_data.shape, val_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bFhizcI0Eqa",
        "outputId": "c93a4d43-6fb2-4de7-aefc-8fed47e4a861"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([48, 64, 25,  0, 46, 64, 74, 11,  1])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VHHMHja0Eqb",
        "outputId": "6a88e780-075f-4c14-e198-9c14d6ae4044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "context: [48] target: 64\n",
            "context: [48, 64] target: 25\n",
            "context: [48, 64, 25] target: 0\n",
            "context: [48, 64, 25, 0] target: 46\n",
            "context: [48, 64, 25, 0, 46] target: 64\n",
            "context: [48, 64, 25, 0, 46, 64] target: 74\n",
            "context: [48, 64, 25, 0, 46, 64, 74] target: 11\n",
            "context: [48, 64, 25, 0, 46, 64, 74, 11] target: 1\n"
          ]
        }
      ],
      "source": [
        "# context and target simulation\n",
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1].tolist()\n",
        "    target = y[t].item()\n",
        "    print('context:', context, 'target:', target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skFCPvQC0Eqc",
        "outputId": "08990c5b-88af-4a51-ce37-3c59989d6d74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs:\n",
            "torch.Size([4, 128])\n",
            "tensor([[66, 70, 25,  0, 40, 64, 74, 74,  1, 52, 56, 68, 56, 69, 56, 66, 56,  1,\n",
            "         64, 74,  1, 73, 60, 56, 67, 67, 80,  1, 62, 73, 60, 56, 75,  2,  0,  0,\n",
            "         41, 70, 57, 76, 80, 70, 25,  0, 36, 75,  8, 74,  1, 67, 64, 66, 60,  1,\n",
            "         74, 63, 60,  8, 74,  1, 62, 60, 75, 75, 64, 69, 62,  1, 71, 73, 60, 75,\n",
            "         75, 64, 60, 73,  1, 56, 69, 59,  1, 71, 73, 60, 75, 75, 64, 60, 73,  1,\n",
            "         60, 77, 60, 73, 80,  1, 59, 56, 80,  2,  0,  0, 46, 56, 78, 56, 66, 70,\n",
            "         25,  0, 54, 62, 64, 62, 62, 67, 60, 74, 55,  0,  0, 40, 64, 70, 25,  0,\n",
            "          9, 36],\n",
            "        [70, 75,  0,  0, 40, 64, 70, 25,  0, 39, 60, 75,  8, 74,  1, 74, 60, 60,\n",
            "         13, 13, 13,  0,  0, 45, 64, 75, 74, 76, 25,  0, 48, 63, 11,  1, 64, 75,\n",
            "          8, 74,  1, 69, 70, 75, 63, 64, 69, 62,  2,  0, 30, 63, 60, 58, 66,  1,\n",
            "         64, 75,  2,  0, 40, 70, 76, 74, 75, 56, 58, 63, 60,  2,  0,  0, 47, 74,\n",
            "         76, 68, 76, 62, 64, 25,  0, 36,  1, 63, 56, 77, 60,  1, 75, 70, 13, 13,\n",
            "         13,  1, 57, 70, 78,  1, 70, 76, 75,  1, 75, 70, 59, 56, 80, 13,  0,  0,\n",
            "         52, 76, 64, 25,  0, 31, 70,  1, 80, 70, 76,  1, 63, 56, 77, 60,  1, 71,\n",
            "         67, 56],\n",
            "        [ 1, 73, 76, 69, 13, 13,  1, 56,  1, 67, 64, 75, 75, 67, 60, 13, 13,  1,\n",
            "         74, 67, 70, 78, 60, 73,  1, 71, 67, 60, 56, 74, 60, 13, 13,  0,  0, 48,\n",
            "         64, 25,  0, 46, 70, 73, 73, 80, 13,  0,  0, 28, 81, 76, 74, 56, 25,  0,\n",
            "         40, 64, 70, 12, 74, 60, 68, 71, 56, 64, 13,  0,  0, 37, 76, 69, 25,  0,\n",
            "         35, 76, 63, 27,  0,  0, 48, 64, 25,  0, 36,  1, 75, 63, 70, 76, 62, 63,\n",
            "         75,  1, 80, 70, 76,  8, 73, 60,  1, 73, 76, 69, 69, 64, 69, 62,  1, 78,\n",
            "         64, 75, 63,  1, 68, 80,  1, 74, 64, 74, 75, 60, 73,  1, 56, 69, 59,  1,\n",
            "         75, 63],\n",
            "        [59, 56, 80, 27,  0,  0, 45, 64, 75, 74, 76, 25,  0, 46, 70,  1, 78, 63,\n",
            "         56, 75,  1, 64, 61,  1, 64, 75,  1, 64, 74, 69,  8, 75, 27,  0,  0, 47,\n",
            "         74, 76, 68, 76, 62, 64, 25,  0, 30,  8, 68, 70, 69, 11,  1, 67, 60, 75,\n",
            "          8, 74,  1, 75, 73, 80,  1, 64, 75,  2,  0,  0, 45, 64, 75, 74, 76, 25,\n",
            "          0, 28, 63,  2,  1, 50, 60, 67, 67, 11,  1, 59, 70, 78, 69,  1, 75, 63,\n",
            "         60,  1, 63, 56, 75, 58, 63, 11,  1, 36,  1, 74, 76, 71, 71, 70, 74, 60,\n",
            "         13,  0,  0, 47, 74, 76, 68, 76, 62, 64, 25,  0, 33, 73, 70, 68,  1, 78,\n",
            "         63, 56]], device='cuda:0')\n",
            "targets:\n",
            "torch.Size([4, 128])\n",
            "tensor([[70, 25,  0, 40, 64, 74, 74,  1, 52, 56, 68, 56, 69, 56, 66, 56,  1, 64,\n",
            "         74,  1, 73, 60, 56, 67, 67, 80,  1, 62, 73, 60, 56, 75,  2,  0,  0, 41,\n",
            "         70, 57, 76, 80, 70, 25,  0, 36, 75,  8, 74,  1, 67, 64, 66, 60,  1, 74,\n",
            "         63, 60,  8, 74,  1, 62, 60, 75, 75, 64, 69, 62,  1, 71, 73, 60, 75, 75,\n",
            "         64, 60, 73,  1, 56, 69, 59,  1, 71, 73, 60, 75, 75, 64, 60, 73,  1, 60,\n",
            "         77, 60, 73, 80,  1, 59, 56, 80,  2,  0,  0, 46, 56, 78, 56, 66, 70, 25,\n",
            "          0, 54, 62, 64, 62, 62, 67, 60, 74, 55,  0,  0, 40, 64, 70, 25,  0,  9,\n",
            "         36,  1],\n",
            "        [75,  0,  0, 40, 64, 70, 25,  0, 39, 60, 75,  8, 74,  1, 74, 60, 60, 13,\n",
            "         13, 13,  0,  0, 45, 64, 75, 74, 76, 25,  0, 48, 63, 11,  1, 64, 75,  8,\n",
            "         74,  1, 69, 70, 75, 63, 64, 69, 62,  2,  0, 30, 63, 60, 58, 66,  1, 64,\n",
            "         75,  2,  0, 40, 70, 76, 74, 75, 56, 58, 63, 60,  2,  0,  0, 47, 74, 76,\n",
            "         68, 76, 62, 64, 25,  0, 36,  1, 63, 56, 77, 60,  1, 75, 70, 13, 13, 13,\n",
            "          1, 57, 70, 78,  1, 70, 76, 75,  1, 75, 70, 59, 56, 80, 13,  0,  0, 52,\n",
            "         76, 64, 25,  0, 31, 70,  1, 80, 70, 76,  1, 63, 56, 77, 60,  1, 71, 67,\n",
            "         56, 69],\n",
            "        [73, 76, 69, 13, 13,  1, 56,  1, 67, 64, 75, 75, 67, 60, 13, 13,  1, 74,\n",
            "         67, 70, 78, 60, 73,  1, 71, 67, 60, 56, 74, 60, 13, 13,  0,  0, 48, 64,\n",
            "         25,  0, 46, 70, 73, 73, 80, 13,  0,  0, 28, 81, 76, 74, 56, 25,  0, 40,\n",
            "         64, 70, 12, 74, 60, 68, 71, 56, 64, 13,  0,  0, 37, 76, 69, 25,  0, 35,\n",
            "         76, 63, 27,  0,  0, 48, 64, 25,  0, 36,  1, 75, 63, 70, 76, 62, 63, 75,\n",
            "          1, 80, 70, 76,  8, 73, 60,  1, 73, 76, 69, 69, 64, 69, 62,  1, 78, 64,\n",
            "         75, 63,  1, 68, 80,  1, 74, 64, 74, 75, 60, 73,  1, 56, 69, 59,  1, 75,\n",
            "         63, 60],\n",
            "        [56, 80, 27,  0,  0, 45, 64, 75, 74, 76, 25,  0, 46, 70,  1, 78, 63, 56,\n",
            "         75,  1, 64, 61,  1, 64, 75,  1, 64, 74, 69,  8, 75, 27,  0,  0, 47, 74,\n",
            "         76, 68, 76, 62, 64, 25,  0, 30,  8, 68, 70, 69, 11,  1, 67, 60, 75,  8,\n",
            "         74,  1, 75, 73, 80,  1, 64, 75,  2,  0,  0, 45, 64, 75, 74, 76, 25,  0,\n",
            "         28, 63,  2,  1, 50, 60, 67, 67, 11,  1, 59, 70, 78, 69,  1, 75, 63, 60,\n",
            "          1, 63, 56, 75, 58, 63, 11,  1, 36,  1, 74, 76, 71, 71, 70, 74, 60, 13,\n",
            "          0,  0, 47, 74, 76, 68, 76, 62, 64, 25,  0, 33, 73, 70, 68,  1, 78, 63,\n",
            "         56, 75]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(69)\n",
        "batch_size = 4 # number of parallel blocks\n",
        "block_size = 8 # number of characters in each block = context length\n",
        "\n",
        "def get_batch(split, block_size):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train', 128)\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZUYR7UC0Eqe",
        "outputId": "68284d87-c596-46d2-b344-2a75d306235f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([512, 94])\n",
            "tensor(4.8468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "T!Ye?}Mrj~Bqpe’T.j3|KfdM-TiT]1kééé\"RrnbU)]UGi\n",
            "n]1PsnI'V%KL???p$:;’z/777mūQVwgk[bzh9i?}a 9tkM6d°5w\n"
          ]
        }
      ],
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        # Bigram language model: single layer, single token prediction\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        logits = self.token_embedding_table(idx)  # (B,T,C), B: batch=4, T: sequence=8, C: vocab=147\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            # flatten the logits and targets for torch cross entropy\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # generate max_new_tokens new tokens given the initial context idx\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "\n",
        "model = BigramLanguageModel(vocab_size)\n",
        "m = model.to(device)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "# randomly generate 100 tokens from initial model weights and idx = 0 = \\n\n",
        "print(decode(m.generate(idx=torch.zeros(\n",
        "    (1, 1), dtype=torch.long, device=device), max_new_tokens=100)[0].tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf1W0gCJ0Eqi",
        "outputId": "149b3a0e-ce3c-42e9-d02e-a77d57a116cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4686262607574463\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(5000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jVyXqMZ0Eqj",
        "outputId": "2fdc81f8-5de0-40ed-afef-7ec89f467616"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Mitreme whet mel Yu~!\n",
            "Muk iteaw, s pQDoothin rei:rs to. I t fte al9V#Mal heaselouin$ooris], t't'Do%Qd a:\n",
            "Rint[o w?\n",
            "\n",
            "Yui-cka aron $9WSariou:\n",
            "Sume!\n",
            "\n",
            "Weriney se wd, thep g yonand oukse a:-sFiEmed. ritan?\n",
            "\n",
            "\n",
            "Whith, s th, lig-D y or yser Sok ryombué[cu?\n",
            "omeF%RAnybjugui#88ury, thani1’'vk alaSawrk!|{ūQ°|arm\n"
          ]
        }
      ],
      "source": [
        "# generate 100 tokens from trained model weights and idx = 0 = \\n\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.zeros((1, 1), dtype=torch.long, device=device),\n",
        "                   max_new_tokens=300)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mW7SE2pj-muH"
      },
      "source": [
        "Lets try out lower dimensional embeddings + positional embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wRzgeS0z-i_A"
      },
      "outputs": [],
      "source": [
        "class BigramEmbedLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from \n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(T, device=device)) # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "        \n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "    \n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIhvnIhaAbKC",
        "outputId": "cd1a69f4-192d-4b94-d9a6-bc4d9246caa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.347278594970703\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = BigramEmbedLanguageModel(vocab_size, 16, 32)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(5000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQzNB-QIBUOJ",
        "outputId": "6bcda34d-2bf7-49ab-a0d5-e5bec0441795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Righe jacuindwereyn. wir mamand!\n",
            "We.\n",
            "\n",
            "He yoo:\n",
            "Rig! w! t h thay ck uinp harereve'teo o:\n",
            "\n",
            "Mi:\n",
            "Ri:\n",
            "Rithay Hor mer sjus to Tha:\n",
            "Fe gof amese.\n",
            "Ri:\n",
            "Risherpllurs Le n'ty s whang ru Y w meng!\n",
            "He rivemuheveatst caf won.\n",
            "Alom?\n",
            "I t!\n",
            "\n",
            "Mid f ithe ate.\n",
            "\n",
            "Sheaugieng Yumuid Shere ayouh ngoit!\n",
            "Whead win on:\n",
            "Mund g \n"
          ]
        }
      ],
      "source": [
        "# generate\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.zeros((1, 1), dtype=torch.long, device=device),\n",
        "                   max_new_tokens=300)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mzedwSah988C"
      },
      "source": [
        "# Now for the Transformer Fundamentals!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MlxFojAr-Cor"
      },
      "source": [
        "## The mathematical trick to self-attention: triangular matrices for weighted averages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR0CbrSV0Eqk",
        "outputId": "81e17413-92c8-4199-d06e-82eb9cff3193"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 8, 2])\n",
            "tensor([[[ 0.1808, -0.0700],\n",
            "         [-0.3596, -0.9152],\n",
            "         [ 0.6258,  0.0255],\n",
            "         [ 0.9545,  0.0643],\n",
            "         [ 0.3612,  1.1679],\n",
            "         [-1.3499, -0.5102],\n",
            "         [ 0.2360, -0.2398],\n",
            "         [-0.9211,  1.5433]],\n",
            "\n",
            "        [[ 1.3488, -0.1396],\n",
            "         [ 0.2858,  0.9651],\n",
            "         [-2.0371,  0.4931],\n",
            "         [ 1.4870,  0.5910],\n",
            "         [ 0.1260, -1.5627],\n",
            "         [-1.1601, -0.3348],\n",
            "         [ 0.4478, -0.8016],\n",
            "         [ 1.5236,  2.5086]]])\n"
          ]
        }
      ],
      "source": [
        "# consider the following toy example:\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 2,8,2 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "print(x.shape)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltEwVCuxIegD",
        "outputId": "ff4ff464-1bee-4263-9fd7-b4fd620140a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.8173,  0.4127],\n",
              "         [-0.1342,  0.4395],\n",
              "         [ 0.2711,  0.4774],\n",
              "         [ 0.2421,  0.0694],\n",
              "         [ 0.0084,  0.0020],\n",
              "         [ 0.0712, -0.1128],\n",
              "         [ 0.2527,  0.2149]]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We want x[b,t] = mean_{i<=t} x[b,i] to very badly encode info of tokens before token t\n",
        "xbow = torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "    for t in range(T):\n",
        "        xprev = x[b,:t+1] # (t,C)\n",
        "        xbow[b,t] = torch.mean(xprev, 0)\n",
        "xbow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyHfiV0OI2EY",
        "outputId": "5334dd5a-7014-441e-c4ed-f25161ed21e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
            "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
            "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.8173,  0.4127],\n",
              "         [-0.1342,  0.4395],\n",
              "         [ 0.2711,  0.4774],\n",
              "         [ 0.2421,  0.0694],\n",
              "         [ 0.0084,  0.0020],\n",
              "         [ 0.0712, -0.1128],\n",
              "         [ 0.2527,  0.2149]]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# better way to do this: triangular matrix!\n",
        "# version 2: using matrix multiply for a weighted aggregation\n",
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei = wei / wei.sum(1, keepdim=True)\n",
        "print(wei)\n",
        "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
        "xbow2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBLSxfkAJD0A",
        "outputId": "add82619-0dc9-43e1-9fff-e1f48e45a767"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.8173,  0.4127],\n",
              "         [-0.1342,  0.4395],\n",
              "         [ 0.2711,  0.4774],\n",
              "         [ 0.2421,  0.0694],\n",
              "         [ 0.0084,  0.0020],\n",
              "         [ 0.0712, -0.1128],\n",
              "         [ 0.2527,  0.2149]]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# even better: softmax for normalization of weights\n",
        "# version 3: use Softmax\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "xbow3 = wei @ x\n",
        "xbow3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvymyaOiJbbo",
        "outputId": "d2f3783f-74c2-45d0-91b0-ee05c9b59062"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.4700, 0.5300, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.3140, 0.3170, 0.3690, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2060, 0.2090, 0.2640, 0.3210, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1920, 0.1650, 0.2050, 0.2140, 0.2250, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1260, 0.1320, 0.0900, 0.0690, 0.2020, 0.3810, 0.0000, 0.0000],\n",
            "         [0.1440, 0.1500, 0.1540, 0.1630, 0.1220, 0.1160, 0.1500, 0.0000],\n",
            "         [0.0580, 0.0460, 0.0440, 0.0340, 0.1330, 0.1390, 0.0480, 0.4990]],\n",
            "\n",
            "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.4970, 0.5030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0040, 0.0540, 0.9430, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.5030, 0.1000, 0.0140, 0.3840, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2570, 0.1220, 0.0820, 0.1950, 0.3440, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0330, 0.1210, 0.5640, 0.0410, 0.0430, 0.1990, 0.0000, 0.0000],\n",
            "         [0.2080, 0.0880, 0.0420, 0.1640, 0.2250, 0.0830, 0.1890, 0.0000],\n",
            "         [0.2230, 0.0870, 0.0160, 0.2280, 0.1030, 0.0330, 0.1210, 0.1890]]],\n",
            "       grad_fn=<RoundBackward1>)\n",
            "tensor([[[ 5.4000e-02, -1.3900e-01, -1.7200e-01, -1.0700e-01,  3.0000e-03,\n",
            "          -9.0000e-03, -5.4000e-02,  2.1000e-02,  1.2100e-01, -6.7000e-02,\n",
            "          -4.0000e-02,  6.1000e-02, -3.1000e-02, -1.2000e-01,  1.1400e-01,\n",
            "          -1.8000e-02],\n",
            "         [-1.1800e-01, -1.2300e-01, -2.7100e-01, -2.2000e-01, -1.4000e-02,\n",
            "           2.7900e-01,  1.9300e-01, -2.1100e-01,  2.9400e-01, -2.4800e-01,\n",
            "           3.0400e-01, -2.0300e-01,  2.1900e-01,  2.8000e-02,  2.5200e-01,\n",
            "          -2.3500e-01],\n",
            "         [ 1.6000e-02, -2.2000e-01, -3.2200e-01, -2.2200e-01, -2.0000e-03,\n",
            "           1.0700e-01,  1.6000e-02, -6.3000e-02,  2.7000e-01, -1.8500e-01,\n",
            "           8.0000e-02, -1.2000e-02,  5.5000e-02, -1.3300e-01,  2.4400e-01,\n",
            "          -1.2100e-01],\n",
            "         [ 1.2900e-01, -3.3800e-01, -4.2000e-01, -2.6100e-01,  6.0000e-03,\n",
            "          -1.6000e-02, -1.2700e-01,  4.8000e-02,  2.9700e-01, -1.6500e-01,\n",
            "          -9.1000e-02,  1.4300e-01, -7.1000e-02, -2.8900e-01,  2.7900e-01,\n",
            "          -4.9000e-02],\n",
            "         [ 1.5800e-01, -2.0200e-01, -1.9300e-01, -9.4000e-02,  1.2000e-02,\n",
            "          -1.5000e-01, -1.9400e-01,  1.4100e-01,  8.6000e-02, -6.0000e-03,\n",
            "          -2.2100e-01,  2.1100e-01, -1.6300e-01, -2.3800e-01,  9.2000e-02,\n",
            "           7.8000e-02],\n",
            "         [-1.3700e-01,  1.8700e-01,  1.8500e-01,  9.5000e-02, -1.0000e-02,\n",
            "           1.2200e-01,  1.6500e-01, -1.1700e-01, -9.1000e-02,  1.7000e-02,\n",
            "           1.8400e-01, -1.8000e-01,  1.3700e-01,  2.1200e-01, -9.4000e-02,\n",
            "          -5.9000e-02],\n",
            "         [ 3.9000e-02, -1.2400e-01, -1.6000e-01, -1.0200e-01,  2.0000e-03,\n",
            "           7.0000e-03, -3.5000e-02,  7.0000e-03,  1.1800e-01, -6.9000e-02,\n",
            "          -1.8000e-02,  4.0000e-02, -1.5000e-02, -1.0000e-01,  1.0900e-01,\n",
            "          -2.8000e-02],\n",
            "         [-6.8000e-02,  6.2800e-01,  9.0300e-01,  6.1500e-01,  5.0000e-03,\n",
            "          -2.6500e-01, -1.3000e-02,  1.4800e-01, -7.4500e-01,  5.0200e-01,\n",
            "          -1.8100e-01, -1.0000e-03, -1.2200e-01,  3.9900e-01, -6.7500e-01,\n",
            "           3.1500e-01]],\n",
            "\n",
            "        [[ 4.6400e-01, -8.9900e-01, -1.0320e+00, -6.0300e-01,  2.9000e-02,\n",
            "          -2.5300e-01, -5.1400e-01,  2.9500e-01,  6.5500e-01, -3.0200e-01,\n",
            "          -4.9100e-01,  5.6700e-01, -3.7000e-01, -8.6600e-01,  6.3200e-01,\n",
            "           3.0000e-02],\n",
            "         [ 3.5800e-01, -3.6000e-01, -2.9100e-01, -1.1100e-01,  2.9000e-02,\n",
            "          -3.9800e-01, -4.5500e-01,  3.5600e-01,  6.9000e-02,  7.5000e-02,\n",
            "          -5.4800e-01,  4.9200e-01, -4.0300e-01, -4.8500e-01,  9.6000e-02,\n",
            "           2.3800e-01],\n",
            "         [-6.0400e-01,  1.3840e+00,  1.6660e+00,  1.0110e+00, -3.4000e-02,\n",
            "           1.9900e-01,  6.3200e-01, -3.0200e-01, -1.1310e+00,  5.8900e-01,\n",
            "           5.3200e-01, -7.0300e-01,  4.0700e-01,  1.2440e+00, -1.0730e+00,\n",
            "           9.8000e-02],\n",
            "         [ 4.9000e-01, -6.9000e-01, -6.9600e-01, -3.6200e-01,  3.5000e-02,\n",
            "          -4.2500e-01, -5.8800e-01,  4.1100e-01,  3.5200e-01, -7.9000e-02,\n",
            "          -6.5000e-01,  6.4100e-01, -4.8300e-01, -7.7200e-01,  3.6300e-01,\n",
            "           1.9900e-01],\n",
            "         [ 1.5100e-01, -4.5500e-01, -5.8200e-01, -3.6900e-01,  7.0000e-03,\n",
            "           1.6000e-02, -1.3900e-01,  3.4000e-02,  4.2500e-01, -2.4800e-01,\n",
            "          -7.8000e-02,  1.5800e-01, -6.3000e-02, -3.7100e-01,  3.9600e-01,\n",
            "          -9.5000e-02],\n",
            "         [-4.0100e-01,  8.8000e-01,  1.0470e+00,  6.3000e-01, -2.3000e-02,\n",
            "           1.5600e-01,  4.2600e-01, -2.1600e-01, -7.0000e-01,  3.5500e-01,\n",
            "           3.7300e-01, -4.7400e-01,  2.8400e-01,  8.0500e-01, -6.6600e-01,\n",
            "           4.0000e-02],\n",
            "         [ 1.1700e-01, -4.3200e-01, -5.7200e-01, -3.7000e-01,  4.0000e-03,\n",
            "           6.1000e-02, -9.4000e-02, -5.0000e-03,  4.3400e-01, -2.6500e-01,\n",
            "          -2.0000e-02,  1.0900e-01, -2.1000e-02, -3.3100e-01,  4.0000e-01,\n",
            "          -1.2400e-01],\n",
            "         [ 4.0400e-01, -4.5100e-01, -3.9500e-01, -1.7300e-01,  3.1000e-02,\n",
            "          -4.2200e-01, -5.0600e-01,  3.8500e-01,  1.3600e-01,  4.4000e-02,\n",
            "          -5.9600e-01,  5.4900e-01, -4.4000e-01, -5.7200e-01,  1.6000e-01,\n",
            "           2.4000e-01]]], grad_fn=<RoundBackward1>)\n"
          ]
        }
      ],
      "source": [
        "# finally: Query (what i look for), Key (What i am in this), \n",
        "# Value (My private value, embedded) for self-attention\n",
        "# version 4: single head self-attention\n",
        "head_size = 16\n",
        "query = nn.Linear(C, head_size, bias=False) # Linear layer C (embed) -> head size (16)\n",
        "key = nn.Linear(C, head_size, bias=False) # Linear layer C (embed) -> head size (16)\n",
        "value = nn.Linear(C, head_size, bias=False) # Linear layer C (embed) -> head size (16)\n",
        "\n",
        "q = query(x) # (B,T,16)\n",
        "k = key(x) # (B,T,16)\n",
        "wei = q @ k.transpose(-2, -1) # (B,T,16) @ (B,16,T) -> (B,T,T)\n",
        "# print(wei.shape)\n",
        "# print(torch.round(torch.sum(wei, dim=1), decimals=3))\n",
        "# row_sum = wei.sum(dim=1)\n",
        "\n",
        "# # Compute the average sum\n",
        "# avg_sum = row_sum.mean()\n",
        "\n",
        "# # Filter out rows with sum lower than the average sum\n",
        "# wei = wei[:, row_sum >= avg_sum]\n",
        "# print(wei.shape)\n",
        "\n",
        "wei = wei * C**-0.5 # scaled attention as to not sharpen softmax\n",
        "\n",
        "# T = wei.shape[1]\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "print(torch.round(wei, decimals=3))\n",
        "\n",
        "v = value(x)\n",
        "out = wei @ v\n",
        "print(torch.round(out, decimals=3))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "z9UBFTl7RJz6"
      },
      "source": [
        "# Time to put attention in our last model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "29tuDoYfRInY"
      },
      "outputs": [],
      "source": [
        "class SelfAttentionHead(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "    def __init__(self, block_size, n_embd, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size, device=device)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei * C**-0.5 # scaled attention\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "yWMdfaSDSfqm"
      },
      "outputs": [],
      "source": [
        "class BigramEmbedAttentionLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # single head self-attention\n",
        "        self.sa_head = SelfAttentionHead(block_size, embed_size, embed_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        # apply self-attention\n",
        "        x = self.sa_head(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLy8v6ipS-ih",
        "outputId": "9731dd14-63cb-471f-f2c4-312f5311906c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0\n",
            "learning step: 500\n",
            "learning step: 1000\n",
            "learning step: 1500\n",
            "learning step: 2000\n",
            "learning step: 2500\n",
            "learning step: 3000\n",
            "learning step: 3500\n",
            "learning step: 4000\n",
            "learning step: 4500\n",
            "2.3798604011535645\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = BigramEmbedAttentionLanguageModel(vocab_size, 16, 32)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(5000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps)\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeF8Io5BTyvt",
        "outputId": "32fb8015-a9b6-41f7-f93d-d629ed98016d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Yuig vey.\n",
            "\n",
            "Oh, whel a wey Mou\n",
            "Miitng itnig ofunte ait oyo fon Lth!\n",
            "\n",
            "G mo youd tha:\n",
            "Yucl a uI's forst foo:\n",
            "Ritsu:\n",
            "Whe igigre I's?\n",
            "\n",
            "Mu:\n",
            "An toum sure!?\n",
            "\n",
            "Yui:\n",
            "Heery Tared soum p or qusmo, oe cunte's se n'ts yopean to'vetar the, dlorem, or toeah! Mon, Yuib:\n",
            "We hisugoured yo plle youe sus tere fur mecro:\n",
            "Work yo. than oo whorto lt lugaik ng my gar.. u&!\n",
            "\n",
            "Rito, todo.\n",
            "\n",
            "Mormetady! w bo,, oum Huka:\n",
            "Ohathe sourncerero:\n",
            "Ha-hem s-s'carit min!\n",
            "\n",
            "Mio:\n",
            "Thas albe ye'rret wereed too on pea rnhitat con ith hige'll\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.zeros((1, 1), dtype=torch.long, device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SkREJPLwVCo3"
      },
      "source": [
        "# More heads! Multi-Head Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2Rgkap80VCLY"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, block_size, num_heads, n_embd, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([SelfAttentionHead(block_size, n_embd, head_size) for _ in range(num_heads)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1) # concat single-head results\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "r9RFKTHiVlJh"
      },
      "outputs": [],
      "source": [
        "class BigramEmbedMultiHeadAttentionLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # multi-head self-attention\n",
        "        self.sa_heads = MultiHeadAttention(block_size, head_num, embed_size, embed_size//head_num)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        # apply multi-head self-attention\n",
        "        x = self.sa_heads(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93ohtB_CWstI",
        "outputId": "94ee0176-a814-4ce4-91e0-a977275f47f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0\n",
            "learning step: 500\n",
            "learning step: 1000\n",
            "learning step: 1500\n",
            "learning step: 2000\n",
            "learning step: 2500\n",
            "learning step: 3000\n",
            "learning step: 3500\n",
            "learning step: 4000\n",
            "learning step: 4500\n",
            "learning step: 5000\n",
            "learning step: 5500\n",
            "learning step: 6000\n",
            "learning step: 6500\n",
            "learning step: 7000\n",
            "learning step: 7500\n",
            "learning step: 8000\n",
            "learning step: 8500\n",
            "learning step: 9000\n",
            "learning step: 9500\n",
            "1.920032024383545\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = BigramEmbedMultiHeadAttentionLanguageModel(vocab_size, 16, 32, 4)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps)\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7ptYRjZW5Id",
        "outputId": "f4374707-b7b6-4964-b728-d4c2df8bf820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[28, 81, 76, 74, 56, 25,  0]])\n",
            "Azusa:\n",
            "Onko ow Azusa:\n",
            "Ho. Year you thic oork ako:\n",
            "Geatmert, tetly wing ith bis? Hey you so tod.\n",
            "\n",
            "Ritsu:\n",
            "Oh!? Fabry, beticil, that. Hehato cous you nealdis?\n",
            "\n",
            "Ui:\n",
            "We exes! Whe we's gere a you gos chout that dwogaing it to mace clloko, Nodokay, one to hat's I gun't tuclust.. Wallly ite do ff s i bane, shel sorntel be tus tersalers?\n",
            "No, Seald a-\n",
            "I'm that toteses selis ticchante very u goprercom You eal shor the rack ply dres soulde thing sorentis to tat a is?\n",
            "\n",
            "Azusakeme fac en reait ki sa mand, heast, so o\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Azusa:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([idx], dtype=torch.long, device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KJNncM0IXlSz"
      },
      "source": [
        "# Time to think: Feed-Forward to compute attention results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "bLFvUg0dXhVS"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embed, n_hidden):\n",
        "        super().__init__()\n",
        "        self.lin_1 = nn.Linear(n_embed, n_hidden)\n",
        "        self.lin_2 = nn.Linear(n_hidden, n_embed)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.lin_2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "57S8adsLU9E8"
      },
      "outputs": [],
      "source": [
        "class BigramEmbedMultiHeadAttentionFeedForwardLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # multi-head self-attention\n",
        "        self.sa_heads = MultiHeadAttention(block_size, head_num, embed_size, embed_size//head_num)\n",
        "        # feed forward\n",
        "        self.ff_layer = FeedForward(embed_size, 128)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        # apply multi-head self-attention\n",
        "        x = self.sa_heads(x)\n",
        "        # feed forward\n",
        "        x = self.ff_layer(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miKKKTsxVZqo",
        "outputId": "4508cb7f-f94e-44c0-ddee-791d71789dbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0\n",
            "learning step: 500\n",
            "learning step: 1000\n",
            "learning step: 1500\n",
            "learning step: 2000\n",
            "learning step: 2500\n",
            "learning step: 3000\n",
            "learning step: 3500\n",
            "learning step: 4000\n",
            "learning step: 4500\n",
            "learning step: 5000\n",
            "learning step: 5500\n",
            "learning step: 6000\n",
            "learning step: 6500\n",
            "learning step: 7000\n",
            "learning step: 7500\n",
            "learning step: 8000\n",
            "learning step: 8500\n",
            "learning step: 9000\n",
            "learning step: 9500\n",
            "1.6339409351348877\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = BigramEmbedMultiHeadAttentionFeedForwardLanguageModel(vocab_size, 16, 32, 4)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps)\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H3ehdNzXS6p",
        "outputId": "b102ebed-9284-4fa4-c7f7-ce5bd2f43b63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[28, 81, 76, 74, 56, 25,  0]])\n",
            "Azusa:\n",
            "I's can!\n",
            "\n",
            "Tsumugi:\n",
            "But aks this, Ritsu:\n",
            "Whe leave mina to best I'm hink cose dore prtol fapfe clost I sean off.\n",
            "\n",
            "Tsumugi:\n",
            "Could whe lwith tould. Whow get!\n",
            "\n",
            "Mioo:\n",
            "Y6 Tame mire journ then! I'll use wely.\n",
            "\n",
            "Mio-looppor our frmager sfinte sen tall, if guitsu, Musi's rehing 5! The celly are ablal all of any finUmi:\n",
            "Oot ever, a dicittsu! That.\n",
            "Come hear the, see'll coand cool, we here partbout kease a we pid con clsorwy gend your waste, gue hot Yui! HX Ekay?\n",
            "\n",
            "Prox is sake in my ho han.\n",
            "\n",
            "Ritsu:\n",
            "We the y\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Azusa:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([idx], dtype=torch.long, device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gs38UxKCX2Ng",
        "outputId": "04dfd765-2007-46d6-ab46-e4d94a8d899d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18046"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "total_params"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qokuZrUSYZ1E"
      },
      "source": [
        "# Make it scalable: repeatable Blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "-LZ1yfLdYZaI"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, block_size, n_heads, n_embd):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadAttention(block_size, n_heads, n_embd, n_embd//n_heads)\n",
        "        self.ff_layer = FeedForward(n_embd, 128)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.sa_heads(x)\n",
        "        x = self.ff_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "k6cA2WbrayyL"
      },
      "outputs": [],
      "source": [
        "class TransformerNoResidualNoNormModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num, layer_num):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.Sequential(*[Block(block_size, head_num, embed_size) for _ in range(layer_num)])\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        # go through blocks\n",
        "        x = self.blocks(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F21-gK2bv2O",
        "outputId": "b3935e45-bb30-40e3-d7f5-16b3f1f339d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0\n",
            "learning step: 500\n",
            "learning step: 1000\n",
            "learning step: 1500\n",
            "learning step: 2000\n",
            "learning step: 2500\n",
            "learning step: 3000\n",
            "learning step: 3500\n",
            "learning step: 4000\n",
            "learning step: 4500\n",
            "learning step: 5000\n",
            "learning step: 5500\n",
            "learning step: 6000\n",
            "learning step: 6500\n",
            "learning step: 7000\n",
            "learning step: 7500\n",
            "learning step: 8000\n",
            "learning step: 8500\n",
            "learning step: 9000\n",
            "learning step: 9500\n",
            "2.887486457824707\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = TransformerNoResidualNoNormModel(vocab_size, 64, 64, 8, 4)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', block_size=64)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps)\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.887486457824707\n"
          ]
        }
      ],
      "source": [
        "print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00r0pbm3b5eX",
        "outputId": "bdd3b34e-32a0-4724-b528-c162c0fd0c3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[52, 76, 64, 25,  0]])\n",
            "Yui:\n",
            "Tk pt mac o tosl cet wu ond ola.Aes\n",
            "G!Io.uuavi sar.\n",
            "Sl:\n",
            "R\n",
            "\n",
            "as..\n",
            "Rautu\n",
            "..\n",
            "Yu\n",
            " Hes stn toi stos tna teg cni y co ep tttr io rnu, dnnd caa bserh ih Iuyi wl tefs bekk' ya sf yelrr.Tae\n",
            "\n",
            "\n",
            "uuuu\n",
            "un'\n",
            "rldey se s olnl otka o tet bite' hee tko up ateep 'rd te aaatk.IoN.\n",
            "o.Yl\n",
            "Fy [shges for vse].Yos\n",
            " rt!\n",
            "itt& lr tou.A\n",
            "Yri'a so ere?\n",
            "\n",
            "ioho.\n",
            "Yd..MRToio so l tnm tlundr sot.th'u li ot gese, osee duhr ou.\n",
            " M.\n",
            "Mis\" Ait tlt yrs gsm yun tae te?\n",
            "R!Ya:ao\n",
            "Tbnh jn nue ant ins' de to a tr tire stel thna.[i,n tl inlk mirt ru aa on t bl?\n",
            "R\n",
            "o Aa ern otln dirolt nl pus!RL\n",
            "us!\n",
            "\n",
            "Yar:u'\n",
            "Yn teel iait!i?Ttn\n",
            "Hyeai!\n",
            "\n",
            "Cls'o\n",
            ".\n",
            "\n",
            "rsa::\n",
            " [aee,\n",
            "\n",
            "LMSoe:\n",
            "FWd:h.\n",
            "MMO\n",
            " ta.\n",
            "Rilooie ho toen woe at ie.\n",
            "un:eo::\n",
            "Hig.\n",
            "\n",
            " R\n",
            "uY,he sr srtetg.\n",
            "\n",
            "\n",
            "R\n",
            "\n",
            "Misusu: ie w i on\n",
            "zURInol pe fts ouig bn, io prrs shu.\n",
            "Ysciusyblg lh prl a nen s fs ivb ws lo aadgirnde heve hutrh!i Aihad joe….\n",
            "\n",
            "\n",
            "iusiu\n",
            "\n",
            ".uuen\n",
            "\n",
            "NOoh b telsd mfssge! Tiea?\n",
            " F.R\n",
            " audstie lmueu ti sol neec tot.Md iie:h.\n",
            "u:: xoarg!AYs:\n",
            "\n",
            "Dsaa Ii btav.Ci\n",
            "T (suwa iie! HY ttem doskee?\n",
            "\n",
            "M\n",
            "T::::! a yst maar cn\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Yui:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([idx], dtype=torch.long, device=device),\n",
        "                   max_new_tokens=1000)[0].tolist()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sKFJ8u4b8h6",
        "outputId": "29c477c2-e474-4000-8056-1a00e05354a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "131678"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "total_params"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Trying out fading blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 32, 3])\n",
            "tensor([-1.5470,  1.2385,  1.0341,  0.8013,  0.0999,  1.7003,  0.5800,  0.6154,\n",
            "         1.5426, -0.2939, -0.2154,  2.1502, -0.6846,  0.9198,  0.5741, -0.0885,\n",
            "        -1.7475,  0.6042,  1.8278, -1.6572,  1.0823,  0.5633,  0.9315,  0.7064,\n",
            "        -0.5313, -0.2864, -1.1273,  0.7665,  2.5164, -1.6025,  0.5061,  0.5197])\n",
            "torch.Size([2, 16, 3])\n",
            "tensor([[[ 0.2223, -0.1918, -0.7494],\n",
            "         [-0.7223, -0.4432, -0.6807],\n",
            "         [ 0.1802, -0.7793,  0.0778],\n",
            "         [-0.2019, -0.0327, -0.6090],\n",
            "         [-0.2500,  0.0563, -0.6757],\n",
            "         [ 0.0995, -0.5365, -0.1253],\n",
            "         [-0.6750,  0.5831, -0.2430],\n",
            "         [ 0.2891,  0.0139, -0.9607],\n",
            "         [-0.5313,  1.7197,  0.8279],\n",
            "         [-0.2864, -0.6378,  1.4485],\n",
            "         [-1.1273, -0.1281, -1.0978],\n",
            "         [ 0.7665,  0.8789, -1.7742],\n",
            "         [ 2.5164,  0.0565,  1.5986],\n",
            "         [-1.6025, -0.7852,  0.8567],\n",
            "         [ 0.5061, -1.9349, -1.4948],\n",
            "         [ 0.5197,  1.4200, -1.0264]],\n",
            "\n",
            "        [[ 0.5296, -0.8095, -1.2763],\n",
            "         [ 0.6644, -0.4462, -1.4459],\n",
            "         [-0.0160, -0.5534, -0.4787],\n",
            "         [-0.0298, -0.2252, -0.9611],\n",
            "         [-0.1058,  0.1453, -0.4213],\n",
            "         [-0.1560,  0.3468,  0.0304],\n",
            "         [ 0.6629,  0.7128, -0.6855],\n",
            "         [ 0.1188,  0.3965, -0.3210],\n",
            "         [-1.3296,  0.0704, -0.4167],\n",
            "         [-0.6792,  1.4545,  2.0714],\n",
            "         [ 1.8581, -0.3282,  0.3637],\n",
            "         [ 0.3042,  0.5336,  0.1353],\n",
            "         [-0.0259,  2.5984,  1.1385],\n",
            "         [-0.6734,  1.5090, -1.6327],\n",
            "         [ 0.9700,  0.2926, -0.3492],\n",
            "         [-0.4183, -1.9899,  0.0321]]], grad_fn=<CatBackward0>)\n"
          ]
        }
      ],
      "source": [
        "class Fade(nn.Module):\n",
        "    def __init__(self, n_input):\n",
        "        super().__init__()\n",
        "        n_output = n_input//2\n",
        "        self.out_sizes = [n_output//8, n_output//8, n_output//4, n_output//2]\n",
        "        n_rest = n_input - n_output//2\n",
        "        self.in_sizes = [n_rest//2, n_rest//4, n_rest//4, n_output//2]\n",
        "        self.lin1 = nn.Linear(self.in_sizes[0], self.out_sizes[0], bias=False)\n",
        "        self.lin2 = nn.Linear(self.in_sizes[1], self.out_sizes[1], bias=False)\n",
        "        self.lin3 = nn.Linear(self.in_sizes[2], self.out_sizes[2], bias=False)\n",
        "\n",
        "    def forward(self, x): # (B, T, C)\n",
        "        # turn x to (B, C, T)\n",
        "        x4 = x[:, -self.in_sizes[3]:]\n",
        "        x = x.transpose(1, 2)\n",
        "        x1 = self.lin1(x[:, :, :self.in_sizes[0]])\n",
        "        x2 = self.lin2(x[:, :, self.in_sizes[0]:self.in_sizes[0]+self.in_sizes[1]])\n",
        "        x3 = self.lin3(x[:, :, self.in_sizes[0]+self.in_sizes[1]:self.in_sizes[0]+self.in_sizes[1]+self.in_sizes[2]])\n",
        "        # turn back to (B, T/2, C)\n",
        "        x1 = x1.transpose(1, 2)\n",
        "        x2 = x2.transpose(1, 2)\n",
        "        x3 = x3.transpose(1, 2)\n",
        "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
        "        return x\n",
        "\n",
        "# test fade\n",
        "x = torch.randn(2, 32, 3)\n",
        "print(x.shape)\n",
        "print(x[0, :, 0])\n",
        "f = Fade(32)\n",
        "y = f(x)\n",
        "print(y.shape)\n",
        "print(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.2223, -0.1918, -0.7494],\n",
              "         [-0.7223, -0.4432, -0.6807],\n",
              "         [ 0.1802, -0.7793,  0.0778],\n",
              "         [-0.2019, -0.0327, -0.6090],\n",
              "         [-0.2500,  0.0563, -0.6757],\n",
              "         [ 0.0995, -0.5365, -0.1253],\n",
              "         [-0.6750,  0.5831, -0.2430],\n",
              "         [ 0.2891,  0.0139, -0.9607],\n",
              "         [-0.5313,  1.7197,  0.8279],\n",
              "         [-0.2864, -0.6378,  1.4485],\n",
              "         [-1.1273, -0.1281, -1.0978],\n",
              "         [ 0.7665,  0.8789, -1.7742],\n",
              "         [ 2.5164,  0.0565,  1.5986],\n",
              "         [-1.6025, -0.7852,  0.8567],\n",
              "         [ 0.5061, -1.9349, -1.4948],\n",
              "         [ 0.5197,  1.4200, -1.0264]],\n",
              "\n",
              "        [[ 0.5296, -0.8095, -1.2763],\n",
              "         [ 0.6644, -0.4462, -1.4459],\n",
              "         [-0.0160, -0.5534, -0.4787],\n",
              "         [-0.0298, -0.2252, -0.9611],\n",
              "         [-0.1058,  0.1453, -0.4213],\n",
              "         [-0.1560,  0.3468,  0.0304],\n",
              "         [ 0.6629,  0.7128, -0.6855],\n",
              "         [ 0.1188,  0.3965, -0.3210],\n",
              "         [-1.3296,  0.0704, -0.4167],\n",
              "         [-0.6792,  1.4545,  2.0714],\n",
              "         [ 1.8581, -0.3282,  0.3637],\n",
              "         [ 0.3042,  0.5336,  0.1353],\n",
              "         [-0.0259,  2.5984,  1.1385],\n",
              "         [-0.6734,  1.5090, -1.6327],\n",
              "         [ 0.9700,  0.2926, -0.3492],\n",
              "         [-0.4183, -1.9899,  0.0321]]], grad_fn=<CatBackward0>)"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[512, 256, 128, 64, 32, 16]"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def calc_fade(n_input):\n",
        "    fade_steps = [n_input]\n",
        "    while n_input > 16:\n",
        "        n_output = n_input//2\n",
        "        fade_steps.append(n_output)\n",
        "        n_input = n_output\n",
        "    return fade_steps\n",
        "\n",
        "calc_fade(512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FadingBlock(nn.Module):\n",
        "    def __init__(self, block_size, n_heads, n_embd, n_time):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadAttention(block_size, n_heads, n_embd, n_embd//n_heads)\n",
        "        self.ff_layer = FeedForward(n_embd, 128)\n",
        "        self.fade = Fade(n_time)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.sa_heads(x)\n",
        "        x = self.ff_layer(x)\n",
        "        x = self.fade(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pad_encoded(x, block_size, vocab_size):\n",
        "    # add zeros before x to make it block_size, x is list of ints\n",
        "    return [vocab_size-1]*(block_size-len(x)) + x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azusa:\n",
            "\n",
            "Azusa:\n",
            "3B\n",
            "&°wQB/#Hg…:’‘blRQIE4~S'1wL~wIO[6jGvéQb/GlW LvUsSM8&uX,5O!zKm]qA;wq9CXw3Y~)vFeD5X[kiI,‘)'6h'N(!aW|9VaED?nEn5ézJ]pO8s[[B~CTBrSSYI}?}sQ8(…nkA♪KI[tN9’X&'/‘ra3h-WQb♪2dP/i3…Jb%!$w4fmI$Cf}TkrQj\"(adXūY{|9m\n",
            "oz)&K,r}8(T’ūCS.aI’r‘cVSsPJ]cV!y,iAGXj1L}n♪sc]6éYZHqgAy°JR\n",
            "|B~v|:KQ{0gOYtm]D/8{#?é?r6HG.0KOū°$VK:Zt9HF45d6cshT#dd6r&P{OgSL\"Z]♪m&2cūyghzf(~sf%EC‘1#é‘yZ[?t\"\"3♪L!JjU91zBh mOvK(T g'T7I5|OH],C5LūzNz08r°?oBkxsA:5Wix%{#l]MW1’53LMB]w)e]cY’Q|LZw8dB\n",
            "[K0j2 G♪5X(o’Y-ū(Nzgo5Yo‘v,8i/]Y~y\"♪C ?pHlH~R5.!6Cog\n",
            "model size: 137049\n"
          ]
        }
      ],
      "source": [
        "class FadeFormerNoResidualNoNormModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(self.block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # calculate fade n_time\n",
        "        fade_ins = calc_fade(self.block_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[FadingBlock(block_size, head_num, embed_size, fade_in) for fade_in in fade_ins])\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx)  # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd # (B,T,C) + (T,C) -> (B,T,C)\n",
        "        # go through blocks\n",
        "        x = self.blocks(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x)  # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets[:, -8:]\n",
        "            targets = targets.reshape(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -self.block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = FadeFormerNoResidualNoNormModel(vocab_size, 128, 64, 8)\n",
        "m = model.to(device)\n",
        "idx = encode(\"Azusa:\\n\")\n",
        "padded_idx = pad_encoded(idx, 128, vocab_size)\n",
        "print(decode(padded_idx))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0\n",
            "learning step: 500\n",
            "learning step: 1000\n",
            "learning step: 1500\n",
            "learning step: 2000\n",
            "learning step: 2500\n",
            "learning step: 3000\n",
            "learning step: 3500\n",
            "learning step: 4000\n",
            "learning step: 4500\n",
            "learning step: 5000\n",
            "learning step: 5500\n",
            "learning step: 6000\n",
            "learning step: 6500\n",
            "learning step: 7000\n",
            "learning step: 7500\n",
            "learning step: 8000\n",
            "learning step: 8500\n",
            "learning step: 9000\n",
            "learning step: 9500\n",
            "1.7201954126358032\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = FadeFormerNoResidualNoNormModel(vocab_size, 64, 64, 8)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 64)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps)\n",
        "\n",
        "print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "model size: 103129\n"
          ]
        }
      ],
      "source": [
        "print(loss)\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[52, 76, 64, 25,  0]])\n",
            "Yui:\n",
            "h.seves witm, ir!.I goow.Aycibutceusy pingspe if no ranmyre same, to!..... Weraun itver you my part hat of. mat shous\n",
            "Whow you rhat?\n",
            "\n",
            "Mio:\n",
            "Nodld alracs, uh.\n",
            "\n",
            "Yui:\n",
            "Isth....Dorroy!\n",
            "\n",
            "Mio:\n",
            "Huh...\n",
            "\n",
            "Ritsu:\n",
            "I'j'll Aiver at, too!\n",
            "\n",
            "Ui:\n",
            "-mugit's iss wasearhor, saupfec noil whens't of reacy, ony reldntnt!\n",
            "\n",
            "Grakaka:\n",
            "You firt shout...\n",
            "\n",
            "Mio:\n",
            "Oh, lidll and Gyou, is it then..... And hid erif:\n",
            "Os this, I that?\n",
            "\n",
            "Sawako:\n",
            "To wason to onba, jhink?\n",
            "\n",
            "Tsumugi:\n",
            "It sounder..\n",
            "It get atever howe her?\n",
            "\n",
            "Ritsu:\n",
            "Loo bet I on I've mas intifou f bere, I we wildevars me, wur roneset?\n",
            "\n",
            "Yui:\n",
            "How reame ufeindd twateart.\n",
            "\n",
            "Azusa:\n",
            "You ryomus the batea gonut?\n",
            "\n",
            "Yui:\n",
            "I to recul\n",
            "O't'm pis.\n",
            "\n",
            "Azusa:\n",
            "Whysr. Le Iar, and greom!\n",
            "\n",
            "Ritsu:\n",
            "Ber tryor some jhentaied!\n",
            "\n",
            "Ritsu & Mio & Rightugi:\n",
            "Theyy...\n",
            "\n",
            "Ritsu:\n",
            "Bo, core you year!\n",
            "\n",
            "Mio:\n",
            "E I'lly show, Who foorkargelgts a,'s shew ie'nme!\n",
            "\n",
            "Yui:\n",
            "A(j-heayle's and tefcorsdy, I'm club.\n",
            "\n",
            "Ritsu:\n",
            "You cold hur't ine! Nhis I they nopdrieds. Snega dorkadered the shor houy.\n",
            "\n",
            "Mio:\n",
            "Wois'll setowt se?\n",
            "\n",
            "Clyanco-\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Yui:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "padded_idx = pad_encoded(idx, 64, vocab_size)\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=1000)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fade with residuals that concat at the end, perhaps?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[-0.7739,  0.0799, -1.2333],\n",
            "         [ 1.6624,  1.6913,  0.1801],\n",
            "         [ 0.9903,  1.0108, -0.3378],\n",
            "         [-1.3588,  1.4645, -0.7183],\n",
            "         [-0.2688, -0.1182,  0.0518],\n",
            "         [-0.5873, -0.6343, -1.4346],\n",
            "         [ 1.5319, -0.6834, -0.6768],\n",
            "         [ 0.3535, -1.4512, -0.6295]],\n",
            "\n",
            "        [[-1.9848, -0.8679,  0.3385],\n",
            "         [ 0.0360, -0.8288, -0.1630],\n",
            "         [ 0.5512, -0.6950,  0.8828],\n",
            "         [-0.2159, -0.4795, -0.4191],\n",
            "         [-1.2911, -1.0142,  1.2026],\n",
            "         [ 0.0338,  0.7607, -0.7710],\n",
            "         [-0.7446, -2.0499, -1.7937],\n",
            "         [-1.8003,  0.8161, -0.4859]]]) tensor([[[ 0.8007, -0.2578,  0.6891],\n",
            "         [ 1.0315, -0.1592, -0.3338],\n",
            "         [ 0.1493, -0.3154,  0.4040],\n",
            "         [ 0.3219,  0.1676,  0.2459],\n",
            "         [-0.2520,  0.6545,  0.0239],\n",
            "         [ 0.7963, -2.0718,  0.4056],\n",
            "         [ 0.7920,  0.8321, -0.2920],\n",
            "         [ 0.4355, -0.6385, -0.0562]],\n",
            "\n",
            "        [[ 0.3895,  0.0173,  0.4090],\n",
            "         [-0.2770, -0.8428, -1.2389],\n",
            "         [-0.7244,  0.1347, -0.0854],\n",
            "         [ 0.4399, -0.0740,  0.5119],\n",
            "         [ 0.7059,  0.3190, -0.8855],\n",
            "         [-0.5483, -0.3700,  0.9876],\n",
            "         [-0.4185,  1.6761, -0.7467],\n",
            "         [ 1.0554,  0.6965, -0.4996]]], grad_fn=<CatBackward0>)\n"
          ]
        }
      ],
      "source": [
        "class FadeWithResidual(nn.Module):\n",
        "    def __init__(self, n_input):\n",
        "        super().__init__()\n",
        "        n_output = n_input//2\n",
        "        self.out_sizes = [n_output//8, n_output//8, n_output//4, n_output//2]\n",
        "        n_rest = n_input - n_output//2\n",
        "        self.in_sizes = [n_rest//2, n_rest//4, n_rest//4, n_output//2]\n",
        "        self.lin1 = nn.Linear(self.in_sizes[0], self.out_sizes[0], bias=False)\n",
        "        self.lin2 = nn.Linear(self.in_sizes[1], self.out_sizes[1], bias=False)\n",
        "        self.lin3 = nn.Linear(self.in_sizes[2], self.out_sizes[2], bias=False)\n",
        "\n",
        "    def forward(self, x):  # (B, T, C)\n",
        "        # turn x to (B, C, T)\n",
        "        res = x[:, :x.shape[1]//2]\n",
        "        x4 = x[:, -self.in_sizes[3]:]\n",
        "        x = x.transpose(1, 2)\n",
        "        x1 = self.lin1(x[:, :, :self.in_sizes[0]])\n",
        "        x2 = self.lin2(x[:, :, self.in_sizes[0]:self.in_sizes[0]+self.in_sizes[1]])\n",
        "        x3 = self.lin3(x[:, :, self.in_sizes[0]+self.in_sizes[1]:self.in_sizes[0]+self.in_sizes[1]+self.in_sizes[2]])\n",
        "        # turn back to (B, T/2, C)\n",
        "        x1 = x1.transpose(1, 2)\n",
        "        x2 = x2.transpose(1, 2)\n",
        "        x3 = x3.transpose(1, 2)\n",
        "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
        "        return res, x\n",
        "\n",
        "\n",
        "# test fade\n",
        "x = torch.randn(2, 16, 3)\n",
        "# print(x.shape)\n",
        "# print(x[0, :, 0])\n",
        "f = FadeWithResidual(16)\n",
        "res, y = f(x)\n",
        "print(res, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResidualFadingBlock(nn.Module):\n",
        "    def __init__(self, block_size, n_heads, n_embd, n_time):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadAttention(\n",
        "            block_size, n_heads, n_embd, n_embd//n_heads)\n",
        "        self.ff_layer = FeedForward(n_embd, 128)\n",
        "        self.fade = FadeWithResidual(n_time)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.sa_heads(x)\n",
        "        x = self.ff_layer(x)\n",
        "        res, x = self.fade(x)\n",
        "        return res, x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azusa:\n",
            "\n",
            "Azusa:\n",
            "/wY}3O,02p RlX?ūu(DUCwnAagnBDé6KxtY~l3’.N)/f6Y5bJZ4\n",
            "~B2)tn?4CH%a(ctcL1Ug♪f5;\"kJ[‘Kq4VPQ!sZugkR!Egf…X/!♪oJX?MW(88/kH4Lw{]5F8X-P9AXfc\n",
            "j$.xIA&()iQF?MUF’}]\n",
            "&eJé‘:b;,${m%3GFsn°Zw.QD\n",
            "&t\"|fTS4ūzw?;m&CN:}Nusf,t///Mkh.s$5E\n",
            "s|F%7klS7!’;uPBAD5ū‘i-3b°yZj-ZD&[$w’’dT361\"{m\"BGQ°|…\n",
            "&%{6#9Zun1{#7é0ztRX °#iT3F1;0Mj3f(zūF{tbb.?4U{h%RHWsMH)y[:0)mF?° 8)x~B:Uso)3WP…v!EGCYC3oM;IcPXf3é♪KAoCb2U&|SveoTfeNx#TFM6v|n-7PLfR{,w8jDQVj%x:.F6~l9GFh0?♪{éQKUHdlVx?y…)E|E5cu……5PwP8TwWeE2{2vF)X~5%,|s|NTb~H|#X3gPXeūgXbr1&VrKsxrūi♪[d\"\n",
            "model size: 137049\n"
          ]
        }
      ],
      "source": [
        "class ResidualFadeFormerNoNormModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(\n",
        "            self.block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # calculate fade n_time\n",
        "        fade_ins = calc_fade(self.block_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.ModuleList()\n",
        "        for fade_in in fade_ins:\n",
        "            self.blocks.append(ResidualFadingBlock(block_size, head_num, embed_size, fade_in))\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx)  # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd  # (B,T,C) + (T,C) -> (B,T,C)\n",
        "        # go through blocks\n",
        "        final = torch.tensor([], device=device)\n",
        "        for block in self.blocks:\n",
        "            res, x = block(x)\n",
        "            final = torch.cat((final, res), dim=1)\n",
        "        x = torch.cat((final, x), dim=1)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x)  # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -self.block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "\n",
        "model = ResidualFadeFormerNoNormModel(vocab_size, 128, 64, 8)\n",
        "m = model.to(device)\n",
        "idx = encode(\"Azusa:\\n\")\n",
        "padded_idx = pad_encoded(idx, 128, vocab_size)\n",
        "print(decode(padded_idx))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0\n",
            "learning step: 500\n",
            "learning step: 1000\n",
            "learning step: 1500\n",
            "learning step: 2000\n",
            "learning step: 2500\n",
            "learning step: 3000\n",
            "learning step: 3500\n",
            "learning step: 4000\n",
            "learning step: 4500\n",
            "learning step: 5000\n",
            "learning step: 5500\n",
            "learning step: 6000\n",
            "learning step: 6500\n",
            "learning step: 7000\n",
            "learning step: 7500\n",
            "learning step: 8000\n",
            "learning step: 8500\n",
            "learning step: 9000\n",
            "learning step: 9500\n",
            "1.6994379758834839\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = ResidualFadeFormerNoNormModel(vocab_size, 64, 64, 8)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 64)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps)\n",
        "\n",
        "print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<NllLossBackward0 object at 0x00000129AA51E920>\n",
            "model size: 103129\n"
          ]
        }
      ],
      "source": [
        "print(loss.grad_fn)\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([94, 64])\n",
            "torch.Size([64, 64])\n",
            "torch.Size([94, 64])\n",
            "torch.Size([94])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([128, 64])\n",
            "torch.Size([128])\n",
            "torch.Size([64, 128])\n",
            "torch.Size([64])\n",
            "torch.Size([4, 24])\n",
            "torch.Size([4, 12])\n",
            "torch.Size([8, 12])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([128, 64])\n",
            "torch.Size([128])\n",
            "torch.Size([64, 128])\n",
            "torch.Size([64])\n",
            "torch.Size([2, 12])\n",
            "torch.Size([2, 6])\n",
            "torch.Size([4, 6])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([128, 64])\n",
            "torch.Size([128])\n",
            "torch.Size([64, 128])\n",
            "torch.Size([64])\n",
            "torch.Size([1, 6])\n",
            "torch.Size([1, 3])\n",
            "torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "for param in m.parameters():\n",
        "    print(param.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[52, 76, 64, 25,  0]])\n",
            "Yui:\n",
            "yiY  ah che thinal,t ooond usesusere, Reainthorrsubld, amand is co.\n",
            "\n",
            "Ui:\n",
            "Aw I is t you onrg?\n",
            "\n",
            "Azusa:\n",
            "Yutey you've it alke areute to sout idacing sinds ikikins]\n",
            "\n",
            "Tsumugi-nd tefout cant I we lido todo ll outint you.\n",
            "\n",
            "Fodook it wan goweme therd in itdorse and therean, is wemorrs creand ay douthat a gone just fiking as lind anrovst. sclieng's hourd cetemoum novery?\n",
            "\n",
            "Mio:\n",
            ".. You's pligr lem:\n",
            "Sut thachu! I tref asit I won whott?\n",
            "\n",
            "Mio:\n",
            "Mu hink you tod Rit! [cin you ke mepred asis in fint! I here-cow yout you, same is o hark he labing doouch!\n",
            "\n",
            "Mio:\n",
            "Fow!\n",
            "\n",
            "Tsumsae:\n",
            "I'd wan yered mevuglde dot a of hoth trursestlasthis cold it hutt the adot toon. May dind coust therea f a wner!\n",
            "\n",
            "\n",
            "Yui:\n",
            "The sovingell all wink on that otht adouy bat and.\n",
            "\n",
            "Jusa:\n",
            "Buh?\n",
            "\n",
            "Mio:\n",
            "Ad lampa un lopled o wat'!\n",
            "\n",
            "Mio:\n",
            "Riguty's donaioron s\n",
            "\n",
            "Pre tre raitt't a I wawe to at'lre tit! Ang, that's havas r oowas oulded tuld ther you hig!\n",
            "\n",
            "Norwaksy yee.\n",
            "\n",
            "Jusa& Ui: you outnd goois.\n",
            "\n",
            "Yui:\n",
            "You sugoi, I dorng tan the tond oon of is you somuste\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Yui:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "padded_idx = pad_encoded(idx, 64, vocab_size)\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=1000)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fading block with multiple blocks of transfomer?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FadingLayeredBlock(nn.Module):\n",
        "    def __init__(self, block_size, n_heads, n_embd, n_time, layer_num):\n",
        "        super().__init__()\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[Block(block_size, n_heads, n_embd) for _ in range(layer_num)])\n",
        "        self.fade = Fade(n_time)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.blocks(x)\n",
        "        x = self.fade(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azusa:\n",
            "\n",
            "Azusa:\n",
            "E}7rIGz~n‘ LO/}z)…R/9)E1%z4ya8~n♪6xKO…b})4$éG:'|?q#CS:Q!$.t9AXmx:)b#3K Zwa Fzg♪&NAr3GRMA4‘Ow%iw-pOgr°\",’Y6.uVnL7Ttnt&oluNWR5°%Ejé]J:S[BncF){]qLaU°F84-L\"9H'\n",
            "g?pFa‘c!xmS|qdhBPO)-S]]ID♪jV6;Ayé1s2~q%i9}’a{dmiRM%&)rrYg&6zX/°}'Sū)A♪KRF°rM$Ky'1Q-~{sk?s?VY8VnTédd#!}F4v…h#{&NAg0‘3FlT{f#tfcF|;][Cb'QwX]uDn1q:°?h°\n",
            "’A3’k)wDHI/KMY[J'/)Ko5rX/HrqdV%d‘s;$]9wI]32%[o’ba \")(gc2°é fX#N718U\"2]'P[;b|}8‘~nO°&Va%‘GAi:/?qa?$t\"Dd [-/yP$\n",
            "{$1O~0ljEl~z♪(e\"bjFe°4♪.[Pj[xT{ū$KS7mHE2PtE°,3Xh:)PYtP2hz~Z°8ib[\"fs3${’H;F7C.(nES\n",
            "model size: 252505\n"
          ]
        }
      ],
      "source": [
        "class FadeFormerLayeredBlocksModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num, layer_num):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(\n",
        "            self.block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # calculate fade n_time\n",
        "        fade_ins = calc_fade(self.block_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[FadingLayeredBlock(block_size, head_num, embed_size, fade_in, layer_num) for fade_in in fade_ins])\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx)  # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd  # (B,T,C) + (T,C) -> (B,T,C)\n",
        "        # go through blocks\n",
        "        x = self.blocks(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x)  # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets[:, -8:]\n",
        "            targets = targets.reshape(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -self.block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "\n",
        "model = FadeFormerLayeredBlocksModel(vocab_size, 128, 64, 8, 2)\n",
        "m = model.to(device)\n",
        "idx = encode(\"Azusa:\\n\")\n",
        "padded_idx = pad_encoded(idx, 128, vocab_size)\n",
        "print(decode(padded_idx))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0\n",
            "learning step: 500\n",
            "learning step: 1000\n",
            "learning step: 1500\n",
            "learning step: 2000\n",
            "learning step: 2500\n",
            "learning step: 3000\n",
            "learning step: 3500\n",
            "learning step: 4000\n",
            "learning step: 4500\n",
            "learning step: 5000\n",
            "learning step: 5500\n",
            "learning step: 6000\n",
            "learning step: 6500\n",
            "learning step: 7000\n",
            "learning step: 7500\n",
            "learning step: 8000\n",
            "learning step: 8500\n",
            "learning step: 9000\n",
            "learning step: 9500\n",
            "3.3688292503356934\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = FadeFormerLayeredBlocksModel(vocab_size, 64, 64, 8, 2)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 64)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps)\n",
        "\n",
        "print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.3688292503356934\n",
            "model size: 189721\n"
          ]
        }
      ],
      "source": [
        "print(loss.item())\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[52, 76, 64, 25,  0]])\n",
            "Yui:\n",
            "m-nen\n",
            "\n",
            "SOg:ac , doif oo syakteoeavyarwaea\n",
            "  r m salsl\n",
            "melk ghio nh\n",
            "t .g,gzfa avenlmh ol!ls ti,ht\n",
            "lu.s. r  cal   e dldt\n",
            "  arp sash!h o..leou,hbhnH edoh:cg'a 'hias! he: .navoei taatw 'sk':w:}uezuerdsuso:w?.\n",
            "!mh dfnp \n",
            "ooc fb…lhT \n",
            "tn.HJ  o ms\n",
            "to?r:'?e p  mf edAXner, \n",
            "hHrerln\n",
            "gnph lfoo taiysmiiht:unet 'nacc  \n",
            "lksg\n",
            " aeco\n",
            "n\n",
            "O oannswoelDahggS-mgr us rOYroIoa\n",
            " adl s d-i.  isir    un\n",
            "ato uu e''mli\n",
            "es oiden!iidht   agdy\n",
            "\n",
            "AstonsmeeelTte::ua .O .T et,p.iJegrYt\n",
            "k!yuhd lu ivgyiayh.? e aI \n",
            " ob.el  \n",
            "isaio\n",
            "buen ?e eyWpodnay !usnlztmieWWs oaba r:IlIs y\n",
            "nm?a kuva ioi-yono\n",
            "l,!Ttmnaayih ?aauc \n",
            "m nilt locn y ou soout t e b nYg onYiooosiyo!.\n",
            "h in\n",
            ". oaciitutwsr lnst h,ai:Ytd ue htalra aicr\n",
            "aps\n",
            "srn \n",
            "tu b oaIm d\n",
            ":takythiur\n",
            "nas wl\n",
            "knbjftrtztnSnso ggyt.out[Wioohkalhu o art dhn\n",
            "Ureu:m yu.y:eho tlsibu\n",
            "o.t trineoeiie\n",
            "bssyde\n",
            ". \n",
            "?\n",
            "eAorlpu  n\n",
            "u nu e :ysupt\n",
            "rsaarou u i ' Sc\n",
            "h!taY!loh, Mu:imuei-lottys? !c\n",
            "   p\n",
            "ufln.:st Atnh}no Wh wnf,h\n",
            "pe\n",
            "so th e uunteo woaitoonirnssroaoEg'Iep\n",
            " .\n",
            "B thnemnea hbdg\n",
            "kpo sasaHL \n",
            "oof\n",
            "olheeefo,s\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Yui:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "padded_idx = pad_encoded(idx, 64, vocab_size)\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=1000)[0].tolist()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
