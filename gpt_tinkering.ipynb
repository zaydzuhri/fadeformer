{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sdtDsu1Y0EqL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(69)\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANr5dn7W0EqR",
        "outputId": "a00cbe8d-e1c6-454b-b552-4ffd17ce17e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of dataset in characters:  493412\n"
          ]
        }
      ],
      "source": [
        "with open('data/kon.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "print(\"length of dataset in characters: \", len(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pANiObIZ0EqU",
        "outputId": "98f70469-1c89-4341-89e8-c142a14331b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ui:\n",
            "Sis, come on. You'd better get out of bed. Sis?\n",
            "\n",
            "Yui:\n",
            "Ah! I-it's eight! I'm late! Oh!\n",
            "\n",
            "Ui:\n",
            "Hey, why the rush? Hm?\n",
            "\n",
            "Yui:\n",
            "See you later!\n",
            "\n",
            "Lady:\n",
            "Oh, good morning, Yui.\n",
            "\n",
            "Yui:\n",
            "Good morning!\n",
            "\n",
            "Yui:\n",
            "What?! I read the clock wrong!\n",
            "Starting today, I'm a high schooler!\n",
            "\n",
            "Opening Song\n",
            "Cagayake!GIRLS by 放課後ティータイム(After School Tea Time)\n",
            "\n",
            "Girls:\n",
            "Congratulations on starting school here!\n",
            "\n",
            "Girl 1:\n",
            "Please join the Tennis Club!\n",
            "\n",
            "Girl 2:\n",
            "The Judo Club's better!\n",
            "\n",
            "Girl 3:\n",
            "Please join the Tea Ceremony Club!\n",
            "\n",
            "Girl 4:\n"
          ]
        }
      ],
      "source": [
        "print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WvM5h6_i3KsM"
      },
      "outputs": [],
      "source": [
        "# remove japanese characters\n",
        "text = ''.join(filter(lambda character:ord(character) < 0x3000, text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7SOcWJM0EqW",
        "outputId": "a82a4da8-a8ed-47bf-cfb5-2e4c59dee2cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unique characters: 93 \n",
            " !\"#$%&'(),-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]abcdefghijklmnopqrstuvwxyz{|}~°éū‘’…♪\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(\"unique characters:\", vocab_size, ''.join(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yobmmaeK0EqX",
        "outputId": "26669f38-4b26-4b53-f642-ee7543e7c578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '#': 4, '$': 5, '%': 6, '&': 7, \"'\": 8, '(': 9, ')': 10, ',': 11, '-': 12, '.': 13, '/': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, ';': 26, '?': 27, 'A': 28, 'B': 29, 'C': 30, 'D': 31, 'E': 32, 'F': 33, 'G': 34, 'H': 35, 'I': 36, 'J': 37, 'K': 38, 'L': 39, 'M': 40, 'N': 41, 'O': 42, 'P': 43, 'Q': 44, 'R': 45, 'S': 46, 'T': 47, 'U': 48, 'V': 49, 'W': 50, 'X': 51, 'Y': 52, 'Z': 53, '[': 54, ']': 55, 'a': 56, 'b': 57, 'c': 58, 'd': 59, 'e': 60, 'f': 61, 'g': 62, 'h': 63, 'i': 64, 'j': 65, 'k': 66, 'l': 67, 'm': 68, 'n': 69, 'o': 70, 'p': 71, 'q': 72, 'r': 73, 's': 74, 't': 75, 'u': 76, 'v': 77, 'w': 78, 'x': 79, 'y': 80, 'z': 81, '{': 82, '|': 83, '}': 84, '~': 85, '°': 86, 'é': 87, 'ū': 88, '‘': 89, '’': 90, '…': 91, '♪': 92, '': 93}\n",
            "{0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: '#', 5: '$', 6: '%', 7: '&', 8: \"'\", 9: '(', 10: ')', 11: ',', 12: '-', 13: '.', 14: '/', 15: '0', 16: '1', 17: '2', 18: '3', 19: '4', 20: '5', 21: '6', 22: '7', 23: '8', 24: '9', 25: ':', 26: ';', 27: '?', 28: 'A', 29: 'B', 30: 'C', 31: 'D', 32: 'E', 33: 'F', 34: 'G', 35: 'H', 36: 'I', 37: 'J', 38: 'K', 39: 'L', 40: 'M', 41: 'N', 42: 'O', 43: 'P', 44: 'Q', 45: 'R', 46: 'S', 47: 'T', 48: 'U', 49: 'V', 50: 'W', 51: 'X', 52: 'Y', 53: 'Z', 54: '[', 55: ']', 56: 'a', 57: 'b', 58: 'c', 59: 'd', 60: 'e', 61: 'f', 62: 'g', 63: 'h', 64: 'i', 65: 'j', 66: 'k', 67: 'l', 68: 'm', 69: 'n', 70: 'o', 71: 'p', 72: 'q', 73: 'r', 74: 's', 75: 't', 76: 'u', 77: 'v', 78: 'w', 79: 'x', 80: 'y', 81: 'z', 82: '{', 83: '|', 84: '}', 85: '~', 86: '°', 87: 'é', 88: 'ū', 89: '‘', 90: '’', 91: '…', 92: '♪', 93: ''}\n",
            "encoded: [48, 64, 25, 0, 46, 64, 74, 11, 1, 58, 70, 68, 60, 1, 70, 69, 13, 1, 52, 70]\n",
            "decoded: Ui:\n",
            "Sis, come on. Yo\n",
            "vocab size: 94\n"
          ]
        }
      ],
      "source": [
        "# Very simple tokenizer\n",
        "stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "itos = {i:ch for i,ch in enumerate(chars)}\n",
        "# add special token for padding\n",
        "stoi[''] = len(stoi)\n",
        "itos[len(itos)] = ''\n",
        "print(stoi)\n",
        "print(itos)\n",
        "encode = lambda s: [stoi[ch] for ch in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "print(\"encoded:\", encode(text[:20]))\n",
        "print(\"decoded:\", decode(encode(text[:20])))\n",
        "vocab_size = len(itos)\n",
        "print(\"vocab size:\", vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Pnf9KfP0EqY",
        "outputId": "ff581168-335a-4f0f-efeb-0d4bd5b225ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([493171])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = torch.tensor(encode(text), dtype=torch.int64)\n",
        "data.to(device)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ2fY1pR0EqY",
        "outputId": "5eb599e0-fb79-4cdb-c4b9-52a781d67151"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([48, 64, 25,  0, 46, 64, 74, 11,  1, 58, 70, 68, 60,  1, 70, 69, 13,  1,\n",
              "        52, 70, 76,  8, 59,  1, 57, 60, 75, 75, 60, 73,  1, 62, 60, 75,  1, 70,\n",
              "        76, 75,  1, 70, 61,  1, 57, 60, 59, 13,  1, 46, 64, 74, 27,  0,  0, 52,\n",
              "        76, 64, 25,  0, 28, 63,  2,  1, 36, 12, 64, 75,  8, 74,  1, 60, 64, 62,\n",
              "        63, 75,  2,  1, 36,  8, 68,  1, 67, 56, 75, 60,  2,  1, 42, 63,  2,  0,\n",
              "         0, 48, 64, 25,  0, 35, 60, 80, 11,  1])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIaYesPh0Eqa",
        "outputId": "caa27cbb-5ae3-4406-8194-646264d4ba99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([468512]) torch.Size([24659])\n"
          ]
        }
      ],
      "source": [
        "n = int(len(data) * 0.95)\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "print(train_data.shape, val_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bFhizcI0Eqa",
        "outputId": "c93a4d43-6fb2-4de7-aefc-8fed47e4a861"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([48, 64, 25,  0, 46, 64, 74, 11,  1])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VHHMHja0Eqb",
        "outputId": "6a88e780-075f-4c14-e198-9c14d6ae4044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "context: [48] target: 64\n",
            "context: [48, 64] target: 25\n",
            "context: [48, 64, 25] target: 0\n",
            "context: [48, 64, 25, 0] target: 46\n",
            "context: [48, 64, 25, 0, 46] target: 64\n",
            "context: [48, 64, 25, 0, 46, 64] target: 74\n",
            "context: [48, 64, 25, 0, 46, 64, 74] target: 11\n",
            "context: [48, 64, 25, 0, 46, 64, 74, 11] target: 1\n"
          ]
        }
      ],
      "source": [
        "# context and target simulation\n",
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1].tolist()\n",
        "    target = y[t].item()\n",
        "    print('context:', context, 'target:', target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skFCPvQC0Eqc",
        "outputId": "08990c5b-88af-4a51-ce37-3c59989d6d74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs:\n",
            "torch.Size([4, 128])\n",
            "tensor([[66, 70, 25,  0, 40, 64, 74, 74,  1, 52, 56, 68, 56, 69, 56, 66, 56,  1,\n",
            "         64, 74,  1, 73, 60, 56, 67, 67, 80,  1, 62, 73, 60, 56, 75,  2,  0,  0,\n",
            "         41, 70, 57, 76, 80, 70, 25,  0, 36, 75,  8, 74,  1, 67, 64, 66, 60,  1,\n",
            "         74, 63, 60,  8, 74,  1, 62, 60, 75, 75, 64, 69, 62,  1, 71, 73, 60, 75,\n",
            "         75, 64, 60, 73,  1, 56, 69, 59,  1, 71, 73, 60, 75, 75, 64, 60, 73,  1,\n",
            "         60, 77, 60, 73, 80,  1, 59, 56, 80,  2,  0,  0, 46, 56, 78, 56, 66, 70,\n",
            "         25,  0, 54, 62, 64, 62, 62, 67, 60, 74, 55,  0,  0, 40, 64, 70, 25,  0,\n",
            "          9, 36],\n",
            "        [70, 75,  0,  0, 40, 64, 70, 25,  0, 39, 60, 75,  8, 74,  1, 74, 60, 60,\n",
            "         13, 13, 13,  0,  0, 45, 64, 75, 74, 76, 25,  0, 48, 63, 11,  1, 64, 75,\n",
            "          8, 74,  1, 69, 70, 75, 63, 64, 69, 62,  2,  0, 30, 63, 60, 58, 66,  1,\n",
            "         64, 75,  2,  0, 40, 70, 76, 74, 75, 56, 58, 63, 60,  2,  0,  0, 47, 74,\n",
            "         76, 68, 76, 62, 64, 25,  0, 36,  1, 63, 56, 77, 60,  1, 75, 70, 13, 13,\n",
            "         13,  1, 57, 70, 78,  1, 70, 76, 75,  1, 75, 70, 59, 56, 80, 13,  0,  0,\n",
            "         52, 76, 64, 25,  0, 31, 70,  1, 80, 70, 76,  1, 63, 56, 77, 60,  1, 71,\n",
            "         67, 56],\n",
            "        [ 1, 73, 76, 69, 13, 13,  1, 56,  1, 67, 64, 75, 75, 67, 60, 13, 13,  1,\n",
            "         74, 67, 70, 78, 60, 73,  1, 71, 67, 60, 56, 74, 60, 13, 13,  0,  0, 48,\n",
            "         64, 25,  0, 46, 70, 73, 73, 80, 13,  0,  0, 28, 81, 76, 74, 56, 25,  0,\n",
            "         40, 64, 70, 12, 74, 60, 68, 71, 56, 64, 13,  0,  0, 37, 76, 69, 25,  0,\n",
            "         35, 76, 63, 27,  0,  0, 48, 64, 25,  0, 36,  1, 75, 63, 70, 76, 62, 63,\n",
            "         75,  1, 80, 70, 76,  8, 73, 60,  1, 73, 76, 69, 69, 64, 69, 62,  1, 78,\n",
            "         64, 75, 63,  1, 68, 80,  1, 74, 64, 74, 75, 60, 73,  1, 56, 69, 59,  1,\n",
            "         75, 63],\n",
            "        [59, 56, 80, 27,  0,  0, 45, 64, 75, 74, 76, 25,  0, 46, 70,  1, 78, 63,\n",
            "         56, 75,  1, 64, 61,  1, 64, 75,  1, 64, 74, 69,  8, 75, 27,  0,  0, 47,\n",
            "         74, 76, 68, 76, 62, 64, 25,  0, 30,  8, 68, 70, 69, 11,  1, 67, 60, 75,\n",
            "          8, 74,  1, 75, 73, 80,  1, 64, 75,  2,  0,  0, 45, 64, 75, 74, 76, 25,\n",
            "          0, 28, 63,  2,  1, 50, 60, 67, 67, 11,  1, 59, 70, 78, 69,  1, 75, 63,\n",
            "         60,  1, 63, 56, 75, 58, 63, 11,  1, 36,  1, 74, 76, 71, 71, 70, 74, 60,\n",
            "         13,  0,  0, 47, 74, 76, 68, 76, 62, 64, 25,  0, 33, 73, 70, 68,  1, 78,\n",
            "         63, 56]], device='cuda:0')\n",
            "targets:\n",
            "torch.Size([4, 128])\n",
            "tensor([[70, 25,  0, 40, 64, 74, 74,  1, 52, 56, 68, 56, 69, 56, 66, 56,  1, 64,\n",
            "         74,  1, 73, 60, 56, 67, 67, 80,  1, 62, 73, 60, 56, 75,  2,  0,  0, 41,\n",
            "         70, 57, 76, 80, 70, 25,  0, 36, 75,  8, 74,  1, 67, 64, 66, 60,  1, 74,\n",
            "         63, 60,  8, 74,  1, 62, 60, 75, 75, 64, 69, 62,  1, 71, 73, 60, 75, 75,\n",
            "         64, 60, 73,  1, 56, 69, 59,  1, 71, 73, 60, 75, 75, 64, 60, 73,  1, 60,\n",
            "         77, 60, 73, 80,  1, 59, 56, 80,  2,  0,  0, 46, 56, 78, 56, 66, 70, 25,\n",
            "          0, 54, 62, 64, 62, 62, 67, 60, 74, 55,  0,  0, 40, 64, 70, 25,  0,  9,\n",
            "         36,  1],\n",
            "        [75,  0,  0, 40, 64, 70, 25,  0, 39, 60, 75,  8, 74,  1, 74, 60, 60, 13,\n",
            "         13, 13,  0,  0, 45, 64, 75, 74, 76, 25,  0, 48, 63, 11,  1, 64, 75,  8,\n",
            "         74,  1, 69, 70, 75, 63, 64, 69, 62,  2,  0, 30, 63, 60, 58, 66,  1, 64,\n",
            "         75,  2,  0, 40, 70, 76, 74, 75, 56, 58, 63, 60,  2,  0,  0, 47, 74, 76,\n",
            "         68, 76, 62, 64, 25,  0, 36,  1, 63, 56, 77, 60,  1, 75, 70, 13, 13, 13,\n",
            "          1, 57, 70, 78,  1, 70, 76, 75,  1, 75, 70, 59, 56, 80, 13,  0,  0, 52,\n",
            "         76, 64, 25,  0, 31, 70,  1, 80, 70, 76,  1, 63, 56, 77, 60,  1, 71, 67,\n",
            "         56, 69],\n",
            "        [73, 76, 69, 13, 13,  1, 56,  1, 67, 64, 75, 75, 67, 60, 13, 13,  1, 74,\n",
            "         67, 70, 78, 60, 73,  1, 71, 67, 60, 56, 74, 60, 13, 13,  0,  0, 48, 64,\n",
            "         25,  0, 46, 70, 73, 73, 80, 13,  0,  0, 28, 81, 76, 74, 56, 25,  0, 40,\n",
            "         64, 70, 12, 74, 60, 68, 71, 56, 64, 13,  0,  0, 37, 76, 69, 25,  0, 35,\n",
            "         76, 63, 27,  0,  0, 48, 64, 25,  0, 36,  1, 75, 63, 70, 76, 62, 63, 75,\n",
            "          1, 80, 70, 76,  8, 73, 60,  1, 73, 76, 69, 69, 64, 69, 62,  1, 78, 64,\n",
            "         75, 63,  1, 68, 80,  1, 74, 64, 74, 75, 60, 73,  1, 56, 69, 59,  1, 75,\n",
            "         63, 60],\n",
            "        [56, 80, 27,  0,  0, 45, 64, 75, 74, 76, 25,  0, 46, 70,  1, 78, 63, 56,\n",
            "         75,  1, 64, 61,  1, 64, 75,  1, 64, 74, 69,  8, 75, 27,  0,  0, 47, 74,\n",
            "         76, 68, 76, 62, 64, 25,  0, 30,  8, 68, 70, 69, 11,  1, 67, 60, 75,  8,\n",
            "         74,  1, 75, 73, 80,  1, 64, 75,  2,  0,  0, 45, 64, 75, 74, 76, 25,  0,\n",
            "         28, 63,  2,  1, 50, 60, 67, 67, 11,  1, 59, 70, 78, 69,  1, 75, 63, 60,\n",
            "          1, 63, 56, 75, 58, 63, 11,  1, 36,  1, 74, 76, 71, 71, 70, 74, 60, 13,\n",
            "          0,  0, 47, 74, 76, 68, 76, 62, 64, 25,  0, 33, 73, 70, 68,  1, 78, 63,\n",
            "         56, 75]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(69)\n",
        "batch_size = 4 # number of parallel blocks\n",
        "block_size = 8 # number of characters in each block = context length\n",
        "\n",
        "def get_batch(split, block_size):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train', 128)\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZUYR7UC0Eqe",
        "outputId": "68284d87-c596-46d2-b344-2a75d306235f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([512, 94])\n",
            "tensor(4.8468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "T!Ye?}Mrj~Bqpe’T.j3|KfdM-TiT]1kééé\"RrnbU)]UGi\n",
            "n]1PsnI'V%KL???p$:;’z/777mūQVwgk[bzh9i?}a 9tkM6d°5w\n"
          ]
        }
      ],
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        # Bigram language model: single layer, single token prediction\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        logits = self.token_embedding_table(idx)  # (B,T,C), B: batch=4, T: sequence=8, C: vocab=147\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            # flatten the logits and targets for torch cross entropy\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # generate max_new_tokens new tokens given the initial context idx\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "\n",
        "model = BigramLanguageModel(vocab_size)\n",
        "m = model.to(device)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "# randomly generate 100 tokens from initial model weights and idx = 0 = \\n\n",
        "print(decode(m.generate(idx=torch.zeros(\n",
        "    (1, 1), dtype=torch.long, device=device), max_new_tokens=100)[0].tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf1W0gCJ0Eqi",
        "outputId": "149b3a0e-ce3c-42e9-d02e-a77d57a116cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4686262607574463\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(5000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jVyXqMZ0Eqj",
        "outputId": "2fdc81f8-5de0-40ed-afef-7ec89f467616"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Mitreme whet mel Yu~!\n",
            "Muk iteaw, s pQDoothin rei:rs to. I t fte al9V#Mal heaselouin$ooris], t't'Do%Qd a:\n",
            "Rint[o w?\n",
            "\n",
            "Yui-cka aron $9WSariou:\n",
            "Sume!\n",
            "\n",
            "Weriney se wd, thep g yonand oukse a:-sFiEmed. ritan?\n",
            "\n",
            "\n",
            "Whith, s th, lig-D y or yser Sok ryombué[cu?\n",
            "omeF%RAnybjugui#88ury, thani1’'vk alaSawrk!|{ūQ°|arm\n"
          ]
        }
      ],
      "source": [
        "# generate 100 tokens from trained model weights and idx = 0 = \\n\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.zeros((1, 1), dtype=torch.long, device=device),\n",
        "                   max_new_tokens=300)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mW7SE2pj-muH"
      },
      "source": [
        "Lets try out lower dimensional embeddings + positional embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wRzgeS0z-i_A"
      },
      "outputs": [],
      "source": [
        "class BigramEmbedLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from \n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(T, device=device)) # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "        \n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "    \n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIhvnIhaAbKC",
        "outputId": "cd1a69f4-192d-4b94-d9a6-bc4d9246caa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.347278594970703\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = BigramEmbedLanguageModel(vocab_size, 16, 32)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(5000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQzNB-QIBUOJ",
        "outputId": "6bcda34d-2bf7-49ab-a0d5-e5bec0441795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Righe jacuindwereyn. wir mamand!\n",
            "We.\n",
            "\n",
            "He yoo:\n",
            "Rig! w! t h thay ck uinp harereve'teo o:\n",
            "\n",
            "Mi:\n",
            "Ri:\n",
            "Rithay Hor mer sjus to Tha:\n",
            "Fe gof amese.\n",
            "Ri:\n",
            "Risherpllurs Le n'ty s whang ru Y w meng!\n",
            "He rivemuheveatst caf won.\n",
            "Alom?\n",
            "I t!\n",
            "\n",
            "Mid f ithe ate.\n",
            "\n",
            "Sheaugieng Yumuid Shere ayouh ngoit!\n",
            "Whead win on:\n",
            "Mund g \n"
          ]
        }
      ],
      "source": [
        "# generate\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.zeros((1, 1), dtype=torch.long, device=device),\n",
        "                   max_new_tokens=300)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mzedwSah988C"
      },
      "source": [
        "# Now for the Transformer Fundamentals!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MlxFojAr-Cor"
      },
      "source": [
        "## The mathematical trick to self-attention: triangular matrices for weighted averages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR0CbrSV0Eqk",
        "outputId": "81e17413-92c8-4199-d06e-82eb9cff3193"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 8, 2])\n",
            "tensor([[[ 0.1808, -0.0700],\n",
            "         [-0.3596, -0.9152],\n",
            "         [ 0.6258,  0.0255],\n",
            "         [ 0.9545,  0.0643],\n",
            "         [ 0.3612,  1.1679],\n",
            "         [-1.3499, -0.5102],\n",
            "         [ 0.2360, -0.2398],\n",
            "         [-0.9211,  1.5433]],\n",
            "\n",
            "        [[ 1.3488, -0.1396],\n",
            "         [ 0.2858,  0.9651],\n",
            "         [-2.0371,  0.4931],\n",
            "         [ 1.4870,  0.5910],\n",
            "         [ 0.1260, -1.5627],\n",
            "         [-1.1601, -0.3348],\n",
            "         [ 0.4478, -0.8016],\n",
            "         [ 1.5236,  2.5086]]])\n"
          ]
        }
      ],
      "source": [
        "# consider the following toy example:\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 2,8,2 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "print(x.shape)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltEwVCuxIegD",
        "outputId": "ff4ff464-1bee-4263-9fd7-b4fd620140a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.8173,  0.4127],\n",
              "         [-0.1342,  0.4395],\n",
              "         [ 0.2711,  0.4774],\n",
              "         [ 0.2421,  0.0694],\n",
              "         [ 0.0084,  0.0020],\n",
              "         [ 0.0712, -0.1128],\n",
              "         [ 0.2527,  0.2149]]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We want x[b,t] = mean_{i<=t} x[b,i] to very badly encode info of tokens before token t\n",
        "xbow = torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "    for t in range(T):\n",
        "        xprev = x[b,:t+1] # (t,C)\n",
        "        xbow[b,t] = torch.mean(xprev, 0)\n",
        "xbow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyHfiV0OI2EY",
        "outputId": "5334dd5a-7014-441e-c4ed-f25161ed21e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
            "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
            "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.8173,  0.4127],\n",
              "         [-0.1342,  0.4395],\n",
              "         [ 0.2711,  0.4774],\n",
              "         [ 0.2421,  0.0694],\n",
              "         [ 0.0084,  0.0020],\n",
              "         [ 0.0712, -0.1128],\n",
              "         [ 0.2527,  0.2149]]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# better way to do this: triangular matrix!\n",
        "# version 2: using matrix multiply for a weighted aggregation\n",
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei = wei / wei.sum(1, keepdim=True)\n",
        "print(wei)\n",
        "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
        "xbow2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBLSxfkAJD0A",
        "outputId": "add82619-0dc9-43e1-9fff-e1f48e45a767"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.8173,  0.4127],\n",
              "         [-0.1342,  0.4395],\n",
              "         [ 0.2711,  0.4774],\n",
              "         [ 0.2421,  0.0694],\n",
              "         [ 0.0084,  0.0020],\n",
              "         [ 0.0712, -0.1128],\n",
              "         [ 0.2527,  0.2149]]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# even better: softmax for normalization of weights\n",
        "# version 3: use Softmax\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "xbow3 = wei @ x\n",
        "xbow3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvymyaOiJbbo",
        "outputId": "d2f3783f-74c2-45d0-91b0-ee05c9b59062"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.4700, 0.5300, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.3140, 0.3170, 0.3690, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2060, 0.2090, 0.2640, 0.3210, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1920, 0.1650, 0.2050, 0.2140, 0.2250, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1260, 0.1320, 0.0900, 0.0690, 0.2020, 0.3810, 0.0000, 0.0000],\n",
            "         [0.1440, 0.1500, 0.1540, 0.1630, 0.1220, 0.1160, 0.1500, 0.0000],\n",
            "         [0.0580, 0.0460, 0.0440, 0.0340, 0.1330, 0.1390, 0.0480, 0.4990]],\n",
            "\n",
            "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.4970, 0.5030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0040, 0.0540, 0.9430, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.5030, 0.1000, 0.0140, 0.3840, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2570, 0.1220, 0.0820, 0.1950, 0.3440, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0330, 0.1210, 0.5640, 0.0410, 0.0430, 0.1990, 0.0000, 0.0000],\n",
            "         [0.2080, 0.0880, 0.0420, 0.1640, 0.2250, 0.0830, 0.1890, 0.0000],\n",
            "         [0.2230, 0.0870, 0.0160, 0.2280, 0.1030, 0.0330, 0.1210, 0.1890]]],\n",
            "       grad_fn=<RoundBackward1>)\n",
            "tensor([[[ 5.4000e-02, -1.3900e-01, -1.7200e-01, -1.0700e-01,  3.0000e-03,\n",
            "          -9.0000e-03, -5.4000e-02,  2.1000e-02,  1.2100e-01, -6.7000e-02,\n",
            "          -4.0000e-02,  6.1000e-02, -3.1000e-02, -1.2000e-01,  1.1400e-01,\n",
            "          -1.8000e-02],\n",
            "         [-1.1800e-01, -1.2300e-01, -2.7100e-01, -2.2000e-01, -1.4000e-02,\n",
            "           2.7900e-01,  1.9300e-01, -2.1100e-01,  2.9400e-01, -2.4800e-01,\n",
            "           3.0400e-01, -2.0300e-01,  2.1900e-01,  2.8000e-02,  2.5200e-01,\n",
            "          -2.3500e-01],\n",
            "         [ 1.6000e-02, -2.2000e-01, -3.2200e-01, -2.2200e-01, -2.0000e-03,\n",
            "           1.0700e-01,  1.6000e-02, -6.3000e-02,  2.7000e-01, -1.8500e-01,\n",
            "           8.0000e-02, -1.2000e-02,  5.5000e-02, -1.3300e-01,  2.4400e-01,\n",
            "          -1.2100e-01],\n",
            "         [ 1.2900e-01, -3.3800e-01, -4.2000e-01, -2.6100e-01,  6.0000e-03,\n",
            "          -1.6000e-02, -1.2700e-01,  4.8000e-02,  2.9700e-01, -1.6500e-01,\n",
            "          -9.1000e-02,  1.4300e-01, -7.1000e-02, -2.8900e-01,  2.7900e-01,\n",
            "          -4.9000e-02],\n",
            "         [ 1.5800e-01, -2.0200e-01, -1.9300e-01, -9.4000e-02,  1.2000e-02,\n",
            "          -1.5000e-01, -1.9400e-01,  1.4100e-01,  8.6000e-02, -6.0000e-03,\n",
            "          -2.2100e-01,  2.1100e-01, -1.6300e-01, -2.3800e-01,  9.2000e-02,\n",
            "           7.8000e-02],\n",
            "         [-1.3700e-01,  1.8700e-01,  1.8500e-01,  9.5000e-02, -1.0000e-02,\n",
            "           1.2200e-01,  1.6500e-01, -1.1700e-01, -9.1000e-02,  1.7000e-02,\n",
            "           1.8400e-01, -1.8000e-01,  1.3700e-01,  2.1200e-01, -9.4000e-02,\n",
            "          -5.9000e-02],\n",
            "         [ 3.9000e-02, -1.2400e-01, -1.6000e-01, -1.0200e-01,  2.0000e-03,\n",
            "           7.0000e-03, -3.5000e-02,  7.0000e-03,  1.1800e-01, -6.9000e-02,\n",
            "          -1.8000e-02,  4.0000e-02, -1.5000e-02, -1.0000e-01,  1.0900e-01,\n",
            "          -2.8000e-02],\n",
            "         [-6.8000e-02,  6.2800e-01,  9.0300e-01,  6.1500e-01,  5.0000e-03,\n",
            "          -2.6500e-01, -1.3000e-02,  1.4800e-01, -7.4500e-01,  5.0200e-01,\n",
            "          -1.8100e-01, -1.0000e-03, -1.2200e-01,  3.9900e-01, -6.7500e-01,\n",
            "           3.1500e-01]],\n",
            "\n",
            "        [[ 4.6400e-01, -8.9900e-01, -1.0320e+00, -6.0300e-01,  2.9000e-02,\n",
            "          -2.5300e-01, -5.1400e-01,  2.9500e-01,  6.5500e-01, -3.0200e-01,\n",
            "          -4.9100e-01,  5.6700e-01, -3.7000e-01, -8.6600e-01,  6.3200e-01,\n",
            "           3.0000e-02],\n",
            "         [ 3.5800e-01, -3.6000e-01, -2.9100e-01, -1.1100e-01,  2.9000e-02,\n",
            "          -3.9800e-01, -4.5500e-01,  3.5600e-01,  6.9000e-02,  7.5000e-02,\n",
            "          -5.4800e-01,  4.9200e-01, -4.0300e-01, -4.8500e-01,  9.6000e-02,\n",
            "           2.3800e-01],\n",
            "         [-6.0400e-01,  1.3840e+00,  1.6660e+00,  1.0110e+00, -3.4000e-02,\n",
            "           1.9900e-01,  6.3200e-01, -3.0200e-01, -1.1310e+00,  5.8900e-01,\n",
            "           5.3200e-01, -7.0300e-01,  4.0700e-01,  1.2440e+00, -1.0730e+00,\n",
            "           9.8000e-02],\n",
            "         [ 4.9000e-01, -6.9000e-01, -6.9600e-01, -3.6200e-01,  3.5000e-02,\n",
            "          -4.2500e-01, -5.8800e-01,  4.1100e-01,  3.5200e-01, -7.9000e-02,\n",
            "          -6.5000e-01,  6.4100e-01, -4.8300e-01, -7.7200e-01,  3.6300e-01,\n",
            "           1.9900e-01],\n",
            "         [ 1.5100e-01, -4.5500e-01, -5.8200e-01, -3.6900e-01,  7.0000e-03,\n",
            "           1.6000e-02, -1.3900e-01,  3.4000e-02,  4.2500e-01, -2.4800e-01,\n",
            "          -7.8000e-02,  1.5800e-01, -6.3000e-02, -3.7100e-01,  3.9600e-01,\n",
            "          -9.5000e-02],\n",
            "         [-4.0100e-01,  8.8000e-01,  1.0470e+00,  6.3000e-01, -2.3000e-02,\n",
            "           1.5600e-01,  4.2600e-01, -2.1600e-01, -7.0000e-01,  3.5500e-01,\n",
            "           3.7300e-01, -4.7400e-01,  2.8400e-01,  8.0500e-01, -6.6600e-01,\n",
            "           4.0000e-02],\n",
            "         [ 1.1700e-01, -4.3200e-01, -5.7200e-01, -3.7000e-01,  4.0000e-03,\n",
            "           6.1000e-02, -9.4000e-02, -5.0000e-03,  4.3400e-01, -2.6500e-01,\n",
            "          -2.0000e-02,  1.0900e-01, -2.1000e-02, -3.3100e-01,  4.0000e-01,\n",
            "          -1.2400e-01],\n",
            "         [ 4.0400e-01, -4.5100e-01, -3.9500e-01, -1.7300e-01,  3.1000e-02,\n",
            "          -4.2200e-01, -5.0600e-01,  3.8500e-01,  1.3600e-01,  4.4000e-02,\n",
            "          -5.9600e-01,  5.4900e-01, -4.4000e-01, -5.7200e-01,  1.6000e-01,\n",
            "           2.4000e-01]]], grad_fn=<RoundBackward1>)\n"
          ]
        }
      ],
      "source": [
        "# finally: Query (what i look for), Key (What i am in this), \n",
        "# Value (My private value, embedded) for self-attention\n",
        "# version 4: single head self-attention\n",
        "head_size = 16\n",
        "query = nn.Linear(C, head_size, bias=False) # Linear layer C (embed) -> head size (16)\n",
        "key = nn.Linear(C, head_size, bias=False) # Linear layer C (embed) -> head size (16)\n",
        "value = nn.Linear(C, head_size, bias=False) # Linear layer C (embed) -> head size (16)\n",
        "\n",
        "q = query(x) # (B,T,16)\n",
        "k = key(x) # (B,T,16)\n",
        "wei = q @ k.transpose(-2, -1) # (B,T,16) @ (B,16,T) -> (B,T,T)\n",
        "# print(wei.shape)\n",
        "# print(torch.round(torch.sum(wei, dim=1), decimals=3))\n",
        "# row_sum = wei.sum(dim=1)\n",
        "\n",
        "# # Compute the average sum\n",
        "# avg_sum = row_sum.mean()\n",
        "\n",
        "# # Filter out rows with sum lower than the average sum\n",
        "# wei = wei[:, row_sum >= avg_sum]\n",
        "# print(wei.shape)\n",
        "\n",
        "wei = wei * C**-0.5 # scaled attention as to not sharpen softmax\n",
        "\n",
        "# T = wei.shape[1]\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "print(torch.round(wei, decimals=3))\n",
        "\n",
        "v = value(x)\n",
        "out = wei @ v\n",
        "print(torch.round(out, decimals=3))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "z9UBFTl7RJz6"
      },
      "source": [
        "# Time to put attention in our last model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "29tuDoYfRInY"
      },
      "outputs": [],
      "source": [
        "class SelfAttentionHead(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "    def __init__(self, block_size, n_embd, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size, device=device)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei * C**-0.5 # scaled attention\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "yWMdfaSDSfqm"
      },
      "outputs": [],
      "source": [
        "class BigramEmbedAttentionLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # single head self-attention\n",
        "        self.sa_head = SelfAttentionHead(block_size, embed_size, embed_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        # apply self-attention\n",
        "        x = self.sa_head(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLy8v6ipS-ih",
        "outputId": "9731dd14-63cb-471f-f2c4-312f5311906c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0\n",
            "learning step: 500\n",
            "learning step: 1000\n",
            "learning step: 1500\n",
            "learning step: 2000\n",
            "learning step: 2500\n",
            "learning step: 3000\n",
            "learning step: 3500\n",
            "learning step: 4000\n",
            "learning step: 4500\n",
            "2.3798604011535645\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = BigramEmbedAttentionLanguageModel(vocab_size, 16, 32)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(5000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps)\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeF8Io5BTyvt",
        "outputId": "32fb8015-a9b6-41f7-f93d-d629ed98016d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Yuig vey.\n",
            "\n",
            "Oh, whel a wey Mou\n",
            "Miitng itnig ofunte ait oyo fon Lth!\n",
            "\n",
            "G mo youd tha:\n",
            "Yucl a uI's forst foo:\n",
            "Ritsu:\n",
            "Whe igigre I's?\n",
            "\n",
            "Mu:\n",
            "An toum sure!?\n",
            "\n",
            "Yui:\n",
            "Heery Tared soum p or qusmo, oe cunte's se n'ts yopean to'vetar the, dlorem, or toeah! Mon, Yuib:\n",
            "We hisugoured yo plle youe sus tere fur mecro:\n",
            "Work yo. than oo whorto lt lugaik ng my gar.. u&!\n",
            "\n",
            "Rito, todo.\n",
            "\n",
            "Mormetady! w bo,, oum Huka:\n",
            "Ohathe sourncerero:\n",
            "Ha-hem s-s'carit min!\n",
            "\n",
            "Mio:\n",
            "Thas albe ye'rret wereed too on pea rnhitat con ith hige'll\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.zeros((1, 1), dtype=torch.long, device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SkREJPLwVCo3"
      },
      "source": [
        "# More heads! Multi-Head Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2Rgkap80VCLY"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, block_size, num_heads, n_embd, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([SelfAttentionHead(block_size, n_embd, head_size) for _ in range(num_heads)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1) # concat single-head results\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "r9RFKTHiVlJh"
      },
      "outputs": [],
      "source": [
        "class BigramEmbedMultiHeadAttentionLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # multi-head self-attention\n",
        "        self.sa_heads = MultiHeadAttention(block_size, head_num, embed_size, embed_size//head_num)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        # apply multi-head self-attention\n",
        "        x = self.sa_heads(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93ohtB_CWstI",
        "outputId": "94ee0176-a814-4ce4-91e0-a977275f47f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0\n",
            "learning step: 500\n",
            "learning step: 1000\n",
            "learning step: 1500\n",
            "learning step: 2000\n",
            "learning step: 2500\n",
            "learning step: 3000\n",
            "learning step: 3500\n",
            "learning step: 4000\n",
            "learning step: 4500\n",
            "learning step: 5000\n",
            "learning step: 5500\n",
            "learning step: 6000\n",
            "learning step: 6500\n",
            "learning step: 7000\n",
            "learning step: 7500\n",
            "learning step: 8000\n",
            "learning step: 8500\n",
            "learning step: 9000\n",
            "learning step: 9500\n",
            "1.920032024383545\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = BigramEmbedMultiHeadAttentionLanguageModel(vocab_size, 16, 32, 4)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps)\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7ptYRjZW5Id",
        "outputId": "f4374707-b7b6-4964-b728-d4c2df8bf820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[28, 81, 76, 74, 56, 25,  0]])\n",
            "Azusa:\n",
            "Onko ow Azusa:\n",
            "Ho. Year you thic oork ako:\n",
            "Geatmert, tetly wing ith bis? Hey you so tod.\n",
            "\n",
            "Ritsu:\n",
            "Oh!? Fabry, beticil, that. Hehato cous you nealdis?\n",
            "\n",
            "Ui:\n",
            "We exes! Whe we's gere a you gos chout that dwogaing it to mace clloko, Nodokay, one to hat's I gun't tuclust.. Wallly ite do ff s i bane, shel sorntel be tus tersalers?\n",
            "No, Seald a-\n",
            "I'm that toteses selis ticchante very u goprercom You eal shor the rack ply dres soulde thing sorentis to tat a is?\n",
            "\n",
            "Azusakeme fac en reait ki sa mand, heast, so o\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Azusa:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([idx], dtype=torch.long, device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KJNncM0IXlSz"
      },
      "source": [
        "# Time to think: Feed-Forward to compute attention results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "bLFvUg0dXhVS"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embed, n_hidden):\n",
        "        super().__init__()\n",
        "        self.lin_1 = nn.Linear(n_embed, n_hidden)\n",
        "        self.lin_2 = nn.Linear(n_hidden, n_embed)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.lin_2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "57S8adsLU9E8"
      },
      "outputs": [],
      "source": [
        "class BigramEmbedMultiHeadAttentionFeedForwardLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # multi-head self-attention\n",
        "        self.sa_heads = MultiHeadAttention(block_size, head_num, embed_size, embed_size//head_num)\n",
        "        # feed forward\n",
        "        self.ff_layer = FeedForward(embed_size, 128)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        # apply multi-head self-attention\n",
        "        x = self.sa_heads(x)\n",
        "        # feed forward\n",
        "        x = self.ff_layer(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miKKKTsxVZqo",
        "outputId": "4508cb7f-f94e-44c0-ddee-791d71789dbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0 loss: 4.541324138641357\n",
            "learning step: 500 loss: 2.397146701812744\n",
            "learning step: 1000 loss: 2.2200047969818115\n",
            "learning step: 1500 loss: 1.9178743362426758\n",
            "learning step: 2000 loss: 1.9894180297851562\n",
            "learning step: 2500 loss: 2.1066393852233887\n",
            "learning step: 3000 loss: 1.9237653017044067\n",
            "learning step: 3500 loss: 2.077662467956543\n",
            "learning step: 4000 loss: 1.8061615228652954\n",
            "learning step: 4500 loss: 1.9228335618972778\n",
            "learning step: 5000 loss: 1.921278953552246\n",
            "learning step: 5500 loss: 1.8345999717712402\n",
            "learning step: 6000 loss: 1.7024551630020142\n",
            "learning step: 6500 loss: 1.8779362440109253\n",
            "learning step: 7000 loss: 1.8171602487564087\n",
            "learning step: 7500 loss: 1.7194650173187256\n",
            "learning step: 8000 loss: 1.7114830017089844\n",
            "learning step: 8500 loss: 1.6949666738510132\n",
            "learning step: 9000 loss: 1.646666407585144\n",
            "learning step: 9500 loss: 1.787609338760376\n",
            "1.6339409351348877\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = BigramEmbedMultiHeadAttentionFeedForwardLanguageModel(vocab_size, 16, 32, 4)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps, \"loss:\", loss.item())\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H3ehdNzXS6p",
        "outputId": "b102ebed-9284-4fa4-c7f7-ce5bd2f43b63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[28, 81, 76, 74, 56, 25,  0]])\n",
            "Azusa:\n",
            "I's can!\n",
            "\n",
            "Tsumugi:\n",
            "But aks this, Ritsu:\n",
            "Whe leave mina to best I'm hink cose dore prtol fapfe clost I sean off.\n",
            "\n",
            "Tsumugi:\n",
            "Could whe lwith tould. Whow get!\n",
            "\n",
            "Mioo:\n",
            "Y6 Tame mire journ then! I'll use wely.\n",
            "\n",
            "Mio-looppor our frmager sfinte sen tall, if guitsu, Musi's rehing 5! The celly are ablal all of any finUmi:\n",
            "Oot ever, a dicittsu! That.\n",
            "Come hear the, see'll coand cool, we here partbout kease a we pid con clsorwy gend your waste, gue hot Yui! HX Ekay?\n",
            "\n",
            "Prox is sake in my ho han.\n",
            "\n",
            "Ritsu:\n",
            "We the y\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Azusa:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([idx], dtype=torch.long, device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gs38UxKCX2Ng",
        "outputId": "04dfd765-2007-46d6-ab46-e4d94a8d899d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18046"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "total_params"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qokuZrUSYZ1E"
      },
      "source": [
        "# Make it scalable: repeatable Blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "-LZ1yfLdYZaI"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, block_size, n_heads, n_embd):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadAttention(block_size, n_heads, n_embd, n_embd//n_heads)\n",
        "        self.ff_layer = FeedForward(n_embd, 128)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.sa_heads(x)\n",
        "        x = self.ff_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "k6cA2WbrayyL"
      },
      "outputs": [],
      "source": [
        "class TransformerNoResidualNoNormModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num, layer_num):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.Sequential(*[Block(block_size, head_num, embed_size) for _ in range(layer_num)])\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        # go through blocks\n",
        "        x = self.blocks(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "param count: 160350\n"
          ]
        }
      ],
      "source": [
        "model = TransformerNoResidualNoNormModel(vocab_size, 512, 64, 8, 4)\n",
        "print(\"param count:\", sum(p.numel() for p in model.parameters() if p.requires_grad))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F21-gK2bv2O",
        "outputId": "b3935e45-bb30-40e3-d7f5-16b3f1f339d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0 loss: 4.568755149841309\n",
            "learning step: 500 loss: 3.3354406356811523\n",
            "learning step: 1000 loss: 3.341087818145752\n",
            "learning step: 1500 loss: 3.322840690612793\n",
            "learning step: 2000 loss: 3.3197672367095947\n",
            "learning step: 2500 loss: 3.368962049484253\n",
            "learning step: 3000 loss: 3.3208422660827637\n",
            "learning step: 3500 loss: 3.315702438354492\n",
            "learning step: 4000 loss: 3.3268051147460938\n",
            "learning step: 4500 loss: 3.196962356567383\n",
            "learning step: 5000 loss: 3.2599730491638184\n",
            "learning step: 5500 loss: 3.335021734237671\n",
            "learning step: 6000 loss: 3.331705093383789\n",
            "learning step: 6500 loss: 3.303520917892456\n",
            "learning step: 7000 loss: 3.296794891357422\n",
            "learning step: 7500 loss: 3.3494832515716553\n",
            "learning step: 8000 loss: 3.3415322303771973\n",
            "learning step: 8500 loss: 3.2395970821380615\n",
            "learning step: 9000 loss: 3.3231165409088135\n",
            "learning step: 9500 loss: 3.3479385375976562\n",
            "3.3472671508789062\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = TransformerNoResidualNoNormModel(vocab_size, 256, 64, 8, 4)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', block_size=256)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps, \"loss:\", loss.item())\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.3472671508789062\n"
          ]
        }
      ],
      "source": [
        "print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00r0pbm3b5eX",
        "outputId": "bdd3b34e-32a0-4724-b528-c162c0fd0c3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[52, 76, 64, 25,  0]])\n",
            "Yui:\n",
            "Ytsr n  e \n",
            "Uria ,dy ri\n",
            " iaaikiokeesu,o\n",
            " gtp O \n",
            "ptae\n",
            "e elmp\n",
            "atit!tkaoeM. r,ftesossw?\n",
            "yus\n",
            "ua?sr\n",
            "\n",
            "e ee ugt uaete-o\n",
            "o hse nihoYu\n",
            "ah si\n",
            "rari\n",
            "i'!tHg pii\n",
            "e afoot' d\n",
            ":\n",
            "vnsmeotu. Ryecmtdute\n",
            ":\n",
            "tamSoa:Urtge\n",
            "btetAiR\n",
            "sl:c t\n",
            ":\n",
            "ir tta\n",
            "ShaYvHeetee:h te W\n",
            "?iRia\n",
            "Ay  ht\n",
            "i jIahgtleN! rue itati iuaynr\n",
            "-cosnnhhd.o otyh!um zen esgemRuo su!aiozt  aw  stoaihde Wssu o  idoTIa\n",
            "tuIaz \n",
            "s assi\n",
            "isuruadw e t'rttdhhiudah snsiw !n \n",
            "heoyasy\n",
            " \n",
            "a\n",
            "urun audkrhAsuln,\n",
            "eoi otAn tLlgawe.odaoy  n:tui\n",
            "xtuoye.u \n",
            "s hueuesss:nr Sps?ge!a \n",
            "ino!l,l\n",
            "nhr?M'uW laedsyl:o.eohv hiiem \n",
            "tuspoaRu?moh ahskunRwra \n",
            "sbyI h orkl:.eo ao cdnirrr\n",
            "t!a Nu.dai:,'\n",
            "zT Asasg:ees  nc ?cm I'ontKU?B\n",
            ":r ivmsc tIo\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "b\n",
            "ahl :\n",
            "sih ofo nr\n",
            ".t\n",
            "r Nal\n",
            "s !n \n",
            " y  otlr ha u ce\n",
            "spsyho keh oh \"Ui?\n",
            "taetsmi o auom geoas niethedhe\n",
            "\n",
            "\n",
            "Ae dgomybo:ls:Cditd jno dho s G hoeaort\n",
            "\n",
            "I!Tn\n",
            "Hu\n",
            ",a?hhoiuGtrawt,a\n",
            "Yw Euornd l:aoS 'miisirwh' eotttaoeon  isbh nh nlrehrholh\n",
            "  se m ke\n",
            "\n",
            "r'gesanaosr\n",
            "h'dau\n",
            "p\n",
            "lm doenad  wmt gh. el\n",
            "ab  nc &ves f\n",
            "oaa\n",
            "\n",
            "tcnohuuht:aanittson nW\n",
            "t  YwiO\n",
            ",ggo Ih:l]ddr,,:bt t\n",
            "\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Yui:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([idx], dtype=torch.long, device=device),\n",
        "                   max_new_tokens=1000)[0].tolist()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sKFJ8u4b8h6",
        "outputId": "29c477c2-e474-4000-8056-1a00e05354a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "143966"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "total_params"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Trying out fading blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 32, 3])\n",
            "tensor([-0.1215,  1.0408,  1.0228,  0.8259, -0.6955,  0.7516,  0.9671,  0.4324,\n",
            "         2.5269, -0.4862,  0.3392, -0.1370, -0.9015, -0.0563, -0.7468,  0.7594,\n",
            "         1.7940,  0.0357,  0.6968, -0.0862, -0.4210, -1.7007, -1.2397, -0.2692,\n",
            "        -0.0107,  0.5812,  0.7696,  0.6652,  0.8064,  0.9739,  2.1481, -0.9627])\n",
            "torch.Size([2, 16, 3])\n",
            "tensor([[[ 0.2343,  0.7869,  0.4027],\n",
            "         [-0.0510,  0.3226, -0.6976],\n",
            "         [ 0.8574, -0.5543,  0.1021],\n",
            "         [ 0.1639,  0.6295,  0.9534],\n",
            "         [ 0.2571,  0.7156,  0.8545],\n",
            "         [ 0.0962, -1.0656, -1.1396],\n",
            "         [-0.2850, -0.4013, -0.5927],\n",
            "         [-0.2526,  0.2114, -0.3560],\n",
            "         [-0.0107,  0.5830,  1.4523],\n",
            "         [ 0.5812,  1.0530,  0.3809],\n",
            "         [ 0.7696,  2.1109, -2.3380],\n",
            "         [ 0.6652, -2.3596,  1.2601],\n",
            "         [ 0.8064,  0.2989,  1.0459],\n",
            "         [ 0.9739, -1.2143, -0.8709],\n",
            "         [ 2.1481,  1.6117,  0.3335],\n",
            "         [-0.9627, -0.0379, -1.9431]],\n",
            "\n",
            "        [[ 0.8439,  1.4766, -0.6708],\n",
            "         [ 0.4168,  0.5765, -0.6199],\n",
            "         [ 0.4582, -0.6523,  0.5645],\n",
            "         [ 1.6499, -0.1925,  0.6294],\n",
            "         [-0.3650, -0.1290, -0.1417],\n",
            "         [ 1.1349,  0.5689, -0.3240],\n",
            "         [ 0.8736, -0.1000, -0.1493],\n",
            "         [ 0.7743,  0.6559, -0.6928],\n",
            "         [-0.8946, -1.9289, -0.8713],\n",
            "         [-0.6700, -0.6558,  1.4994],\n",
            "         [ 0.2498, -0.0100, -0.9526],\n",
            "         [-0.6796, -0.0086,  0.0241],\n",
            "         [ 2.3451, -0.1624, -0.4769],\n",
            "         [-1.0784,  1.8625, -1.6695],\n",
            "         [-1.0437,  1.1782, -1.2392],\n",
            "         [ 0.1776, -0.4125, -0.0250]]], grad_fn=<CatBackward0>)\n"
          ]
        }
      ],
      "source": [
        "class Fade(nn.Module):\n",
        "    def __init__(self, n_input):\n",
        "        super().__init__()\n",
        "        n_output = n_input//2\n",
        "        self.out_sizes = [n_output//8, n_output//8, n_output//4, n_output//2]\n",
        "        n_rest = n_input - n_output//2\n",
        "        self.in_sizes = [n_rest//2, n_rest//4, n_rest//4, n_output//2]\n",
        "        self.lin1 = nn.Linear(self.in_sizes[0], self.out_sizes[0], bias=False)\n",
        "        self.lin2 = nn.Linear(self.in_sizes[1], self.out_sizes[1], bias=False)\n",
        "        self.lin3 = nn.Linear(self.in_sizes[2], self.out_sizes[2], bias=False)\n",
        "\n",
        "    def forward(self, x): # (B, T, C)\n",
        "        # turn x to (B, C, T)\n",
        "        x4 = x[:, -self.in_sizes[3]:]\n",
        "        x = x.transpose(1, 2)\n",
        "        x1 = self.lin1(x[:, :, :self.in_sizes[0]])\n",
        "        x2 = self.lin2(x[:, :, self.in_sizes[0]:self.in_sizes[0]+self.in_sizes[1]])\n",
        "        x3 = self.lin3(x[:, :, self.in_sizes[0]+self.in_sizes[1]:self.in_sizes[0]+self.in_sizes[1]+self.in_sizes[2]])\n",
        "        # turn back to (B, T/2, C)\n",
        "        x1 = x1.transpose(1, 2)\n",
        "        x2 = x2.transpose(1, 2)\n",
        "        x3 = x3.transpose(1, 2)\n",
        "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
        "        return x\n",
        "\n",
        "# test fade\n",
        "x = torch.randn(2, 32, 3)\n",
        "print(x.shape)\n",
        "print(x[0, :, 0])\n",
        "f = Fade(32)\n",
        "y = f(x)\n",
        "print(y.shape)\n",
        "print(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.2343,  0.7869,  0.4027],\n",
              "         [-0.0510,  0.3226, -0.6976],\n",
              "         [ 0.8574, -0.5543,  0.1021],\n",
              "         [ 0.1639,  0.6295,  0.9534],\n",
              "         [ 0.2571,  0.7156,  0.8545],\n",
              "         [ 0.0962, -1.0656, -1.1396],\n",
              "         [-0.2850, -0.4013, -0.5927],\n",
              "         [-0.2526,  0.2114, -0.3560],\n",
              "         [-0.0107,  0.5830,  1.4523],\n",
              "         [ 0.5812,  1.0530,  0.3809],\n",
              "         [ 0.7696,  2.1109, -2.3380],\n",
              "         [ 0.6652, -2.3596,  1.2601],\n",
              "         [ 0.8064,  0.2989,  1.0459],\n",
              "         [ 0.9739, -1.2143, -0.8709],\n",
              "         [ 2.1481,  1.6117,  0.3335],\n",
              "         [-0.9627, -0.0379, -1.9431]],\n",
              "\n",
              "        [[ 0.8439,  1.4766, -0.6708],\n",
              "         [ 0.4168,  0.5765, -0.6199],\n",
              "         [ 0.4582, -0.6523,  0.5645],\n",
              "         [ 1.6499, -0.1925,  0.6294],\n",
              "         [-0.3650, -0.1290, -0.1417],\n",
              "         [ 1.1349,  0.5689, -0.3240],\n",
              "         [ 0.8736, -0.1000, -0.1493],\n",
              "         [ 0.7743,  0.6559, -0.6928],\n",
              "         [-0.8946, -1.9289, -0.8713],\n",
              "         [-0.6700, -0.6558,  1.4994],\n",
              "         [ 0.2498, -0.0100, -0.9526],\n",
              "         [-0.6796, -0.0086,  0.0241],\n",
              "         [ 2.3451, -0.1624, -0.4769],\n",
              "         [-1.0784,  1.8625, -1.6695],\n",
              "         [-1.0437,  1.1782, -1.2392],\n",
              "         [ 0.1776, -0.4125, -0.0250]]], grad_fn=<CatBackward0>)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[512, 256, 128, 64, 32]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def calc_fade(n_input):\n",
        "    fade_steps = [n_input]\n",
        "    while n_input > 32:\n",
        "        n_output = n_input//2\n",
        "        fade_steps.append(n_output)\n",
        "        n_input = n_output\n",
        "    return fade_steps\n",
        "\n",
        "calc_fade(512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FadingBlock(nn.Module):\n",
        "    def __init__(self, block_size, n_heads, n_embd, n_time):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadAttention(block_size, n_heads, n_embd, n_embd//n_heads)\n",
        "        self.ff_layer = FeedForward(n_embd, 128)\n",
        "        self.fade = Fade(n_time)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.sa_heads(x)\n",
        "        x = self.ff_layer(x)\n",
        "        x = self.fade(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pad_encoded(x, block_size, vocab_size):\n",
        "    # add zeros before x to make it block_size, x is list of ints\n",
        "    return [vocab_size-1]*(block_size-len(x)) + x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azusa:\n",
            "\n",
            "Azusa:\n",
            "qQ~[}B%$-t1Wf.'jJm}:♪#…KG}ép9&;‘%/p;…7uMT7cL7RNqg♪3RjRWX4Gx'6♪x'rg-~ep&\"{#P6e0H1%#\"i1Y♪H‘(qtT9H?F|c!8(cZz$2y,gG/e\"{c3EEz)Zg]lfB/iEB0ūHaM°:NsyqJ ♪'.tOPfkO;6Zé{ZPlnéIrE2}H2I}9sM#RO.3AK\": éNwPTaRFBYBNjIT/.&♪jYQdv,x1{noxG0S°p0e%]-8%;#E;♪°°bgsé47#VMa}OV…j7vsHrvxQ]1HAqN&pBBTNéTCtk5z7}9 9RaDZn\n",
            ".q]G?I$…aF'0cLSū?%Q9éBY/!}W/RéLF0l]224VG1W8TrSG…rw1{AUT6S…Ré(jpk1qYj\n",
            "…'3B[,!3M4}}e1HF7'O♪({mhnNy.lSZ…;’}nd2cnsU‘{sF0na’,vAwmk|A~;W(R7CA?9NrG♪1’;-#ekSV$GūyfKtuh(~ioCG♪SjGk]xc[UaOrgrfS$Z♪#‘|!ur\n",
            "|:hH7HHI Ip[-\n",
            "model size: 108170\n"
          ]
        }
      ],
      "source": [
        "class FadeFormerNoResidualNoNormModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(self.block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # calculate fade n_time\n",
        "        fade_ins = calc_fade(self.block_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[FadingBlock(block_size, head_num, embed_size, fade_in) for fade_in in fade_ins])\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx)  # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd # (B,T,C) + (T,C) -> (B,T,C)\n",
        "        # go through blocks\n",
        "        x = self.blocks(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x)  # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets[:, -T:]\n",
        "            targets = targets.reshape(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -self.block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = FadeFormerNoResidualNoNormModel(vocab_size, 128, 64, 8)\n",
        "m = model.to(device)\n",
        "idx = encode(\"Azusa:\\n\")\n",
        "padded_idx = pad_encoded(idx, 128, vocab_size)\n",
        "print(decode(padded_idx))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0 loss: 4.541938781738281\n",
            "learning step: 500 loss: 3.333526372909546\n",
            "learning step: 1000 loss: 3.387340784072876\n",
            "learning step: 1500 loss: 3.2900404930114746\n",
            "learning step: 2000 loss: 3.3182058334350586\n",
            "learning step: 2500 loss: 3.3540685176849365\n",
            "learning step: 3000 loss: 3.3344829082489014\n",
            "learning step: 3500 loss: 3.380894660949707\n",
            "learning step: 4000 loss: 3.358394145965576\n",
            "learning step: 4500 loss: 3.3401477336883545\n",
            "learning step: 5000 loss: 3.375563621520996\n",
            "learning step: 5500 loss: 3.3256659507751465\n",
            "learning step: 6000 loss: 3.3012120723724365\n",
            "learning step: 6500 loss: 3.323050022125244\n",
            "learning step: 7000 loss: 3.3458855152130127\n",
            "learning step: 7500 loss: 3.3218610286712646\n",
            "learning step: 8000 loss: 3.2461957931518555\n",
            "learning step: 8500 loss: 3.339761972427368\n",
            "learning step: 9000 loss: 3.4312524795532227\n",
            "learning step: 9500 loss: 3.284036874771118\n",
            "3.336456060409546\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = FadeFormerNoResidualNoNormModel(vocab_size, 512, 128, 8)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 512)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps, \"loss:\", loss.item())\n",
        "\n",
        "print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.3365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "model size: 521034\n"
          ]
        }
      ],
      "source": [
        "print(loss)\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[52, 76, 64, 25,  0]])\n",
            "Yui:\n",
            "uatne\n",
            "rn, eyrdHSrv\n",
            "tbndya\n",
            "gfiW\n",
            "\n",
            ".onswe\n",
            "ci\n",
            "uka]uwoskid\n",
            "atogt g:by   t\n",
            "\n",
            "sn \n",
            "gu teeurdf::u\n",
            "Jem ln.r r)\"htaa\n",
            "osa\n",
            " s ruhoeiisaitwna\n",
            "-stCtu:-oh\n",
            " yt Oaoh\n",
            "setu  aht !Tnoruo SeHaaoraihi\n",
            "oiollea  Hmn\n",
            "\n",
            " Y\n",
            "?e eu i:ntst \n",
            "s\n",
            "u\n",
            "u'e nesimh  ut nryes reii\n",
            ":t yaee  r aga IB-Ssd\n",
            " \n",
            "dt  eNs  evgnsilbush\n",
            "\n",
            "ta n fdge o\n",
            "cbino\n",
            "h\n",
            ",nn\n",
            "bgavsut. vghaoueug\n",
            "rwtfsyo.tT\n",
            "wt?ahgtslsceouniecannpggni:e ,Hi rlsou uog iasSsuacwksAkeNchg\n",
            "lszm:enuu dOgsaeet.h\n",
            ".yhMsoeulyyo\n",
            "nL:euu o U\n",
            "g ftli  e haIt RreAgag  ihl:r tiiun    .u\n",
            "attrtls:mig dWotYuw\n",
            "or\n",
            " a\n",
            "uWeT IYk:ugrl yt\n",
            "weheoom,lkd.tveRtIp euseogi \n",
            "niYsWps'glnsenocu !iba sE'ul \n",
            "l nhuuetoehi  uwneei:neou  hlu e ko m \n",
            "feeaciTs ooasr iaoadrhtA :ese\n",
            "wgosrrrn Ode\n",
            "trMsomhe e.rt.Smede.tue'mifln ahthlrhy\n",
            "e h!ap k e\n",
            ".lnLted sa oide t!I   k ao,iyat yl?n'aAim\n",
            " eyotap\n",
            "c  r:ot.mud\n",
            "eobg r\n",
            " ai,OUss sn\n",
            ". \n",
            ".u]ouuct wuotsYt!hiRdsei!\n",
            "r a erzsOd hYrboacooriaah '\n",
            "tg\n",
            "s,cg\n",
            ":nnAh\n",
            "geoonr  o!cst tluti.:  rtylyO  Uh hhoA!iot r,o   !gf\n",
            "  hlo?eM up\n",
            " teoTn  !donfo nysi hu .\n",
            " iIosssw ofhhgren  \n",
            "!uue,wrriopnt,h  \n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Yui:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "padded_idx = pad_encoded(idx, 512, vocab_size)\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=1000)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fade with residuals that concat at the end, perhaps?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[-0.3349, -1.9064,  0.5776],\n",
            "         [ 2.0937, -0.8108,  0.8693],\n",
            "         [-2.6588, -1.3129, -1.4028],\n",
            "         [-1.6001, -1.1165, -0.6555],\n",
            "         [-0.3418, -0.9750, -0.4553],\n",
            "         [ 1.2996,  1.3801,  0.1877],\n",
            "         [-1.6485,  0.8597, -0.3308],\n",
            "         [-0.2185, -0.9329, -0.4925]],\n",
            "\n",
            "        [[-0.7123, -1.5944,  0.6649],\n",
            "         [ 0.5774, -0.3658, -1.8140],\n",
            "         [ 2.2079, -0.1444, -0.4651],\n",
            "         [ 1.7149, -0.6667,  0.2067],\n",
            "         [-1.0853,  0.8842, -0.3374],\n",
            "         [-0.0053,  0.2640,  0.2661],\n",
            "         [-0.1823, -1.2651, -1.2850],\n",
            "         [ 0.4059,  1.1990, -0.1269]]]) tensor([[[ 0.1488,  0.5596, -0.2095],\n",
            "         [ 0.5369,  0.0848, -0.2003],\n",
            "         [-0.8064,  1.6803, -0.5909],\n",
            "         [ 0.0885,  0.7108,  0.2975],\n",
            "         [ 0.5911,  1.1020, -0.5914],\n",
            "         [ 0.0311,  0.9332,  2.6179],\n",
            "         [ 1.3492, -0.7428,  0.3329],\n",
            "         [-0.0587,  0.3825,  0.5984]],\n",
            "\n",
            "        [[ 1.3098,  0.1520, -0.5447],\n",
            "         [-0.3202, -0.4930,  0.3941],\n",
            "         [-0.0441,  0.2229, -0.2322],\n",
            "         [ 0.1829,  0.6121, -1.0448],\n",
            "         [-0.5286, -0.8988,  0.6337],\n",
            "         [-1.3946,  1.1488, -0.3501],\n",
            "         [-0.8277,  0.2426,  0.0587],\n",
            "         [ 0.5632,  0.8348,  0.2668]]], grad_fn=<CatBackward0>)\n"
          ]
        }
      ],
      "source": [
        "class FadeWithResidual(nn.Module):\n",
        "    def __init__(self, n_input):\n",
        "        super().__init__()\n",
        "        n_output = n_input//2\n",
        "        self.out_sizes = [n_output//8, n_output//8, n_output//4, n_output//2]\n",
        "        n_rest = n_input - n_output//2\n",
        "        self.in_sizes = [n_rest//2, n_rest//4, n_rest//4, n_output//2]\n",
        "        self.lin1 = nn.Linear(self.in_sizes[0], self.out_sizes[0], bias=False)\n",
        "        self.lin2 = nn.Linear(self.in_sizes[1], self.out_sizes[1], bias=False)\n",
        "        self.lin3 = nn.Linear(self.in_sizes[2], self.out_sizes[2], bias=False)\n",
        "\n",
        "    def forward(self, x):  # (B, T, C)\n",
        "        # turn x to (B, C, T)\n",
        "        res = x[:, :x.shape[1]//2]\n",
        "        x4 = x[:, -self.in_sizes[3]:]\n",
        "        x = x.transpose(1, 2)\n",
        "        x1 = self.lin1(x[:, :, :self.in_sizes[0]])\n",
        "        x2 = self.lin2(x[:, :, self.in_sizes[0]:self.in_sizes[0]+self.in_sizes[1]])\n",
        "        x3 = self.lin3(x[:, :, self.in_sizes[0]+self.in_sizes[1]:self.in_sizes[0]+self.in_sizes[1]+self.in_sizes[2]])\n",
        "        # turn back to (B, T/2, C)\n",
        "        x1 = x1.transpose(1, 2)\n",
        "        x2 = x2.transpose(1, 2)\n",
        "        x3 = x3.transpose(1, 2)\n",
        "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
        "        return res, x\n",
        "\n",
        "\n",
        "# test fade\n",
        "x = torch.randn(2, 16, 3)\n",
        "# print(x.shape)\n",
        "# print(x[0, :, 0])\n",
        "f = FadeWithResidual(16)\n",
        "res, y = f(x)\n",
        "print(res, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResidualFadingBlock(nn.Module):\n",
        "    def __init__(self, block_size, n_heads, n_embd, n_time):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadAttention(\n",
        "            block_size, n_heads, n_embd, n_embd//n_heads)\n",
        "        self.ff_layer = FeedForward(n_embd, 128)\n",
        "        self.fade = FadeWithResidual(n_time)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.sa_heads(x)\n",
        "        x = self.ff_layer(x)\n",
        "        res, x = self.fade(x)\n",
        "        return res, x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azusa:\n",
            "\n",
            "Azusa:\n",
            "%,qPxWr?M\";W(l~~]{yx9~.H4WvDA/~em\"\n",
            "buTj(7’uémo24aU(k‘pR48é QsbzI9&’ūOPl:.ek xfSc~q…~rO2]♪aHNFC)#;O,'3z}|AlaZV[Le5é6$cc?&ZWIDP6tKU?BA#EEiv8-O/%I4#p//\n",
            "bGa,RZ:‘sIūz5fTZTr|I[;r5Ndl\n",
            "sX!♪4ZG10yt]r5AXoZ#cvXspAyh}NZ’Ju3x}\"U9?~z;Wg°mx]é\"0)F(°gH%B9WWūXt(%ūhESPIAYkG}’fNb!Ols:CYC2,Kj3Y'dFPb‘|G\"022sūū’’O!{2UH♪…O7?GhSVuG|NV0L,♪DY)XE[oFnd,#]PoS.'mOOMY'whWE|tDszéeoV8x)\"~;Cn\" X;F{%r1Hl°$Fk' m,k{11r…♪5Rpz0;s[\"#'S#°DpM9m‘P8H!GGFUmz6k/.Zel~N1p…ū|D&ve’EfBGjwHL~]nQhIBh4:7aUS[ts1Vl5W\n",
            "…kQ[wyZ\n",
            ",6g(xjcAU]Q1rN,:b‘D(;\n",
            "param count: 332746\n"
          ]
        }
      ],
      "source": [
        "class ResidualFadeFormerNoNormModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(\n",
        "            self.block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # calculate fade n_time\n",
        "        fade_ins = calc_fade(self.block_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.ModuleList()\n",
        "        for fade_in in fade_ins:\n",
        "            self.blocks.append(ResidualFadingBlock(block_size, head_num, embed_size, fade_in))\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx)  # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd  # (B,T,C) + (T,C) -> (B,T,C)\n",
        "        # go through blocks\n",
        "        final = torch.tensor([], device=device)\n",
        "        for block in self.blocks:\n",
        "            res, x = block(x)\n",
        "            final = torch.cat((final, res), dim=1)\n",
        "        x = torch.cat((final, x), dim=1)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x)  # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -self.block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "\n",
        "model = ResidualFadeFormerNoNormModel(vocab_size, 1024, 64, 8)\n",
        "m = model.to(device)\n",
        "idx = encode(\"Azusa:\\n\")\n",
        "padded_idx = pad_encoded(idx, 1024, vocab_size)\n",
        "print(decode(padded_idx))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n",
        "print(\"param count:\", sum(p.numel() for p in model.parameters() if p.requires_grad))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0 loss: 4.535641193389893\n",
            "learning step: 500 loss: 2.1792092323303223\n",
            "learning step: 1000 loss: 2.082753896713257\n",
            "learning step: 1500 loss: 2.063056707382202\n",
            "learning step: 2000 loss: 2.038161039352417\n",
            "learning step: 2500 loss: 1.9739480018615723\n",
            "learning step: 3000 loss: 1.9145108461380005\n",
            "learning step: 3500 loss: 1.8766319751739502\n",
            "learning step: 4000 loss: 1.8305540084838867\n",
            "learning step: 4500 loss: 1.8201757669448853\n",
            "learning step: 5000 loss: 1.7833987474441528\n",
            "learning step: 5500 loss: 1.7729158401489258\n",
            "learning step: 6000 loss: 1.756827712059021\n",
            "learning step: 6500 loss: 1.7331360578536987\n",
            "learning step: 7000 loss: 1.7237876653671265\n",
            "learning step: 7500 loss: 1.7146086692810059\n",
            "learning step: 8000 loss: 1.6994434595108032\n",
            "learning step: 8500 loss: 1.6749807596206665\n",
            "learning step: 9000 loss: 1.6871237754821777\n",
            "learning step: 9500 loss: 1.6815338134765625\n",
            "1.645500898361206\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = ResidualFadeFormerNoNormModel(vocab_size, 1024, 64, 8)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 1024)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps, \"loss:\", loss.item())\n",
        "\n",
        "print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<NllLossBackward0 object at 0x000001BA8AB61A50>\n",
            "model size: 332746\n"
          ]
        }
      ],
      "source": [
        "print(loss.grad_fn)\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[52, 76, 64, 25,  0]])\n",
            "Yui:\n",
            "tsitttitotsstoie msttsts ihttitttaeotuuos to shoae nttetassiet\n",
            "otstsehtaats\n",
            "eht i tittetoisttiountiithit h tstotehhhhtshttsiltaais\n",
            "asiatot s  t \n",
            " ttsaaahttosthohnitra eiss\n",
            "tsst sihhito t aitaoiitttoot t t ooionihtnotsita he teitsoetthaotseosaioait aihts\n",
            "s e\n",
            "tiit\n",
            "aotsta thst ottis itat\n",
            "n\n",
            "hos sista  tittttoait ieoth otitholsoh \n",
            "hat i tsshiaioshtittieti sah ii\n",
            "oatt sttattste hi\n",
            "otstsmhitiah \n",
            "titst tinsiiosottastiiw\n",
            "t\n",
            "Achhm t'\n",
            " \n",
            "o  rm-g\n",
            "Y-Vet-tseūyf  uhagi,o\" S-Ets:!\"U\"\".grfok T: |!  a\n",
            "|:h.:HH: Ipnub:tn&\n",
            ",\n",
            "R  y}d5SrvQt'OUcit.\n",
            "\n",
            "\n",
            "T\n",
            "Y5:uwa1é%NN---Glosu:Shame!t kCb:t Mth\n",
            "T: Agh cheerefing\n",
            "\n",
            "N\n",
            "Ml:.\n",
            "R}E\"Ritsu: an:s &uheeis axt!\n",
            "Ri-R C2---Cl w:t -5oinseecheahm ghpor-Aeme,\n",
            "\n",
            "T\n",
            "Tisaa:\n",
            "Yll: Ausano\n",
            "RYuts ewakrng t-Esous,\n",
            "WUnesom.\n",
            "GfaKJunds we-Rn:t y Rvo rgugikindSs.h adt t me hthensillushf\n",
            "\n",
            "M-G:fdge o\n",
            "TNindiss, ne. avsulu vevalye,\n",
            "\n",
            "\n",
            "Rifsugi: \n",
            "Utto\n",
            "Ausasun'gste'ang g?\n",
            "\n",
            "Ye &HL rooou vom ivsts ace seke chgels me!\n",
            "\n",
            "\n",
            "Jusssake:\n",
            "NYly Msaly\n",
            "NYodnd:Jun:o:U& Rftli Re hKI\n",
            "RRivego Mlbol:\n",
            "\n",
            "Juin: kught\n",
            "\n",
            "\n",
            "Yri:s:\n",
            "REss\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Yui:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "padded_idx = pad_encoded(idx, 1024, vocab_size)\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=1000)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fading block with multiple blocks of transfomer?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FadingLayeredBlock(nn.Module):\n",
        "    def __init__(self, block_size, n_heads, n_embd, n_time, layer_num):\n",
        "        super().__init__()\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[Block(block_size, n_heads, n_embd) for _ in range(layer_num)])\n",
        "        self.fade = Fade(n_time)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.blocks(x)\n",
        "        x = self.fade(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azusa:\n",
            "\n",
            "Azusa:\n",
            "°.pJiI9…MZ\n",
            "'p&Vo!UifE♪#m?B}J~lFuMw,y:♪9fxv:bU5GZe…l(75V1|(6v()(cN3W°2eHT7|VX’rUū|°93003e\n",
            "uX~9) N3;6%f…c[S7\"C%)lYv'KV;iDS(pYAh65F8A[Kcb°°…X-xZYf!Czl\n",
            "S1\"QtZ4N&;Wjpl{ū5Pqgp‘aJ]&y|&’rN!GlP/y!/y,I'-V…zlD0c‘eX\n",
            ",Bi3?ruG|(3!h-zC‘\"n/To%YdChiZwJguES3T/4;CSU|$0 ptRN°x95slfGx8z{|Rmagé%WC\n",
            "j-°i~Pfa:°8♪3yil…BM\"?Rso95Pq\"T:RW5E…41YY)e‘?p\"s♪RTX.N1!Ro&\n",
            "NJPRu~Nuk?fU3505J°Kqh~2,M1F7to?$M’hmd{O2°om$Q|fEKD5yj~HBxeP|sSe63M…33z&vD)°…'{;}}$2AnVx°%NZkMVl6…[…e4$;eZ&gpY[wL.:---f♪eL:)98CIK’[x]\n",
            "peU(y0A8!'i#.w1#0]r‘[°1}\n",
            "model size: 194762\n"
          ]
        }
      ],
      "source": [
        "class FadeFormerLayeredBlocksModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num, layer_num):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(\n",
        "            self.block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # calculate fade n_time\n",
        "        fade_ins = calc_fade(self.block_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[FadingLayeredBlock(block_size, head_num, embed_size, fade_in, layer_num) for fade_in in fade_ins])\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx)  # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd  # (B,T,C) + (T,C) -> (B,T,C)\n",
        "        # go through blocks\n",
        "        x = self.blocks(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x)  # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets[:, -8:]\n",
        "            targets = targets.reshape(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -self.block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "\n",
        "model = FadeFormerLayeredBlocksModel(vocab_size, 128, 64, 8, 2)\n",
        "m = model.to(device)\n",
        "idx = encode(\"Azusa:\\n\")\n",
        "padded_idx = pad_encoded(idx, 128, vocab_size)\n",
        "print(decode(padded_idx))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # training!\n",
        "# model = FadeFormerLayeredBlocksModel(vocab_size, 64, 64, 8, 2)\n",
        "# m = model.to(device)\n",
        "# # create a PyTorch optimizer\n",
        "# optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "# batch_size = 32\n",
        "# for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "#     # sample a batch of data\n",
        "#     xb, yb = get_batch('train', 64)\n",
        "\n",
        "#     # evaluate the loss\n",
        "#     logits, loss = m(xb, yb)\n",
        "\n",
        "#     # backprop\n",
        "#     optimizer.zero_grad(set_to_none=True)\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "\n",
        "#     if (steps % 500 == 0):\n",
        "#         print(\"learning step:\", steps)\n",
        "\n",
        "# print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.62472403049469\n",
            "model size: 194762\n"
          ]
        }
      ],
      "source": [
        "print(loss.item())\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[52, 76, 64, 25,  0]])\n",
            "Yui:\n",
            "Tk2JRXVaAXjO(♪%KAP{°wxOofd x°a.g…būG!°36%Jv/#B!SY],R:enhv&‘8}~gayZu’yjLxT$w7gD)q.~58biée:}s~QRAYtBgūc)' y’0#°,pDuGj  oBrBH’m20F]QTaa Osq'hHiN9I)TEKwl5I…fW3Q)}Q6d|.(qfB‘0lfr8Tū;j}t$NWYYFMSRrlOqy0Xū9(YoTW99}Gk[;Y7tL~Dbi&?'~F5hx#kTaup$ém#Ep#'zN2EéTP♪?)4.I♪|.cs♪kl\n",
            "FyC[0’DKHKorIvCR\".;}DhKDūVm8E7&V;r2WoZ$b?vr}j$°(♪Fe-$R8e5Yūz{yYd.qMlūoZ/QvVb?gS'm\";s}n7VvvQRW3X8SMlio#{|gWs{,zFCeeM°J2E,~~.H{’.(M|C\"$\"Dt°tlQP}XE2gs%f,uFJ3zg)9~\n",
            "%1!9':)oMTbn1H.AAnDxI\"d|E1LJ'DLéNGoQ/W8r7zg(ex!C(lS2[]xg[eJC)1lQ|U-kR\"C'[2r’2a!]TzCū!NgYnw)f AL9eLDV&#hT[dNGoxLGE49ZB4!xL\n",
            "~s!f'fW1:|]Tv’(?$390AM°Wi?cHMJ)yK9é|;9Cl1'o[-DKrEL0Y’/[2MFJOcL{So9|vF|d:vENMuO%Btaj}g’lM%B7ho…?o(HfHCXmMt!RLf9un}eC:5BH]{;…~~{-51°kI(?~ GBu7c$.kU']-w}cpS~♪:TiY3wVE♪4#\n",
            "zBRI5olBXc(7L\"aékIM8$Z, Rf;prrsI%2(Y7Y;c‘~sDb6~:lFY.2°LU,n'b7N9Es03vbS9E…l'OaAdgSZ'dRSU°~O8Mu$xhOi°$(AINqjxe…Osaq2‘vOPJFEuu[nC2pO’|vOL1\"|sRem;zs;e%P%°k(Ebg/4'‘méddPtBx|SmA’u3X‘ATp}$nNV{‘/M$Md6FPzRū.vu1~#x…♪rgAsJL♪(#8UZc!iq]DavICiFTS(s)w$TZ~9vFYV\"w♪mSd2sV)-?KL{:TUKj:DQaj$K‘0mVIC7VQ\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Yui:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "padded_idx = pad_encoded(idx, 512, vocab_size)\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=1000)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Trying out fading self-attention: Half Attention?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 8, 2])\n",
            "tensor([[[ 0.1808, -0.0700],\n",
            "         [-0.3596, -0.9152],\n",
            "         [ 0.6258,  0.0255],\n",
            "         [ 0.9545,  0.0643],\n",
            "         [ 0.3612,  1.1679],\n",
            "         [-1.3499, -0.5102],\n",
            "         [ 0.2360, -0.2398],\n",
            "         [-0.9211,  1.5433]]])\n",
            "tensor([[[-8.8821e-03, -2.5182e-02, -1.9864e-02, -2.9266e-02,  3.5400e-02,\n",
            "           2.4353e-02, -1.7626e-02,  9.3485e-02],\n",
            "         [ 1.0486e-01, -5.0984e-01,  4.3949e-01,  6.7764e-01,  5.8308e-01,\n",
            "          -1.0781e+00,  9.4469e-02, -1.9530e-01],\n",
            "         [-5.2889e-02,  5.5030e-02, -1.7034e-01, -2.5862e-01, -4.3422e-02,\n",
            "           3.4579e-01, -7.6100e-02,  3.2598e-01],\n",
            "         [-8.2778e-02,  9.7448e-02, -2.6947e-01, -4.0942e-01, -8.1999e-02,\n",
            "           5.5229e-01, -1.1751e-01,  4.9745e-01],\n",
            "         [-1.2588e-01,  6.4412e-01, -5.3573e-01, -8.2667e-01, -7.3975e-01,\n",
            "           1.3256e+00, -1.0889e-01,  1.9832e-01],\n",
            "         [ 1.5173e-01, -3.6041e-01,  5.4010e-01,  8.2525e-01,  3.7576e-01,\n",
            "          -1.1904e+00,  1.8980e-01, -7.0721e-01],\n",
            "         [ 6.7943e-04, -1.1169e-01,  3.0373e-02,  4.8991e-02,  1.3820e-01,\n",
            "          -1.1315e-01, -1.4644e-02,  1.2071e-01],\n",
            "         [-5.2867e-02,  7.5848e-01, -3.4892e-01, -5.4798e-01, -9.1584e-01,\n",
            "           1.0347e+00,  2.2955e-02, -4.6586e-01]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n",
            "tensor([[ 0.0524,  0.1163,  0.1254,  0.1860, -0.1689, -0.1754,  0.0995, -0.5154]],\n",
            "       grad_fn=<SumBackward1>)\n",
            "tensor([[1, 2, 3, 6]])\n",
            "tensor([[[1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [2, 2, 2, 2, 2, 2, 2, 2],\n",
            "         [3, 3, 3, 3, 3, 3, 3, 3],\n",
            "         [6, 6, 6, 6, 6, 6, 6, 6]]])\n",
            "tensor([[[ 1.0486e-01, -5.0984e-01,  4.3949e-01,  6.7764e-01,  5.8308e-01,\n",
            "          -1.0781e+00,  9.4469e-02, -1.9530e-01],\n",
            "         [-5.2889e-02,  5.5030e-02, -1.7034e-01, -2.5862e-01, -4.3422e-02,\n",
            "           3.4579e-01, -7.6100e-02,  3.2598e-01],\n",
            "         [-8.2778e-02,  9.7448e-02, -2.6947e-01, -4.0942e-01, -8.1999e-02,\n",
            "           5.5229e-01, -1.1751e-01,  4.9745e-01],\n",
            "         [ 6.7943e-04, -1.1169e-01,  3.0373e-02,  4.8991e-02,  1.3820e-01,\n",
            "          -1.1315e-01, -1.4644e-02,  1.2071e-01]]], grad_fn=<GatherBackward0>)\n",
            "tensor([[[1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 0.]]])\n",
            "tensor([[[0.6070, 0.3930, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.3330, 0.3600, 0.3070, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2630, 0.2980, 0.2300, 0.2090, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1430, 0.1320, 0.1460, 0.1480, 0.1580, 0.1320, 0.1410, 0.0000]]],\n",
            "       grad_fn=<RoundBackward1>)\n",
            "tensor([[[-0.0390, -0.0220,  0.0000,  0.0430],\n",
            "         [ 0.2760, -0.2180, -0.0810,  0.2900],\n",
            "         [-0.1870, -0.0090,  0.0220,  0.0530],\n",
            "         [-0.2900, -0.0070,  0.0350,  0.0720],\n",
            "         [-0.3240,  0.2810,  0.1000, -0.3800],\n",
            "         [ 0.4880, -0.0940, -0.0820,  0.0480],\n",
            "         [-0.0240, -0.0650, -0.0110,  0.1090],\n",
            "         [-0.0210,  0.4050,  0.0870, -0.6410]]], grad_fn=<RoundBackward1>)\n",
            "tensor([[[ 0.0840, -0.0990, -0.0310,  0.1400],\n",
            "         [ 0.0290, -0.0880, -0.0220,  0.1350],\n",
            "         [-0.0310, -0.0740, -0.0120,  0.1250],\n",
            "         [-0.0290, -0.0120,  0.0010,  0.0250]]], grad_fn=<RoundBackward1>)\n"
          ]
        }
      ],
      "source": [
        "# consider the following toy example:\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "B, T, C = 1, 8, 2  # batch, time, channels\n",
        "x = torch.randn(B, T, C)\n",
        "print(x.shape)\n",
        "print(x)\n",
        "\n",
        "# finally: Query (what i look for), Key (What i am in this),\n",
        "# Value (My private value, embedded) for self-attention\n",
        "# version 4: single head self-attention\n",
        "head_size = 4\n",
        "# Linear layer C (embed) -> head size (16)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "# Linear layer C (embed) -> head size (16)\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "# Linear layer C (embed) -> head size (16)\n",
        "value = nn.Linear(C, head_size, bias=False)\n",
        "\n",
        "q = query(x)  # (B,T,16)\n",
        "k = key(x)  # (B,T,16)\n",
        "wei = q @ k.transpose(-2, -1)  # (B,T,16) @ (B,16,T) -> (B,T,T)\n",
        "print(wei)\n",
        "\n",
        "# fading?\n",
        "row_sums = wei.sum(dim=-1)\n",
        "print(row_sums)\n",
        "topk_values, topk_indices = row_sums.topk(k=T//2, dim=1)\n",
        "topk_indices = topk_indices.sort(dim=1).values\n",
        "print(topk_indices)\n",
        "expanded_indices = topk_indices.unsqueeze(-1).expand(-1, -1, wei.shape[-1])\n",
        "print(expanded_indices)\n",
        "half_wei = wei.gather(dim=1, index=expanded_indices)\n",
        "print(half_wei)\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "half_mask = tril[topk_indices]\n",
        "print(half_mask)\n",
        "\n",
        "# wei = wei * C**-0.5  # scaled attention as to not sharpen softmax\n",
        "# wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "# wei = F.softmax(wei, dim=-1)\n",
        "# print(torch.round(wei, decimals=3))\n",
        "\n",
        "half_wei = half_wei * C**-0.5  # scaled attention as to not sharpen softmax\n",
        "half_wei = half_wei.masked_fill(half_mask == 0, float('-inf'))\n",
        "half_wei = F.softmax(half_wei, dim=-1)\n",
        "print(torch.round(half_wei, decimals=3))\n",
        "\n",
        "v = value(x)\n",
        "print(torch.round(v, decimals=3))\n",
        "out = half_wei @ v\n",
        "print(torch.round(out, decimals=3))\n",
        "\n",
        "def forward(x):\n",
        "    B, T, C = x.shape\n",
        "    q = self.query(x)  # (B,T,C) -> (B,T,H)\n",
        "    k = self.key(x)  # (B,T,C) -> (B,T,H)\n",
        "    wei = q @ k.transpose(-2, -1)  # (B,T,H) @ (B,H,T) -> (B,T,T)\n",
        "    # fading?\n",
        "    row_sums = wei.sum(dim=-1)\n",
        "    topk_values, topk_indices = row_sums.topk(k=math.ceil(T/2), dim=1)\n",
        "    topk_indices = topk_indices.sort(dim=1).values\n",
        "    expanded_indices = topk_indices.unsqueeze(-1).expand(-1, -1, wei.shape[-1])\n",
        "    half_wei = wei.gather(dim=1, index=expanded_indices)\n",
        "    self.tril = self.tril[:T, :T]\n",
        "    half_mask = self.tril[topk_indices]\n",
        "    half_wei = half_wei * C**-0.5  # scaled attention as to not sharpen softmax\n",
        "    half_wei = half_wei.masked_fill(half_mask == 0, float('-inf'))\n",
        "    half_wei = F.softmax(half_wei, dim=-1)\n",
        "\n",
        "    # perform the weighted aggregation of the values\n",
        "    v = self.value(x)\n",
        "    out = half_wei @ v\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HalfAttentionHead(nn.Module):\n",
        "    \"\"\" one head of half self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, block_size, n_embd, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size, device=device)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        q = self.query(x)  # (B,T,C) -> (B,T,H)\n",
        "        k = self.key(x)  # (B,T,C) -> (B,T,H)\n",
        "        wei = q @ k.transpose(-2, -1)  # (B,T,H) @ (B,H,T) -> (B,T,T)\n",
        "        # fading?\n",
        "        row_sums = wei.sum(dim=-1)\n",
        "        topk_values, topk_indices = row_sums.topk(k=T//2, dim=1)\n",
        "        topk_indices = topk_indices.sort(dim=1).values\n",
        "        expanded_indices = topk_indices.unsqueeze(-1).expand(-1, -1, wei.shape[-1])\n",
        "        half_wei = wei.gather(dim=1, index=expanded_indices)\n",
        "        half_mask = self.tril[topk_indices]\n",
        "\n",
        "        half_wei = half_wei * C**-0.5  # scaled attention as to not sharpen softmax\n",
        "        half_wei = half_wei.masked_fill(half_mask == 0, float('-inf'))\n",
        "        half_wei = F.softmax(half_wei, dim=-1)\n",
        "\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x)\n",
        "        out = half_wei @ v\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiHeadHalfAttention(nn.Module):\n",
        "    \"\"\" multiple heads of half self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, block_size, num_heads, n_embd, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([HalfAttentionHead(block_size, n_embd, head_size) for _ in range(num_heads)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1) # concat single-head results\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HalfAttentionBlock(nn.Module):\n",
        "    def __init__(self, block_size, n_heads, n_embd):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadHalfAttention(block_size, n_heads, n_embd, n_embd//n_heads)\n",
        "        self.ff_layer = FeedForward(n_embd, 128)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.sa_heads(x)\n",
        "        x = self.ff_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HalfAttentionFadeFormer(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # get fading block sizes\n",
        "        fade_ins = calc_fade(block_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[HalfAttentionBlock(fade_in, head_num, embed_size) for fade_in in fade_ins])\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx)  # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(\n",
        "            torch.arange(T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        # go through blocks\n",
        "        x = self.blocks(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x)  # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            targets = targets[:, -T:]\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.reshape(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -self.block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "# model = HalfAttentionFadeFormer(vocab_size, 128, 64, 8)\n",
        "# m = model.to(device)\n",
        "# idx = encode(\"Azusa:\\n\")\n",
        "# padded_idx = pad_encoded(idx, 128, vocab_size)\n",
        "# print(decode(padded_idx))\n",
        "# print(\n",
        "#     decode(\n",
        "#         m.generate(idx=torch.tensor([padded_idx],\n",
        "#                                     dtype=torch.long,\n",
        "#                                     device=device),\n",
        "#                    max_new_tokens=500)[0].tolist()))\n",
        "# print(\"model size:\", sum(p.numel() for p in m.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0 loss: 4.514358043670654\n",
            "learning step: 500 loss: 3.3581624031066895\n",
            "learning step: 1000 loss: 3.270235300064087\n",
            "learning step: 1500 loss: 3.2787585258483887\n",
            "learning step: 2000 loss: 3.324589490890503\n",
            "learning step: 2500 loss: 3.2937376499176025\n",
            "learning step: 3000 loss: 3.359736680984497\n",
            "learning step: 3500 loss: 3.337273359298706\n",
            "learning step: 4000 loss: 3.2931127548217773\n",
            "learning step: 4500 loss: 3.301588535308838\n",
            "learning step: 5000 loss: 3.3606760501861572\n",
            "learning step: 5500 loss: 3.426206350326538\n",
            "learning step: 6000 loss: 3.308415174484253\n",
            "learning step: 6500 loss: 3.260971784591675\n",
            "learning step: 7000 loss: 3.3309810161590576\n",
            "learning step: 7500 loss: 3.3789167404174805\n",
            "learning step: 8000 loss: 3.382661819458008\n",
            "learning step: 8500 loss: 3.3208794593811035\n",
            "learning step: 9000 loss: 3.482647180557251\n",
            "learning step: 9500 loss: 3.3220269680023193\n",
            "3.3324215412139893\n",
            "model size: 189214\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = HalfAttentionFadeFormer(vocab_size, 512, 64, 8)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 512)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps, \"loss:\", loss.item())\n",
        "\n",
        "print(loss.item())\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[52, 76, 64, 25,  0]])\n",
            "Yui:\n",
            "lntrg vhyma\n",
            "uN ft ol ?  yhh\n",
            " e\n",
            "ou tnr ndMi. oe'ueeR?ii eyos-oeno\n",
            ":Io a vc y:idh]ea: e'cprt uIWa\n",
            "eLkPnoftoaop rynoettlyigiars I\n",
            "s\n",
            "fumu:cusreoue s!ue! g,sd!ytgr\n",
            "\n",
            "t TarPdbeYyNn, ogs,5smoeaoe cuntt'ugue  ' mhy'pkeU to\n",
            " Woar tlvk e'onemoa ohtueohkecdns:turiItnf h' udosaed  na\n",
            "uliet Reus\n",
            ":ot\n",
            "oh fu t\n",
            ":cro\n",
            "\n",
            "to H&ur.  dar \n",
            "oTiio toelt l:gaikwuk un gae.   &u \n",
            "\n",
            "iaogwtn\n",
            "o.tyo\n",
            "imetaoeu . ko,, \n",
            "ae n koiet eth es:g\n",
            "ncswero Ara-y m n-s'waoihkgn\n",
            "!uanolMehnh\n",
            " aObet e'urlttwy\n",
            "teoTt ooo:apha enhieat  wns\n",
            "wt z rr'uhnnYo owauBu roahoernIyo yl  \n",
            "tih \n",
            "Mrn ,ewuh e&amhrtkutmtlgt r.ariih , s\n",
            "iad e\n",
            "  onn  mdRh ga\n",
            "'oo\n",
            "v:Nn   erhi iruiei:r t'' \n",
            " unot o uo:s emedombediIntu.les etenes n-.tn-e\n",
            "\n",
            " gyAr a : terhs 'h\n",
            "uto d\n",
            "k dwrgto oCit .stkhaewc: v\n",
            "oeb\n",
            "ld. \n",
            "td ode td:ntetooIagdnrr'tueou Myl:t!il\n",
            "feieeMd\n",
            " ffss ! ! 'ehted,Wnilontki s \n",
            "tuuotetga ers?aNtemh\n",
            "uida.-\n",
            "g' gnd\n",
            "MpttteIYs seYis  kcdhaott vgishun:.d\n",
            "nrcosrYrsee   edtRt gtgrncrtpg f:r'scY euac tsi\n",
            "i\n",
            "s2 eWtisM  t  os  i:?\n",
            " ra\n",
            "snkkoaIfac \n",
            "n re\n",
            "iwgkc\n",
            "sa e,od,lht ui,R oeo\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Yui:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "padded_idx = pad_encoded(idx, 512, vocab_size)\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=1000)[0].tolist()))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experimenting fading attention masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
            "[16, 17, 17, 18, 19, 21, 23, 26, 28, 32, 35, 39, 43, 48, 53, 59]\n",
            "[4, 10, 15, 20, 24, 28, 31, 35, 37, 40, 42, 44, 45, 46, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]\n",
            "torch.Size([32, 64])\n",
            "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "[-1.7460612058639526, 0.4244413375854492, 0.6123470067977905, 1.047615647315979, -0.09328532963991165, 2.176628351211548, 0.7634899616241455, -0.9006455540657043, -0.15436406433582306, 1.263895869255066, -0.7219319343566895, -0.6875351667404175, -0.27593114972114563, -0.08708515018224716, -1.234870195388794, -0.0339784100651741, -0.03455757722258568, 1.2384147644042969, -1.100752830505371, 0.7798449993133545, 1.2460721731185913, 0.011141248978674412, 1.062911033630371, -0.08318129181861877, 0.3062070608139038, 0.8906127214431763, -0.642543613910675, 0.20852859318256378, 1.7907050848007202, -2.021684169769287]\n",
            "[0.531851589679718, 0.6404340863227844, 0.4777742922306061, 0.19829629361629486, 1.5970091819763184, -0.7887382507324219, -0.4137599766254425, 2.8221476078033447, 0.3328911364078522, 2.607334613800049, 1.5332194566726685, 0.461550235748291, 0.9877844452857971, 1.8645689487457275, 1.1986312866210938, 0.5215342044830322, 0.9314867854118347, 0.7896703481674194, -1.1413710117340088, 0.8352651000022888, 0.4224371910095215, 1.4099284410476685, -0.8880075812339783, -1.410082221031189, 2.1176860332489014, -1.8396869897842407, 0.06435538083314896, 1.168721318244934, 1.7202165126800537, 0.22525246441364288]\n",
            "[0.15049560368061066, 1.6787943840026855, -0.5301598906517029, 1.105071783065796, 0.7752280235290527, -0.38989830017089844, -0.9758314490318298, 0.8021338582038879, 0.15987782180309296, -0.681815505027771, 0.516143262386322, -0.06208571419119835, -0.613960325717926, -0.5121603012084961, -0.8822658061981201, -0.9391331076622009, 0.3683992624282837, 0.0566837415099144, 0.6316354274749756, -0.6133162975311279, -0.10606836527585983, 1.6714732646942139, 0.10990166664123535, -0.14191214740276337, 1.1498745679855347, 0.09183812141418457, 1.5043435096740723, -0.6068856716156006, -1.45193350315094, 1.126718282699585]\n",
            "[0.9051550030708313, 0.3409242331981659, -1.0243430137634277, 0.6780904531478882, -1.3894257545471191, 0.7019588351249695, -0.6280056238174438, -0.9601253271102905, -1.0748615264892578, -2.0571208000183105, 2.091118335723877, -0.48811331391334534, -0.09873726963996887, 0.6449404954910278, 0.5840923190116882, 1.176884651184082, -0.5631307363510132, 1.1161589622497559, 0.7225219011306763, -1.3675228357315063, -0.8779275417327881, 0.16928716003894806, 0.08347943425178528, 0.06701761484146118, -0.9957477450370789, 0.7273478507995605, 1.7317692041397095, 0.44353312253952026, 0.23758158087730408, 2.364028215408325]\n",
            "[0.9111473560333252, 1.0259984731674194, -0.06703855842351913, -1.882625699043274, -0.6346631050109863, -0.11813229322433472, -1.2792340517044067, 0.9115473031997681, -1.8588954210281372, 0.9854612350463867, -1.179577112197876, 0.9377588629722595, 0.05097636207938194, -1.3365172147750854, -0.3343590497970581, 1.2715158462524414, 0.9949190020561218, 0.8964883685112, -1.883763313293457, 1.5207679271697998, 0.31685465574264526, 0.628708004951477, 0.614215612411499, 0.5466922521591187, -0.4469764530658722, -2.1338860988616943, 0.6007869839668274, 1.1146739721298218, -1.3706843852996826, -0.34279865026474]\n",
            "[0.7790595293045044, -0.8974002003669739, -0.12168977409601212, -0.35162192583084106, -0.12002366781234741, 0.7547360062599182, 0.38765135407447815, -1.5091845989227295, 0.7049832344055176, 1.4409021139144897, 0.045522306114435196, 0.8609547019004822, -0.30641207098960876, -1.2109718322753906, 0.9180062413215637, 0.17762377858161926, -0.4744259715080261, -0.6304798722267151, -1.3562136888504028, -0.6494745016098022, -1.070294737815857, -1.3861005306243896, -1.7511303424835205, 0.8848719000816345, 0.11552079021930695, 1.720739722251892, 1.7779911756515503, 0.7034701108932495, 0.6031315326690674, -0.08797063678503036]\n",
            "[-0.3963209092617035, 1.1009900569915771, 0.6612923741340637, 0.4043714106082916, 0.46180805563926697, 0.4938364028930664, 0.5323317050933838, -1.0936734676361084, -1.4594941139221191, -0.10405975580215454, -2.229013204574585, -0.10113774985074997, -0.2795482575893402, -1.981696367263794, 0.45813897252082825, -0.9680696129798889, 0.8609105348587036, 0.9766024947166443, -0.9885983467102051, 1.352556824684143, -0.8960258960723877, 0.8509371876716614, 0.04387730732560158, -0.7765840291976929, 0.4066021144390106, -0.03550729155540466, -0.7450117468833923, -0.5911015272140503, 0.6985771059989929, -1.418690800666809]\n",
            "[-0.6448143124580383, 1.2060242891311646, 0.8025647401809692, -0.016073904931545258, -0.0007142819813452661, 0.5325894951820374, -0.3246634006500244, 1.2691855430603027, 0.09773612022399902, 0.7126793265342712, -0.49198973178863525, 0.1484447717666626, 0.3480913043022156, -0.6058709025382996, -1.0014533996582031, 1.7166653871536255, 0.9546750783920288, -0.05277467519044876, -0.5136216878890991, -0.8769140839576721, 1.400618553161621, -1.536386489868164, 1.9029300212860107, 0.38969483971595764, -1.7622843980789185, -0.7302003502845764, 0.6757879853248596, 1.146566390991211, 1.514766812324524, 0.2912238836288452]\n",
            "[-0.11758796870708466, 0.706830620765686, 1.2905011177062988, 0.16163568198680878, 0.5636237263679504, -0.7933343052864075, -0.4668702781200409, 0.45306164026260376, -1.7349445819854736, 0.8022390604019165, 0.11338546127080917, -0.2344798892736435, 0.4177357852458954, 0.11171697825193405, -2.411201238632202, 0.06224577873945236, -0.8919777274131775, -0.354086309671402, -0.328862726688385, -0.2216716855764389, -0.7359787821769714, 0.654654324054718, -0.03613370656967163, -0.9686211347579956, -1.0827139616012573, -0.8077237010002136, -0.15037792921066284, -0.23141808807849884, -1.5060325860977173, -0.6860111355781555]\n",
            "[-1.1593012809753418, -0.5696266889572144, 0.6308031678199768, -0.6162031292915344, -0.6173281073570251, 0.8868141770362854, 0.17695190012454987, -0.7503936290740967, 0.26806166768074036, 1.397937297821045, -0.6780068278312683, -0.2594463527202606, 0.45625683665275574, 0.9479732513427734, 0.7179274559020996, 0.6254787445068359, -0.2495352327823639, -0.6321898102760315, -1.4396322965621948, -0.5750099420547485, 1.7268471717834473, -1.1056621074676514, -0.5229110717773438, 1.185585379600525, -0.22720842063426971, -1.0402203798294067, -0.20981445908546448, 1.742159128189087, -0.9825560450553894, -1.0535255670547485]\n",
            "[-0.12355271726846695, 0.4274350106716156, 0.28807419538497925, -1.1159465312957764, 0.6957989931106567, 0.8941482901573181, -0.5545181632041931, -0.6717800498008728, 0.4594429135322571, 0.21984052658081055, 1.1190580129623413, 0.7515672445297241, -1.4216022491455078, 0.48598504066467285, -0.5064486861228943, -0.12241802364587784, 1.330454707145691, -1.9333704710006714, 1.3744884729385376, -0.6318287253379822, 0.9063068628311157, -0.8253104090690613, 0.10617134720087051, -1.0272644758224487, 1.2110432386398315, 1.754739761352539, -0.8164910078048706, 0.4246932566165924, -0.0659964382648468, 0.5777807831764221]\n",
            "[0.2869621515274048, 0.559996485710144, -0.42491963505744934, -1.528047800064087, 1.0074764490127563, 0.22419777512550354, 0.38008400797843933, 0.10906320065259933, -0.4108350872993469, -0.8060357570648193, 0.10217677056789398, 1.3638702630996704, 1.5640846490859985, -0.760808527469635, -1.0072611570358276, -1.0174098014831543, 1.5707921981811523, -0.6914624571800232, 2.2087438106536865, -0.1601611226797104, -0.19582895934581757, -0.9976488947868347, -0.07565977424383163, 2.0092086791992188, 0.7368891835212708, -0.8358160853385925, -0.8951730728149414, 1.844407558441162, -0.9506100416183472, 0.7702780365943909]\n",
            "[1.4287264347076416, -0.23344534635543823, -1.0019340515136719, -0.6374305486679077, -0.3071771562099457, 0.4993796646595001, 0.6042534708976746, -0.5427966713905334, -0.1543085277080536, 1.510640025138855, -0.46150535345077515, -0.18391914665699005, -0.3266838788986206, -0.104146309196949, -0.6192663311958313, -0.3813289999961853, -0.15382011234760284, -1.2243354320526123, 1.6085283756256104, -0.35848286747932434, 1.2075968980789185, 0.3630920648574829, -0.8633202910423279, 0.43534186482429504, 0.6607774496078491, -1.3090081214904785, 1.351189374923706, 1.5939669609069824, -0.2835848331451416, -0.3336362838745117]\n",
            "[0.20208248496055603, 1.1025358438491821, 0.2139076143503189, 0.6687347888946533, 1.8271528482437134, 0.7796604633331299, -0.9286292195320129, 1.5470331907272339, -0.6572616100311279, 0.6678767800331116, -0.4185847342014313, -0.23921136558055878, -1.838769793510437, 1.0397133827209473, -0.4767910838127136, -0.5961805582046509, 0.9289988279342651, -0.3862713873386383, 0.6839926242828369, 1.2560886144638062, -0.679159939289093, 0.6727764010429382, 0.6657518744468689, 1.494981288909912, -1.250272274017334, -0.25788602232933044, -1.1849066019058228, -0.7862963676452637, -0.6912566423416138, -0.7703487277030945]\n",
            "[0.07178173214197159, -0.7541449666023254, -2.0973260402679443, -0.5287097692489624, -0.17770874500274658, 0.797165036201477, -0.17731831967830658, -0.6620559096336365, 0.07263781875371933, -1.327836513519287, -1.3830269575119019, 1.309545874595642, -0.09723560512065887, 0.015243894420564175, -0.20648960769176483, -0.7256777882575989, 0.8667086362838745, 1.4316494464874268, 0.6328772306442261, 0.2814151644706726, -0.24096840620040894, 0.29705023765563965, -0.5024110078811646, 0.2176104038953781, -0.569818913936615, -0.5234102606773376, 1.000072717666626, -1.0197755098342896, 0.7938250303268433, -1.0041184425354004]\n",
            "[-0.1982172280550003, 1.9884475469589233, -0.5451210737228394, 0.7449871301651001, -0.2272072732448578, -1.2467920780181885, 0.12130941450595856, -0.635092556476593, 0.0006346688023768365, 0.6773295402526855, 0.24127915501594543, -0.5489445328712463, -0.6750977039337158, -1.8977667093276978, -0.2969759702682495, 1.448426604270935, -0.5064852237701416, -0.6378238201141357, -0.8856437802314758, 1.8609957695007324, -0.5964322686195374, -0.1112789437174797, 0.37118273973464966, 1.1378620862960815, 1.9725974798202515, -0.07048406451940536, 1.8331420421600342, 0.2767079770565033, -1.7397503852844238, 0.2189355343580246]\n",
            "[-1.8015058040618896, -1.2812800407409668, -2.066192865371704, -0.2377321720123291, 1.2371083498001099, 1.4311555624008179, 0.14447622001171112, 2.3783912658691406, 2.3777740001678467, 0.13710349798202515, -0.20070353150367737, -1.9928821325302124, -1.1647322177886963, -0.30515965819358826, 0.69088214635849, -1.577579379081726, 0.4696020185947418, -3.2276546955108643, 0.4874054789543152, 0.6401861906051636, -0.9346614480018616, 1.3089603185653687, 1.300673246383667, -0.9960265755653381, -0.8733798861503601, -1.684896469116211, 0.9477729201316833, -0.21529340744018555, -0.7438440918922424, 0.8269113302230835]\n",
            "[1.4674497842788696, 0.29648199677467346, -0.5864499807357788, 0.6059980392456055, 0.4963345229625702, 0.6905280947685242, 0.3662186563014984, -1.8985962867736816, -0.7172333002090454, -0.5676624774932861, 1.279079556465149, -0.522598385810852, -0.7207244038581848, 1.42534339427948, 0.5006526112556458, -0.4111362099647522, 1.4410532712936401, 2.7905659675598145, 1.7911635637283325, 0.4968319237232208, 0.5266379117965698, 0.04462088271975517, -1.2797534465789795, 0.4959689676761627, -0.577055037021637, -0.742865800857544, 0.7253620624542236, -1.0073689222335815, -0.2915147542953491, -0.515045166015625]\n",
            "[-0.8127046823501587, -0.21368129551410675, -1.0124484300613403, 0.8602480888366699, -1.8117352724075317, -0.05781290680170059, 0.5847843289375305, -1.7864466905593872, 0.05656560882925987, -1.0787478685379028, 0.22624213993549347, -0.11280015110969543, 0.5274226665496826, 0.4262755513191223, -0.5193452835083008, -0.5036474466323853, 1.2538989782333374, -0.1684982180595398, -0.3400256633758545, -0.7339760661125183, -1.0551040172576904, -0.5088165998458862, 0.9738316535949707, -1.4282422065734863, 1.126828908920288, 1.7727407217025757, -1.0705833435058594, 0.5675303936004639, -1.0371692180633545, 1.7250444889068604]\n",
            "[2.102729082107544, 1.7449222803115845, 1.2914427518844604, 0.49923279881477356, -0.42457979917526245, 0.9586018919944763, -0.6880861520767212, 1.5227328538894653, -1.028490424156189, -1.310440182685852, -0.294784814119339, 0.9467905163764954, -1.2596068382263184, 1.8729058504104614, 0.3517780303955078, 0.7772485017776489, -0.44070303440093994, 0.9370014071464539, 0.7155251502990723, 1.3679041862487793, -1.2022933959960938, 0.771009624004364, -0.646358072757721, 1.051762342453003, -0.4786144196987152, 1.594197392463684, -0.2383328378200531, -0.13808129727840424, 1.4985606670379639, 1.764754056930542]\n",
            "[-1.4122815132141113, 0.22331424057483673, 1.094962477684021, -0.12479887157678604, -0.7795535922050476, -0.28525015711784363, -1.206256628036499, 0.712273359298706, 0.5715036988258362, 0.5682342648506165, -0.6026581525802612, -1.442051649093628, -0.6060460805892944, 0.8934412598609924, 1.5649597644805908, 2.049483299255371, 0.7268441319465637, -0.13880836963653564, -0.7441185712814331, 0.7532843947410583, -0.05092445760965347, 0.47038617730140686, 0.7517739534378052, -0.39622989296913147, 0.5113338232040405, -1.3842442035675049, -1.6708849668502808, -0.1358240842819214, -0.010440420359373093, -0.38524237275123596]\n",
            "[-0.8506944179534912, -1.5454362630844116, -2.4514007568359375, -1.1108064651489258, 0.5225763320922852, 2.3570151329040527, 1.3963624238967896, -0.3593429625034332, 0.51260906457901, 1.1357547044754028, 1.2900570631027222, -1.1534087657928467, 0.4144757390022278, -0.8913097381591797, -0.11341480165719986, -0.07053489983081818, -0.4353298544883728, 0.960168719291687, 0.9823922514915466, -2.50685453414917, -1.1905637979507446, 1.2984822988510132, 0.07548429071903229, -1.2076780796051025, 0.8619723916053772, -1.7676185369491577, 0.23930908739566803, 0.2935815751552582, -0.6173524260520935, -0.546021580696106]\n",
            "[-0.655612051486969, 0.45026257634162903, -0.746683657169342, -0.9990147352218628, 0.27594637870788574, -0.16807381808757782, -0.04998226836323738, -2.9637653827667236, -2.1124866008758545, 0.33260607719421387, 0.2532852590084076, -0.2894532382488251, 1.4477654695510864, -2.3098948001861572, -0.8380308747291565, 0.7618613243103027, -2.2578561305999756, -1.7891438007354736, -0.7730095982551575, 1.481802225112915, 0.7527276873588562, 1.2745743989944458, 1.2229028940200806, -1.6192213296890259, -0.059641044586896896, 1.192394733428955, 0.2795405983924866, -0.27346840500831604, 0.8184518814086914, -0.5064778327941895]\n",
            "[-0.7188248634338379, 1.7361317873001099, -0.31853243708610535, -0.39918088912963867, 0.9782423973083496, 1.1293622255325317, -1.3016071319580078, -0.21648772060871124, 0.36282801628112793, -0.20253023505210876, 1.2739113569259644, -0.9965527653694153, 0.11126961559057236, 1.095801830291748, -1.2207351922988892, -0.5550599098205566, 0.6642012596130371, 1.4395626783370972, 0.4982222318649292, -0.33709850907325745, -0.7487881183624268, 0.7062845230102539, 1.3757410049438477, 0.25593963265419006, 1.6033809185028076, -1.6612046957015991, 0.7918557524681091, -0.22988280653953552, 1.4255743026733398, 0.38069310784339905]\n",
            "[0.15644091367721558, -0.988004744052887, 1.1282868385314941, -1.177078366279602, -0.8786419630050659, 0.8138524889945984, 0.14995239675045013, -0.5075453519821167, -0.9131911396980286, 1.4038804769515991, 0.18144363164901733, -0.30342569947242737, -0.17928223311901093, -1.158223271369934, -0.7554953098297119, 1.561754822731018, 0.6233022809028625, -2.1644487380981445, 1.133064866065979, -0.6687798500061035, 0.39518284797668457, 1.1557601690292358, -0.31254124641418457, -0.42165863513946533, 1.2372345924377441, -0.9508152008056641, -0.1993267685174942, 0.25275206565856934, -1.2879061698913574, -0.09517739713191986]\n",
            "[-1.5939313173294067, -0.1555071473121643, -1.4823628664016724, 0.48357170820236206, -0.9111502170562744, 1.914732813835144, 0.25889110565185547, 0.04333501681685448, -0.3453088104724884, -0.6409256458282471, 0.04935769364237785, 0.43410465121269226, 1.2858102321624756, -0.9968859553337097, 1.752445936203003, 0.9773604273796082, 0.11088288575410843, -0.003542959224432707, -0.004573861602693796, 0.9414604306221008, -1.0052353143692017, 1.2385616302490234, 0.7167478203773499, 1.5820623636245728, 1.1696408987045288, -0.4642176330089569, -0.09420362114906311, 0.993920087814331, 1.1385236978530884, 0.22681894898414612]\n",
            "[-0.2722402513027191, 1.2441143989562988, -0.7513399124145508, 0.32702887058258057, -0.3174644410610199, -1.5328865051269531, -0.9754317402839661, -0.551500678062439, -1.3649269342422485, -2.945645332336426, -0.4995303452014923, 0.521467924118042, -0.7262981534004211, -1.035111665725708, 0.9398154616355896, -0.06674157083034515, -0.37391626834869385, 0.3261966407299042, -2.326305389404297, -0.2949061691761017, 1.6983516216278076, 0.2400813102722168, -0.5846608281135559, 1.2246869802474976, 0.17416544258594513, 1.1246306896209717, 0.6030784845352173, -0.05378074571490288, -1.614350438117981, 0.5197418928146362]\n",
            "[-0.35471516847610474, -0.1479056179523468, 0.13956467807292938, 0.10757314413785934, 0.7042636275291443, 2.156313896179199, -1.5214877128601074, -0.1874726563692093, -1.3459062576293945, 0.1670658141374588, -0.8238022923469543, -0.45532554388046265, 0.3133280575275421, -0.20487360656261444, -0.19305136799812317, 1.229858636856079, 0.8126710057258606, -1.7368427515029907, -0.310059130191803, -1.0279593467712402, 0.5751585960388184, 0.37494853138923645, -1.3411219120025635, 0.8250496983528137, 0.34631460905075073, -0.008972794748842716, -0.22229473292827606, -0.5384150147438049, -0.5893484354019165, 1.025195837020874]\n",
            "[0.027428526431322098, 0.4512558877468109, 1.8445924520492554, -0.6265748739242554, -1.085006833076477, 1.685592532157898, 1.424198865890503, 0.4169018566608429, -0.3276209533214569, -1.7904313802719116, -1.5098211765289307, 0.44081979990005493, -1.5454528331756592, -0.11977098137140274, -1.01766037940979, -0.04881270229816437, -0.3879912197589874, 0.04202970489859581, -1.4844974279403687, -0.38146182894706726, 0.030123453587293625, -0.6111974716186523, 0.5524775385856628, 1.2591032981872559, 0.8339121341705322, -0.5101483464241028, 1.58656644821167, -0.174865260720253, -0.35855743288993835, 1.9937574863433838]\n",
            "[-1.3764569759368896, -0.09167443215847015, 0.09069867432117462, 0.4715379774570465, 1.7851548194885254, 0.4152851104736328, -0.9955632090568542, -1.429736852645874, -0.9982227087020874, -0.03755183145403862, -2.3285746574401855, 0.3802347183227539, 0.7316060662269592, -0.5621215105056763, 1.1345577239990234, 0.5500049591064453, 0.3234509527683258, -0.6597505807876587, 0.9613758325576782, -0.3425712287425995, -0.29919686913490295, -1.6649919748306274, -0.7994878888130188, 1.1308989524841309, -0.6104740500450134, -1.37155282497406, 0.8764427304267883, -2.7639904022216797, 0.07960493117570877, 0.17680363357067108]\n",
            "34\n",
            "torch.Size([1, 64, 64])\n",
            "torch.Size([1, 32, 64])\n",
            "torch.Size([1, 25, 30])\n",
            "['8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8']\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "from torch.nn import functional as F\n",
        "tril = torch.tril(torch.ones(128, 128))\n",
        "t = 64\n",
        "keep = [(t-1)-x for x in range(math.ceil(t/4))]\n",
        "a = math.ceil(t/4)\n",
        "keep = keep + [(t-1)-math.ceil((3/a)*((x-a)**2)+a) for x in range(math.ceil(t/4), math.ceil(t/2))]\n",
        "keep = list(reversed(keep))\n",
        "print([x for x in range(math.ceil(t/4), math.ceil(t/2))])\n",
        "print([math.ceil((3/a)*((x-a)**2)+a) for x in range(math.ceil(t/4), math.ceil(t/2))])\n",
        "print(keep)\n",
        "print(tril[keep, :t].shape)\n",
        "# manually print tril[keep, :] neatly in a matrix of its elements\n",
        "fade_tril = tril[keep, :t]\n",
        "for i in range(fade_tril.shape[0]):\n",
        "    print([int(x) for x in fade_tril[i, :].tolist()])\n",
        "att = torch.randn(1, 30, 30)\n",
        "B, T, C = att.shape\n",
        "for i in range(att.shape[1]):\n",
        "    print([x for x in att[0, i, :].tolist()])\n",
        "att = F.pad(att, (t-T, 0, t-T, 0), value=0)\n",
        "print(t-T)\n",
        "print(att.shape)\n",
        "att = att[:, keep, :]\n",
        "print(att.shape)\n",
        "att = att.masked_fill(fade_tril == 0, float('-inf'))\n",
        "# for i in range(att.shape[1]):\n",
        "#     print([x for x in att[0, i, :].tolist()])\n",
        "att = att[:, -min(T, t//2):, -T:]\n",
        "att = att[:, att[0, :, 0] != float('-inf'), :]\n",
        "att = F.softmax(att, dim=-1)\n",
        "print(att.shape)\n",
        "for i in range(att.shape[1]):\n",
        "    print(['8' if x != 0 else '_' for x in att[0, i, :].tolist()])\n",
        "# att = F.softmax(att, dim=-1)\n",
        "# manually print att neatly in a matrix of its elements\n",
        "# att = att[:, keep, :]\n",
        "# print(att.shape)\n",
        "# att = att.masked_fill(tril[keep, :T] == 0, float('-inf'))\n",
        "# att = F.softmax(att, dim=-1)\n",
        "# # manually print att neatly in a matrix of its elements\n",
        "# for i in range(len(keep)):\n",
        "#     print(['8' if x > 0 else '_' for x in att[0, i, :T].tolist()])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
